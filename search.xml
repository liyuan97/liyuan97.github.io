<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>知识图谱与推荐系统综述</title>
    <url>/2020/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E4%B8%8E%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%BB%BC%E8%BF%B0/</url>
    <content><![CDATA[<blockquote>
<p>最近有调研几篇知识图谱在推荐系统的应用的论文，在组内进行了分享。在这里写成文字版，给大家普及一下知识图谱的背景以及在推荐上的应用。如有错误，望指正。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">背景介绍（2012-2020）</span><br><span class="line">推荐场景发展</span><br><span class="line">1. Collaborative knowledge base embedding for recommender systems KDD, 2016, Microsoft</span><br><span class="line">2. Deep knowledge-aware network (DKN) 2018,  ShanghaiJiaoTongU</span><br><span class="line">3. RippleNet: Propagating User Preferences on the Knowledge Graph for Recommender Systems, 2018, ShanghaiJiaoTongU</span><br><span class="line">总 结</span><br></pre></td></tr></table></figure><br><a id="more"></a></p>
<h1 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h1><p><img alt="image.png" data-src="https://i.loli.net/2020/09/02/bLznvOZGX1trjDC.png"><br>知识图谱在数学里可以抽象成异构信息网络（Heterogeneous Information Network）。<br>区别于同构信息网络的点在于，同构信息网络内，所有的节点都是同一种类型，边的关系也是同一种类型，比如：社交网络的节点是“人”，边是“认识”；论文相互引用关系的网络中，节点是“论文“，边是有向的”引用“关系。<br>而再异构信息网络中（也就是我们提到的知识图谱），节点的类型可以是多种，比如“歌曲” “歌手” “歌单” “创作公司” 等，关系也可以是多种 “歌手-歌手” ： “相似，恋人，合作过”、“歌手-歌曲”：“原创，翻唱，作词，作曲”等。<br>可以理解为，知识图谱可以填充所有现实世界错综复杂的关系。<br>愿景是，如果我们可以结构化的梳理出这些数据，并且把显示的信息用于我们的推荐、搜索等领域，定能使得我们的系统更加智能，可解释。可以使得我们的内容理解更加充分。</p>
</blockquote>
<h2 id="知识图谱的常见应用"><a href="#知识图谱的常见应用" class="headerlink" title="知识图谱的常见应用"></a>知识图谱的常见应用</h2><p>最常见的图谱的应用是搜索引擎，比如说我们搜索“腾讯的CEO是谁”，这个搜索的问句中，“腾讯”就是一个实体，“的CEO”是一种关系，而最后的关系指向了另一个节点。<br>再比如，在“天眼查”这个网站中，主要的节点是人和企业。之间就有从属，合作等关系。</p>
<p><img alt="image.png" data-src="https://i.loli.net/2020/09/02/EZscJfHzxNdIvwU.png"></p>
<h2 id="互联网大佬的布局"><a href="#互联网大佬的布局" class="headerlink" title="互联网大佬的布局"></a>互联网大佬的布局</h2><p>其实各个互联网公司也都开始做相关的研究，国内阿里和美团据称已经应用到推荐领域了。<br><img alt="image.png" data-src="https://i.loli.net/2020/09/02/hDFZodaVMc6xNs2.png"></p>
<h2 id="知识图谱的构建方式"><a href="#知识图谱的构建方式" class="headerlink" title="知识图谱的构建方式"></a>知识图谱的构建方式</h2><p>想构建一个完整的知识图谱并不容易。从结构化的数据中提取关系较为简单，但是高质量的结构话关系数据往往数据量小且难以得到。当我们去提取半结构化数据（XML和JSON）和非结构化数据（文本，图片）中提取关系就相对复杂很多。涉及到实体识别(Named Entity Recognition, NER)，实习分类，关系识别等数据提取的工作。以及之后的数据清洗，知识表示和推理。整体来说，想要一个“大而全”的知识图谱目前来说较为复杂，也是目前的一个瓶颈。<br><img alt="image.png" data-src="https://i.loli.net/2020/09/02/WxVEJbz5QqXdHjS.png"></p>
<h1 id="论文串讲"><a href="#论文串讲" class="headerlink" title="论文串讲"></a>论文串讲</h1><p>对于图谱，最直接的使用就是对于每一个节点，边都进行表征学习，最后输出Embedding来支持后面的其他业务。所以，如何进行图表征就是研究的重点。</p>
<h2 id="0-背景知识：知识图谱特征学习-Knowledge-Graph-Embedding"><a href="#0-背景知识：知识图谱特征学习-Knowledge-Graph-Embedding" class="headerlink" title="0. 背景知识：知识图谱特征学习(Knowledge Graph Embedding)"></a>0. 背景知识：知识图谱特征学习(Knowledge Graph Embedding)</h2><p>回顾一下word2vec中的“平行四边形”关系，我们可以发现“dring-&gt;drinking” 和 “swam -&gt; swaming” 之间的向量是平行的。但是在word2vec并没有直接的去学习这个“-&gt;”边的向量。<br><img alt="image.png" data-src="https://i.loli.net/2020/09/02/QDCSeO8VBzFdPki.png"><br>在图谱中，边也是需要进行向量化表征的。在研究中，已经诞生了很多表征的基本方法，如TransE, TransH , TransR , TransD , TransA , TransG , TranSparse等，他们都是对于向量表征的关系定义，感兴趣的同学可以详细了解。举两个具体的例子（如下图）。<br><img alt="image.png" data-src="https://i.loli.net/2020/09/02/NR7YvGfkT54yEwb.png"><br>在左边的TransE中，h 和 t都是节点，r是关系。而所有的向量都在同一个空间，h+r可以近似的表示t。<br>在左边的TransH中，h 和 t都是节点，h’d’是关系。节点向量的投影可以在平面上表示出关系。<br>在右边的TranR中，h 和 t都通过一个映射关系M，映射到关系空间内，可以恰好和关系r进行计算。<br>除此之外，还有一些其他的表示方法，都大同小异。 </p>
<h2 id="1-Collaborative-knowledge-base-embedding-for-recommender-systems-KDD-2016-Microsoft"><a href="#1-Collaborative-knowledge-base-embedding-for-recommender-systems-KDD-2016-Microsoft" class="headerlink" title="1. Collaborative knowledge base embedding for recommender systems KDD, 2016, Microsoft"></a>1. Collaborative knowledge base embedding for recommender systems KDD, 2016, Microsoft</h2><p>微软在2016年首次把知识图谱带入到了推荐系统中，也就是对于协同过滤引入了side-information。<br>物品的属性是一种结构化的数据，用简单的MLP并不能学习到它们之间的关联，从而无法全面的刻画一个物品。本文提出基于知识图谱的embedding来刻画物品的显式信息，这种是从图结构中学到的关联，能够比较充分地学习到物品的表达。本文关于物品的表达有三个部分，另外两个分别是文本信息和图片信息。<br><img alt="image.png" data-src="https://i.loli.net/2020/09/02/m1qxGtMu9SQRUyE.png"><br>如下图所示，知识图谱其实只是side-information中的一种，而其中结构化embedding使用刚刚介绍的TransR来求得，即将两个存在于实体空间的实体向量通过映射在关系空间的关系向量连接。<br><img alt="image.png" data-src="https://i.loli.net/2020/09/02/q43GVKk1HEXeh7t.png"><br>在引用了外部信息之后，当模型表现会优于现在的其他模型。<br><img alt="image.png" data-src="https://i.loli.net/2020/09/02/bWqEC9KDnv4az6i.png"></p>
<h2 id="2-Deep-knowledge-aware-network-DKN-2018-ShanghaiJiaoTongU"><a href="#2-Deep-knowledge-aware-network-DKN-2018-ShanghaiJiaoTongU" class="headerlink" title="2. Deep knowledge-aware network (DKN) 2018, ShanghaiJiaoTongU"></a>2. Deep knowledge-aware network (DKN) 2018, ShanghaiJiaoTongU</h2><p>第二篇是来源于上海交大的文章，针对于新闻推荐场景的。目前的新闻推荐系统有以下几个问题：</p>
<ol>
<li>无法建立知识层面的潜在链接</li>
<li>对用户的个性化推荐无法高时效性地动态适应</li>
</ol>
<p>本文在其中引入外部知识，提出了基于新闻内容和用户点击率的推荐系统：deep knowledge-aware network (DKN)。 其中有两个核心部分：一个是knowledge-aware convolutional neural network (KCNN)，该网络结合了语义信息和知识信息共同对新闻进行表示；另一部分是引入attention机制，根据用户历史点击和当前候选新闻进行用户点击率预测。</p>
<h3 id="method"><a href="#method" class="headerlink" title="method"></a>method</h3><p>DKN结构如下：<br><img alt="image.png" data-src="https://i.loli.net/2020/09/02/A2knNWecfEJVz6Q.png"></p>
<h3 id="知识提取"><a href="#知识提取" class="headerlink" title="知识提取"></a>知识提取</h3><p>本文首先将其中包含的实体抽取出来进行实体链接，进而得到该文章知识层面的表示。<br><img alt="image.png" data-src="https://i.loli.net/2020/09/02/SHbEaMAUrCwBzxc.png"><br>这里分为如下三步：</p>
<ol>
<li>从新闻内容提取实体，并进行实体链接</li>
<li>用文中包含的实体构建出一个子图，再对每一个实体从图谱中提取邻居实体（一跳范围）进行扩充</li>
<li>对子图做graph embedding， 可用方法有transE，transH等等</li>
</ol>
<p>由于即使graph embedding已经基本保留了知识图谱的结构信息，但是效果还是不够好，所以这里引入“上下文”信息做辅助。</p>
<p><img alt="[公式]" data-src="https://www.zhihu.com/equation?tex=context%28e%29%3D%5Cleft%5C%7Be_%7Bi%7D+%7C%5Cleft%28e%2C+r%2C+e_%7Bi%7D%5Cright%29+%5Cin+%5Cmathcal%7BG%7D+%5Ctext+%7B+or+%7D%5Cleft%28e_%7Bi%7D%2C+r%2C+e%5Cright%29+%5Cin+%5Cmathcal%7BG%7D%5Cright%5C%7D"></p>
<p>所谓“上下文”指节点的邻居节点集，如下图所示：<br><img alt="image.png" data-src="https://i.loli.net/2020/09/02/UjNiqS6d2u8LeRG.png"><br>每个节点的embedding就可以用它“上下文”节点embedding的均值来表示：</p>
<p><img alt="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Coverline+%7B%5Crm%7Be%7D%7D+%3D+%5Cfrac%7B1%7D%7B%7B%7C%7B%5Crm%7Bcontext%7D%7D%28e%29%7C%7D%7D%5Csum%5Climits_%7B%7Be_i%7D+%5Cin+%7B%5Cmathop%7B%5Crm+context%7D%5Cnolimits%7D+%28e%29%7D+%7B%7B%7B%5Crm%7Be%7D%7D_i%7D%7D++"></p>
<p>对于每个用户，有历史点击记录  <img alt="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Cleft%5C%7Bt_%7B1%7D%5E%7Bi%7D%2C+t_%7B2%7D%5E%7Bi%7D%2C+%5Cldots%2C+t_%7BN_%7Bi%7D%7D%5E%7Bi%7D%5Cright%5C%7D">  ，其中  <img alt="[公式]" data-src="https://www.zhihu.com/equation?tex=t_%7Bj%7D%5E%7Bi%7D">  表示用户点击的第条新闻的标题，  <img alt="[公式]" data-src="https://www.zhihu.com/equation?tex=t%3D%5Cleft%5Bw_%7B1%7D%2C+w_%7B2%7D%2C+%5Cldots%5Cright%5D">  是其中包括的词项。每个词项从语义角度都能找到一个word embedding，从知识角度有可能能在知识图谱中找到对应的实体，并得到entity embedding（流程如上节描述）。</p>
<h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><p><img alt="image.png" data-src="https://i.loli.net/2020/09/02/NA8kvgRQCy9VDaJ.png"></p>
<p>点   评：</p>
<ol>
<li>多通道的CNN词表示与实体表示来建模标题序列，能更好的建模词和实体之间的关系 👏      </li>
<li>DKN使用attention机制，赋予user历史不同的权重，能更好地刻画用户的兴趣😎（ Attention牛逼    </li>
<li>用了实体周围的一阶信息，丰满了Embedding的信息</li>
</ol>
<h2 id="3-RippleNet-Propagating-User-Preferences-on-the-Knowledge-Graph-for-Recommender-Systems-2018-ShanghaiJiaoTongU"><a href="#3-RippleNet-Propagating-User-Preferences-on-the-Knowledge-Graph-for-Recommender-Systems-2018-ShanghaiJiaoTongU" class="headerlink" title="3. RippleNet: Propagating User Preferences on the Knowledge Graph for Recommender Systems, 2018, ShanghaiJiaoTongU"></a>3. RippleNet: Propagating User Preferences on the Knowledge Graph for Recommender Systems, 2018, ShanghaiJiaoTongU</h2><p>第三篇同样来源于上海交大，且超越了前一篇。作者考虑到了第二篇中，既然用了一阶紧邻的节点对于中心节点进行表征可行，那也可以进行一个扩大范围。<br>考虑到水波(Ripple)的传播，以user感兴趣的item为seed，在商品知识图谱上向外一圈一圈的扩散到其他的item，这个过程称之为偏好传播(Preference Propagation)。</p>
<p>该模型认为外层的item同样属于用户的潜在偏好, 因此在刻画user时候，需要将其考虑进去，而不能仅仅使用观测到的items去表示user偏好。</p>
<p><img alt="image.png" data-src="https://i.loli.net/2020/09/02/vZFrkYmcuU5I12D.png"><br>模型的结构如下图。不断的向外扩展，来拟合残差。<br><img alt="image.png" data-src="https://i.loli.net/2020/09/02/65ETk4SFNnhJD1j.png"><br>最终的结果，超越了目前所有模型，包括DKN。<br><img alt="image.png" data-src="https://i.loli.net/2020/09/02/crmjHFnRTUhEJAD.png"></p>
<p>点   评：</p>
<ol>
<li>通过图的向外层层传播，来构造user Embedding的兴趣，可解释性非常强，很有创意 👏      </li>
<li>在多个Embedding传递的过程中，通过vRh的softmax，实现了类似Attention的功能</li>
<li>联合学习是端到端的方式，训练开销大，但是比较方便<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1></li>
<li>知识图谱，可以有效利用大量存在的先验知识，进而降低模型对于大规模样本的依赖</li>
<li>知识图谱，有更好的可解释性，通过Attention，可以解释用户对于item的具体哪个属性更喜欢</li>
<li>知识图谱，可以综合更多的信息，充分利用item的自身以及临阶属性<br>但是:</li>
<li>知识图谱目前仍然属于前沿(发展不成熟)，是否真正需要还需调研</li>
<li>音乐场景下，数据格式较为简单。通过关键词匹配，或者曲库标签，可以只花费20%的成本，实现80%的效果</li>
</ol>
<p>参考资料：<br><a href="https://tech.meituan.com/2018/11/22/meituan-brain-nlp-01.html" target="_blank" rel="noopener">https://tech.meituan.com/2018/11/22/meituan-brain-nlp-01.html</a><br><a href="https://zhuanlan.zhihu.com/p/131455882" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/131455882</a><br><a href="http://shomy.top/2019/03/19/kg-ns-recsys/" target="_blank" rel="noopener">http://shomy.top/2019/03/19/kg-ns-recsys/</a><br><a href="https://www.jianshu.com/p/ac4988c535ae" target="_blank" rel="noopener">https://www.jianshu.com/p/ac4988c535ae</a><br><a href="https://www.sohu.com/a/337458150_817016" target="_blank" rel="noopener">https://www.sohu.com/a/337458150_817016</a><br><a href="https://zhuanlan.zhihu.com/p/34919142" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/34919142</a><br><a href="https://blog.csdn.net/Sunflower_ke/article/details/89642009" target="_blank" rel="noopener">https://blog.csdn.net/Sunflower_ke/article/details/89642009</a><br><a href="https://www.jianshu.com/p/2e3cade31098" target="_blank" rel="noopener">https://www.jianshu.com/p/2e3cade31098</a><br><a href="https://www.jianshu.com/p/c5ffaf7ed449" target="_blank" rel="noopener">https://www.jianshu.com/p/c5ffaf7ed449</a><br><a href="https://www.leiphone.com/news/201709/kefvQPk1FMybCleb.html" target="_blank" rel="noopener">https://www.leiphone.com/news/201709/kefvQPk1FMybCleb.html</a><br><a href="https://zhuanlan.zhihu.com/p/62914401" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/62914401</a></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>知识图谱</tag>
      </tags>
  </entry>
  <entry>
    <title>如何把自己绑到新基建的火车上？</title>
    <url>/2020/new-construction/</url>
    <content><![CDATA[<blockquote>
<p>本文回顾近几十年发展过程，展望一下未来20年的发展方向。雷军说，站在风口，猪都能飞。既然大家都是猪，就要找好风口。</p>
</blockquote><p>国家发改委首次明确「新基建」范围，具体涵盖</p><ol>
<li>5G 基建</li>
<li>工业互联网</li>
<li>人工智能</li>
<li>大数据中心</li>
<li>高速公路轨道交通</li>
<li>新能源汽车充电桩</li>
<li>特高压</li>
</ol><a id="more"></a>


<p>这是10-20年内，国家万亿的投资渠道。我坚定的相信，无论把自己绑在国家发展的风口上的这些朝阳产业上，会发展的更好。先来回顾一下近几年的互联网发展历史。</p>
<h1 id="1990至今-互联网时代"><a href="#1990至今-互联网时代" class="headerlink" title="1990至今 互联网时代"></a>1990至今 互联网时代</h1><p>在旧工业革命时，我们的大清因为自大保守，没有赶上工业革命的快车。但是随着新中国成立和改革开放的这些年的追赶，和对于先进文化的学校，到了互联网时代，中美几乎处于同一起跑线，同时开跑。</p>
<p>美国有了雅虎，谷歌，Amazon，Microsoft。<br>而中国现在的互联网巨头也几乎都是2000年左右创办的。<br>网易： 1997年6月<br>搜狐： 1998年2月<br>京东： 1998年6月18日<br>腾讯： 1998年11月11日<br>新浪： 1998年12月<br>阿里： 1999年9月9日<br>美国的公司伴随着全球化的进展，迅速将互联网/软件市场全球化。相对于传统行业，互联网有着天然的快速传播，生产后即可享受最大化的边际收益，迅速发展。现在美国的巨头都成为了万亿级公司。而值得庆幸的是，中国这几家企随着国家的保护措施以及中文社区的天然壁垒，现在混得也可以相媲美。</p>
<p>回顾历史，只要是在20年前，有先见之明，投身于互联网时代，现在绝对是靠股票都能财富自由的人。</p>
<h1 id="2008至今-移动互联网2C"><a href="#2008至今-移动互联网2C" class="headerlink" title="2008至今 移动互联网2C"></a>2008至今 移动互联网2C</h1><p>iPhone的诞生，标志了智能手机的兴起。之后的3G，4G时代快速迭代，使得传统的互联网公司还没歇息，快速迈入移动互联网的蓝海之中。<br>传统巨头：</p>
<ul>
<li><strong>阿里</strong>迅速投入手机淘宝的研发，淘宝+支付宝的天然优势形成了自己的护城河。</li>
<li><strong>腾讯</strong>宁愿断掉手机QQ的大腿，也要制造一款纯净的移动互联网社交平台，微信。当然，微信的成功也让腾讯上了头等舱，为之后的游戏，广告等业务创造了土壤。</li>
<li><strong>新浪</strong>前期发展不是很了解，后期微博迅速拓展移动端，并且引入了明星，饭圈等内容生态，干翻了腾讯微博，留在了船上。</li>
<li><strong>网易</strong>虽然做的比较杂，但是手机游戏的自然增长也带了巨大的收益。</li>
<li><strong>搜狐</strong>和<strong>百度</strong>算是反应太慢，百度虽然也有尝试过外卖/以及推广百度app，但是单单外卖app和一个搜索引擎，没有绝对性的壁垒，最后外卖业务也凉了。</li>
</ul>
<p>当然，移动互联网也带来了更多新机遇。</p>
<ul>
<li>手机行业：<strong>小米，华为，蓝绿厂</strong>这几家最有代表性的厂商就是抓住了移动互联网的机遇。当然大浪淘沙，虽然赛道不错，但是那些跑不快的马(魅族，努比亚，天语，小辣椒，中兴等)确实死在了沙滩上。最值得遗憾的就是传统巨头诺基亚和摩托诺拉没有及时调整方向，直接被挤下了赛道。</li>
<li>直播：4g的普及使得观众和主播随时可以在手机上完成互动，直播行业曾经千帆竞技，最后大浪淘沙，现在<strong>斗鱼，YY，虎牙</strong>通过运营跑赢杀到最后。</li>
<li>外卖：外卖行业需要结合线下，而且容易形成壁垒。美团，饿了么，百度，滴滴血拼到最后，<strong>腾讯控股美团，阿里控股饿了么</strong>，形成了平衡。</li>
<li>短视频：短视频也从千帆竞技到两分天下，最后<strong>抖音、快手</strong>两家基于推荐算法的公司跑到最后。虽然腾讯，b站也都开始发展自己的短视频，但是由于入场晚，没有“基因”，微视依然不瘟不火。【值得一提的是抖音母公司<strong>字节跳动</strong>发展迅速，凭借着成功经验疯狂生产不同的app，形成了app矩阵，用人海拼概率，总有儿子有出息。并且不断的迭代出海市场，Tiktok成为了全球化的短视频平台。而且有了Tiktok的经验，我看好字节跳动在海外市场的发展】</li>
<li>移动支付：其实移动支付虽然前期竞争猛烈，但实际上还是<strong>阿里和腾讯</strong>在跑马圈地，最后二分天下。移动支付的门槛太高，银联有着天然的资源优势，玩到最后都难以抗衡。</li>
<li>社交电商：社交电商唯一nb的代表就是<strong>拼多多</strong>，完全放弃pc端，只做移动端，靠社交电商能超过京东，和淘宝抗衡，拼多多真的很强。当然，拼多多的成功还有很多其他因素，比如淘宝对于中小商户的挤压，物流成本的降低，对准了下沉时长，等等等等。拼多多现在2020.05.22的股价已经是$68了，太顶了。上市十几块到现在市值翻了三四倍。</li>
<li>移动打车：<strong>滴滴快滴</strong>血拼，挤掉对手，最后合并，垄断市场。经典的故事，不多说了。</li>
</ul>
<h1 id="2015至今-产业互联网2B"><a href="#2015至今-产业互联网2B" class="headerlink" title="2015至今 产业互联网2B"></a>2015至今 产业互联网2B</h1><ul>
<li>产业互联网基础—云计算</li>
</ul>
<p>互联网2B最直观的感受就是各类云计算市场的崛起。云计算市场也有着国家的安全保护的战略意义，国内三家巨头享受到了红利。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200524125047.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>2015年无论对于投资界，BAT等科技巨头，或者中小型创新企业，面向B端市场的企业级服务受到重视，其中人工智能、大数据、云计算等主要面向企业级服务的互联网基础设施成为科技巨头的布局重点。</p>
<ul>
<li><p>在这方面，阿里起步较早，阿里云在2016年都高调表态，强势进军云计算平台，再结合淘宝本身的自身需求，对于高频发高计算的技术积累，在数据库和弹性计算上都有了迅猛增长。就在2020的5月，也就是前几天，阿里云年收入破四百亿。实属吓人。阿里云现在也开始着力发展海外业务，与老牌的AWS，Google Cloud开始抗衡。做到了亚太第一。</p>
</li>
<li><p>腾讯云起步较晚，但是发力迅猛，各种活动的促销，也抢来了一大块蛋糕。2019年全年应收170亿，付费用户超过100万。</p>
</li>
<li><p>百度虽然在移动互联网发展的不好，但是百度云的发展也还可以。尤其是在ai算法方法发力充足，百度的飞浆深度学习框架虽然和TF，pytorch还有着明显差距，但是国内已经有人开始使用了。在算法上的沉淀，确实给百度带来了一定的市场。</p>
</li>
<li><p>除此之外的还有华为云，七牛云等小的计算平台。</p>
</li>
</ul>
<p>当然，除了计算，产业互联网更多的应用场景需要具体的去优化和抽象，这也就之后十年的发展方向。</p>
<h1 id="新基建对于从业者"><a href="#新基建对于从业者" class="headerlink" title="新基建对于从业者"></a>新基建对于从业者</h1><p>回归历史，雷军的那句话真很对。<code>站在风口，猪都能飞</code>，如何选择风口就太重要了。而新基建我觉得是一个简单粗暴的选择方式，十万亿的发展空间对于任何一个行业都有直接的刺激。</p>
<p>过去二十年的国家基础建设主要是房地产，铁路等。铁路普通人无法投资，但是一大批人通过炒房/提前购买，实现了财富的增长，抛开对于社会的影响，这些人确实改善了自己的生活的目的。</p>
<p>现在回到正题，新基建对于我们来说，该如何选择？如何把自己绑到新基建的火车上？</p>
<ul>
<li>简单回答：<strong>投资</strong>。<br>从事相关行业，力量投资；购买相关股票，价值投资。<br>价值投资不必多说，就买各个领域的龙头股票，等待稳定收益。</li>
</ul>
<p>力量投资就得结合自身的专业特长去考虑：<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200524132125.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>图来自<a href="https://www.bilibili.com/video/BV1H7411y7Hh" target="_blank" rel="noopener">所长林超</a><br>对于每个领域多说两句：</p>
<ol>
<li>5G 基建<br> 上游通信，纯工业，包括数字电路，芯片，天线，系带，运营线等。下游则是5G带来的新应用，包括内容(4K,VR)平台，云游戏平台，自动驾驶等等，以及需要大量的相应的内容创作者(网红)。虽然传统巨头必然会转型，但是绝对会爆发出一些新的明星公司。</li>
<li>工业互联网<br> 工业互联网是个难啃的骨头，因为需要不断的对于传统行业的痛点进行深耕，找到解决方案，然后抽象方案，形成自己的体系。阿里也有“工业大脑”，华为也有“智慧大脑”。但是这里我看好某些做垂直行业的小型公司崛起，只有深挖到生产的每一步才能做好。</li>
<li>人工智能<br>人工智能是个虚词，不落到具体的应用，技术会显得一文不值。这几年的CV和NLP的发展，确实落地了具体的应用，比如人脸识别，车牌识别，图像修复增强；骚扰电话机器人，机器翻译，搜索引擎的智能，语音助手等。如果能诞生一个新的具体的应用场景，就能杀入市场，盘活技术。</li>
<li>大数据中心<br>主要也被云计算平台包揽了。</li>
<li>高速公路轨道交通 &amp; 6. 新能源汽车充电桩 &amp; 7. 特高压<br>关于最后几点，我不太了解，都是纯工业的方向。虽然石油价格的下跌也缺失造成了一定的阻力，我相信电动车行业是发展方向，适合长期投资。</li>
</ol>
<p>总的来说，如果你和我一样是计算机相关专业，那去坚定地去从事互联网行业，如果想发展的更好，就坚定地去产业/工业互联网的这样toB的产业。不断的成为一个垂直细分领域的专家，身价只会随着年龄越来越高。</p>
<p>对于更有梦想的同学来说，就可以考虑不断的积累经验，等待机会。在3-5年后，一旦爆发了新的媒体形式，新的交互模式。必然会诞生像小红书，抖音，bilibili这样新的PUGC平台型娱乐工具，而平台的增长是非常快速的，可能三四年就能实现上市。<br><strong>你需要做的就是准备好人脉，储备好技术，提前入场，努力垄断，干翻对手。一将功成万骨枯。</strong></p>
<blockquote>
<p>本文并未查阅资料，纯属白日做梦，大家看看就好。</p>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title>【分析整理】 58同城多业务融合推荐实践与思考</title>
    <url>/2020/%E3%80%90%E5%88%86%E6%9E%90%E6%95%B4%E7%90%86%E3%80%91/</url>
    <content><![CDATA[<blockquote>
<p>平衡业务策略与模型之间的关系。策略能力有限，模型也“没有银弹”。</p>
</blockquote><p>最近刚好在研究策略和多样性的关系，就帮DataFunTalk社区又整理了一篇稿子，策略本身很乏味，但是策略可以解决很多模型解决不了的问题。<br>为什么会这样呢？主要还是模型太笨了，由于模型不能完全动态的掌握用户的心理变化，兴趣变化，所以一般的推荐模型都是对于用户的基于历史的点击率CTR预估，可以简化为分类或者回归模型。可是实际上，远远没有这么简单。我觉得最接近”智能化的推荐“的算法就应该是强化学习，算法推出一个item就是一次尝试，用户的行为会及时让系统收到反馈，无论是”多样性“，”准确性“，”兴趣偏好“，”负反馈“，统统都会被融合到Agent的激励里。之后有空了希望进一步调研强化学习在推荐的瓶颈。<br>以下为分享内容。</p><a id="more"></a>

<hr>
<p><img alt="5.《多业务融合推荐实践与思考》——58同城推荐分享.王炜.可发布版本.20200426(1)_page-0001.jpg" data-src="https://i.loli.net/2020/06/14/lhQZtX3sSngG2Ma.jpg"><br>本文主要介绍了58同城在推荐场景的重排优化部分，主要通过“用户兴趣优化&amp;重排”，“业务流量分配机制”，“动态刷新机制”三个方面，实现了重排的策略。最终的业务指标有明显提升。</p>
<ul>
<li>推荐系统整体架构</li>
<li>场景介绍</li>
<li>重排优化  <ul>
<li>用户兴趣优化&amp;重排</li>
<li>业务流量分配机制 </li>
<li>动态刷新机制</li>
</ul>
</li>
<li>总结与后续规划 Q&amp;A</li>
</ul>
<h1 id="推荐系统整体架构"><a href="#推荐系统整体架构" class="headerlink" title="推荐系统整体架构"></a>推荐系统整体架构</h1><p><img alt="5.《多业务融合推荐实践与思考》——58同城推荐分享.王炜.可发布版本.20200426_1__page-0005.jpg" data-src="https://i.loli.net/2020/06/14/DX8tzx6kUBHOC9y.jpg"></p>
<ul>
<li>最上面是系统的对外接口层，包括到58的各个业务的推荐接口的输出，以及负反馈的输入。</li>
<li>中间是业务逻辑层，包括兴趣服务，召回服务，排序服务，解释服务，abtest服务等。</li>
<li>底层是算法层，包括业务数据，日志数据，召回逻辑，排序逻辑，算法平台等。</li>
</ul>
<h1 id="场景介绍"><a href="#场景介绍" class="headerlink" title="场景介绍"></a>场景介绍</h1><p><img alt="5.《多业务融合推荐实践与思考》——58同城推荐分享.王炜.可发布版本.20200426_1__page-0007.jpg" data-src="https://i.loli.net/2020/06/14/AN4cnvVtz5XLiPh.jpg"><br>本文主要优化的是58同城的首页信息流，这个业务场景的特点有：</p>
<ol>
<li>强兴趣：大部分用户都是带着自己的需求进入app；不同的兴趣周期有所差异，比如租房周期短，买房周期长。</li>
<li>多业务：首页的访问量较大(千万级别pv)，如何把流量分配给不同的业务就很关键。</li>
<li>推荐感知：虽然用户的目标单一，但是如何做到推荐结果的多样性就需要对其优化。</li>
</ol>
<p><img alt="5.《多业务融合推荐实践与思考》——58同城推荐分享.王炜.可发布版本.20200426_1__page-0008.jpg" data-src="https://i.loli.net/2020/06/14/gUnY8pR7ml2Vefa.jpg"><br>58现有的召回和排序逻辑与业内同行保持一致，所以本次分享主要结合业务策略在重排层的实验结果。虽然看起来不高大上，但是简单实用。希望能给同行带来启发，减少试错成本。</p>
<p><img alt data-src="https://i.loli.net/2020/06/14/4gOlfupJABNXE3y.jpg"><br>58app首页推荐业务(多品类推荐)主要面临的挑战在于：</p>
<ol>
<li>如何满足用户对于不同品类的兴趣？（用户兴趣问题）</li>
<li>推荐的业务比例如何和平台的业务比例进行匹配？（流量分配）</li>
<li>是推荐单一品类效果好，还是推荐不同品类的混排？（混排策略）</li>
<li>如何平衡CTR和多样性？（动态刷新机制）</li>
</ol>
<h1 id="重排优化"><a href="#重排优化" class="headerlink" title="重排优化"></a>重排优化</h1><h2 id="用户兴趣优化-amp-重排"><a href="#用户兴趣优化-amp-重排" class="headerlink" title="用户兴趣优化&amp;重排"></a>用户兴趣优化&amp;重排</h2><p><img alt="5.《多业务融合推荐实践与思考》——58同城推荐分享.王炜.可发布版本.20200426_1__page-0012.jpg" data-src="https://i.loli.net/2020/06/14/sJcAyldFmDR3e9P.jpg"><br>业界常见的推荐系统都是要建立user和item之间的联系，还需要建立58的toC和toB之间的链接。<br><img alt="5.《多业务融合推荐实践与思考》——58同城推荐分享.王炜.可发布版本.20200426_1__page-0013.jpg" data-src="https://i.loli.net/2020/06/14/JwV1oisNHY6uICQ.jpg"><br>建立联系的过程就是对于user和item分别建立标签体系，然后对其匹配。对于user打标签需要长期的用户画像，也需要短期的兴趣。在供需方各自提供的需求中抽取出标签之后，进行匹配。<br><img alt="5.《多业务融合推荐实践与思考》——58同城推荐分享.王炜.可发布版本.20200426_1__page-0014.jpg" data-src="https://i.loli.net/2020/06/14/4pjM9w3vl28oHLE.jpg"><br>（通过用户的行为日志），得到了用户的兴趣之后，对于原始兴趣直接进行推荐效果并不理想。 所以有以下的问题：</p>
<ul>
<li>时效性的及时满足：对于58的业务来说，需要及时捕捉用户兴趣的变化，才能推荐出满足当下需求的item。</li>
<li>兴趣分层：不同兴趣的优先级和占比需要进行优化。</li>
<li>兴趣去噪：对于用户太旧的兴趣需要考虑丢弃去噪。</li>
<li>向量化兴趣(TODO)：从标签的兴趣，逐渐过滤到向量化的兴趣。通过对于用户画像/兴趣的Embedding进行召回。</li>
</ul>
<p><img alt="5.《多业务融合推荐实践与思考》——58同城推荐分享.王炜.可发布版本.20200426_1__page-0015.jpg" data-src="https://i.loli.net/2020/06/14/9yNPpLzGM43IAVw.jpg"><br>用户兴趣和画像系统主要包括以上的方面，接下来详细介绍。</p>
<p><img alt="5.《多业务融合推荐实践与思考》——58同城推荐分享.王炜.可发布版本.20200426_1__page-0016.jpg" data-src="https://i.loli.net/2020/06/14/nqfkNiyvm6AS58t.jpg"></p>
<ol>
<li>数据抽取：对用户的点击进行埋点，对用户的购买/转化行为进行埋点。<br><img alt="5.《多业务融合推荐实践与思考》——58同城推荐分享.王炜.可发布版本.20200426_1__page-0017.jpg" data-src="https://i.loli.net/2020/06/14/OneN6xWoVd2rRFl.jpg"></li>
<li>数据清洗：去除掉无意义的数据，补充缺失数据。<br><img alt="image.png" data-src="https://i.loli.net/2020/06/14/NQ69fyZsoVMRtix.png"></li>
<li>兴趣分类：通过时间戳区分用户的长期/中期/临时兴趣。比如一个用户几个兴趣前在找工作，到现在找工作的需求可能已经解决了，目前就需要找租房了。<br><img alt="5.《多业务融合推荐实践与思考》——58同城推荐分享.王炜.可发布版本.20200426_1__page-0019.jpg" data-src="https://i.loli.net/2020/06/14/Y3XSlPGupNrw8my.jpg"></li>
<li>兴趣计算：对于兴趣进行分类之后，就需要对于数据进行存储和打通线上调用接口的服务。<br><img alt="5.《多业务融合推荐实践与思考》——58同城推荐分享.王炜.可发布版本.20200426_1__page-0020.jpg" data-src="https://i.loli.net/2020/06/14/Vw1y4Wbnu6ShaZ2.jpg"></li>
<li>兴趣衰减的公式如图，一般来说最好可以通过线上的ab实验确定自己业务的衰减参数；再者可以做的更细，对于不同的兴趣得到不同的时间衰减参数。通过时间衰减，可以解决用户近期的兴趣和实时兴趣权重上升；久远的兴趣权重会下降。<br>其它思路: (1)不同业务需求，衰减公式或参数不同，衰减快慢不同; (2)实时与历史兴趣，短期与长期兴趣，衰减快慢不同。<br><img alt="  .jpg" data-src="https://i.loli.net/2020/06/14/ZN3rvixfcEUHug4.jpg"></li>
<li>兴趣合并：</li>
</ol>
<ul>
<li>可以对不同时间维度的兴趣进行合并。</li>
<li>也可以对不同领域的兴趣进行合并，得到用户画像。可以用于兴趣的专业和试探，用于增加多样性。<br><img alt="5.《多业务融合推荐实践与思考》——58同城推荐分享.王炜.可发布版本.20200426_1__page-0023.jpg" data-src="https://i.loli.net/2020/06/14/Acd6fDG4aIWzNRV.jpg"></li>
</ul>
<ol>
<li><p>兴趣聚合<br>数据统计会发现，虽然大部分用户只关注个别价格区间，但是有一批用户会关注多个汽车的价格区间，导致推荐的分散，效果并不理想。可以采用“优势组直选策略”选取权重最大(浏览最多的)策略，保留一个区间；或者是“长尾组淘汰策略”，排除掉权重小的几个区间。</p>
</li>
<li><p>兴趣去噪<br><img alt="5.《多业务融合推荐实践与思考》——58同城推荐分享.王炜.可发布版本.20200426_1__page-0025.jpg" data-src="https://i.loli.net/2020/06/14/DaR5THXbS4GqoVc.jpg"><br>兴趣去噪和兴趣聚合原理一样，去除掉“用户误点”，“客户端误报”，等噪音数据。</p>
</li>
<li>兴趣扩展<br><img alt="5.《多业务融合推荐实践与思考》——58同城推荐分享.王炜.可发布版本.20200426_1__page-0026.jpg" data-src="https://i.loli.net/2020/06/14/T1yAc7YuXHlxnjW.jpg"><br>兴趣扩展就是当用户的召回较少时，逐层增加兴趣的边界，经过实验，一般增加扩展会导致点击率下降，所以也需要调整和平衡。</li>
</ol>
<p>扩展的方式如图，可以是品内标签的横向扩展。从用户选择的一个点，向外发散，从而召回更多的item。也可以是跨品类的扩展，从最小类目扩展到二级类目。用户有了更多的选择，也接近自己的倾向。实验的点击率有所提高。<br>从表格中，可以看出相关扩展和范扩展点击率都不会很好，所以需要分层，优先满足原始兴趣。<br><img alt="image.png" data-src="https://i.loli.net/2020/06/14/8yZkfmRSYHBN4Jq.png"></p>
<p>举个例子：从地图上的一个点，就可以按照距离向外扩展；向类似接近的品类进行扩散。</p>
<p><img alt="5.《多业务融合推荐实践与思考》——58同城推荐分享.王炜.可发布版本.20200426_1__page-0028.jpg" data-src="https://i.loli.net/2020/06/14/j2OanEkCW6KAPdw.jpg"></p>
<ol>
<li>兴趣排序<br>对于召回源的权重进行排序，从而满足较大权重的兴趣排到前面。这里，由于我们的场景是强兴趣的，所以主要的召回渠道仍然是兴趣的召回。希望对场景类似的朋友有所帮助。</li>
</ol>
<h2 id="重排优化—业务流量分配策略"><a href="#重排优化—业务流量分配策略" class="headerlink" title="重排优化—业务流量分配策略"></a>重排优化—业务流量分配策略</h2><p>对于58的混合推荐场景来说，对于推荐结果来说，对于用户来说，需要给出用户需要的推荐结果；对于平台来说，也需要对于不同的业务都给予一定比例的曝光分流。</p>
<ol>
<li>为什么要持续优化流量分配策略?<br>首页推荐哪些业务线的帖子需要为分流这个重要目的服务。比如：58上的整租房的帖子高于合租房的帖子，所以就需要推荐出来的整租的帖子也高于合租的帖子。</li>
</ol>
<ol>
<li>本次优化以前，原策略对各业务的分配策略有以下问题:<br>(1)品类之间平均分配，未考虑权重;<br>(2)大品类与小品类之间的冲突、重叠。</li>
</ol>
<p>针对以上的问题，我们做了以下的实验策略对比：<br>原始策略：</p>
<ol>
<li>直接采用精排结果序列。—-缺点在于：以CTR为学习评价目标，所以热门的item比例过大，大部分用户的结果趋同。</li>
<li>按照item的比例分配流量。假设58平台流量在大的品类上，占比如下: 招聘:租房:二手车:本地服务 = 40:30:20:10。每个用户都按上面的比例分配。—-缺点在于：每个用户之间的需求差异不明显，给每个用户都推相同比例的不合理。</li>
</ol>
<p>所以，我们进行了以下策略，既保证个性化需求，也保证了业务的流量分发的合理。<br>实验策略：<br><img alt="image.png" data-src="https://i.loli.net/2020/06/14/Dg57QVoZnJNycH6.png"><br>比如说，用户的兴趣比例如（1），而召回的比例如（2），就需要通过强插入黄页的其他item，补足缺口。<br><img alt="image.png" data-src="https://i.loli.net/2020/06/14/K4WqiRGt17SnvdM.png"><br>采用这种策略，可以保证分发的比例与大盘比例一致。这个问题类似于在新闻推荐里，有文章/视频/短视频，如果用停留时长作为评价指标，推荐出来的视频往往是长视频和长文章。这时候就需要进行比例调整，合理分配。<br><img alt="image.png" data-src="https://i.loli.net/2020/06/14/RF3KPuZbeoMDhi7.png"><br>在最后的重排阶段，也会对候选的item进行打散，避免相同类型的item过于聚集，增加了多样性。<br><img alt="image.png" data-src="https://i.loli.net/2020/06/14/MsyxV5kAjHrpOuN.png"><br>重排还有一种机制就是把当下的实时兴趣优先排出来，让推荐系统强感知用户的实时兴趣。</p>
<h2 id="动态刷新机制"><a href="#动态刷新机制" class="headerlink" title="动态刷新机制"></a>动态刷新机制</h2><p>常见的推荐系统，用户用的越久，推荐的越窄，这就涉及了多样性的问题。而一般来说，增加了多样性就会涉及CTR的下降。我们采用了一种动态化刷新机制方案，整理来说多样性增加CTR也没有下降。</p>
<ol>
<li>为什么需要动态化刷新机制?<br>目的: 解决内容多样性问题。</li>
<li>优化思路:<br>可以通过协同过滤、向量化召回等多路召回的办法增加多样性。<br>但在我们面临的问题是召回集合基本不变的前提下，优先考虑在集合内部的排序上进行动态调整。</li>
</ol>
<p>最终上线的版本如下：<br><img alt="image.png" data-src="https://i.loli.net/2020/06/14/PDyuYHlwA74pOgn.png"><br>通过对于多次曝光的item进行降低排序位置，避免用户反复看到已经浏览的item。<br><img alt="image.png" data-src="https://i.loli.net/2020/06/14/xw2W4y3bTvjV1kS.png"><br>再引入时间衰减，近期多次帖子会更强的打压，远期的浏览曝光就进行衰减，逐步恢复正常排序。<br><img alt="image.png" data-src="https://i.loli.net/2020/06/14/p4Uf8Fq91OvgVNt.png"><br>服务端的下发日志和客户端的曝光日志比不一定是真实曝光，但是响应更快，也可以考虑加到曝光打压中，可以进行综合考量。</p>
<ol>
<li>整体效果: (1)以上3步迭代的整体效果:点击率比基准提升+7.0%。</li>
</ol>
<p>(2)同一用户最新访问的帖子集合较前一次访问的集合的动态变化比率 全天平均达到60%。</p>
<ol>
<li>近期规划:<br>(1)引入全站的曝光日志，进一步优化刷新机制。<br>(2)引入用户的点击日志，通过再营销等策略，进一步优化效果。</li>
</ol>
<p>总结：<br>1.关键是理解业务。<br>2.优化策略之间的冲突、叠加。<br>3.多目标之间的平衡。<br>4.算法与策略之间的关系。</p>
<p>后续规划 ：<br>1.动态化刷新机制的进一步优化<br>2.首页推荐理由的进一步优化<br>3.冷启动的进一步优化<br>4.基于feed流机制的访问模式<br>5.深度学习模型的持续优化</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
  </entry>
  <entry>
    <title>MSBD5004 Mathematical Methods for Data Analysis Homework 5</title>
    <url>/2020/MSBD5004-Mathematical-Methods-for-Data-Analysis-Homework-5/</url>
    <content><![CDATA[<blockquote>
<p>5004完结撒花🌸🌸ヽ(°▽°)ノ🌸🌸.</p>
</blockquote><h1 id="Q1"><a href="#Q1" class="headerlink" title="Q1"></a>Q1</h1><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200509220809.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p><script type="math/tex; mode=display">
\begin{aligned}
&if \ n=0,\ c_0 =\int_{-\frac{1}{2}}^{\frac{1}{2}} t \exp (0) d t=0\\
&if \ n\not=0,\ c_n =\int_{-\frac{1}{2}}^{\frac{1}{2}} t \exp (-2 i \pi k t) d t=\frac{i(\pi n \cos (\pi k)-\sin (\pi n))}{2 \pi^{2} n^{2}}=\frac{(-1)^ni}{2\pi n}\\
\end{aligned}</script><a id="more"></a>

<script type="math/tex; mode=display">
So, \ f(t) = \sum_{k\not=0} \frac{(-1)^ni}{2\pi n} e^{2\pi i n t}</script><p>◾</p>
<h1 id="Q2"><a href="#Q2" class="headerlink" title="Q2"></a>Q2</h1><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200509222100.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<script type="math/tex; mode=display">
\begin{aligned}
&if \ n=0,\ c_0 =\int_{-\frac{1}{2}}^{\frac{1}{2}} t^2 \exp (0) d t=\frac{1}{12}\\
&if \ n\not=0,\ c_n =\int_{-\frac{1}{2}}^{\frac{1}{2}} t^{2} \exp (-2 i \pi n t) d t=\frac{\left(\pi^{2} n^{2}-2\right) \sin (\pi n)+2 \pi n \cos (\pi n)}{4 \pi^{3} n^{3}}=\frac{(-1)^n}{2\pi^2 n^2} \\
&So, \ f(t) =\frac{1}{12} +\sum_{n\not=0} \frac{(-1)^n}{2\pi^2 n^2}  e^{2\pi i n t}\\
&Use\ fourier\ teansform, \\
&1/80=\int_{-\frac{1}{2}}^{\frac{1}{2}} (t^2)^2dt=\frac{1}{12^2}+\sum_{n\not=0} \frac{1}{4\pi^4 n^4}  \\
&\sum_{n=2}^{\infty} \frac{1}{ n^4}=\frac{\pi^4}{90}-1
\end{aligned}</script><p>◾</p>
<h1 id="Q3"><a href="#Q3" class="headerlink" title="Q3"></a>Q3</h1><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200509234833.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<script type="math/tex; mode=display">
g(t)=\left\{\begin{array}{cc}
1, & |t| < 1 \\
0, & \text { otherwise }
\end{array}\right.</script><p>◾</p>
<h1 id="Q4"><a href="#Q4" class="headerlink" title="Q4"></a>Q4</h1><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200509235212.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<script type="math/tex; mode=display">
\begin{aligned}
\hat{f}(s)&=\int_{-\infty}^{\infty} f(t) e^{-2 \pi i s t} d t=\int_{-1}^{1} f(t)e^{-2 \pi i s t} dt\\
&=\int_{-1}^{0} (1+t)e^{-2 \pi i s t} dt\ +\ \int_{0}^{1} (1-t)e^{-2 \pi i s t} dt \\
&= \frac{\sin^2 (\pi s)}{\pi^2 s^2}\\
&=sinc^2(s)
\end{aligned}</script><p>◾</p>
<h1 id="Q5"><a href="#Q5" class="headerlink" title="Q5"></a>Q5</h1><ol>
<li>Compute the Discrete Fourier Transform of [1 1 2 2]T.</li>
</ol>
<script type="math/tex; mode=display">
\mathbf{X}=\left(\begin{array}{cccc}
1 & 1 & 1 & 1 \\
1 & -i & -1 & i \\
1 & -1 & 1 & -1 \\
1 & i & -1 & -i
\end{array}\right)\left(\begin{array}{c}
X_{0} \\
X_{1} \\
X_{2} \\
X_{3}
\end{array}\right)=\left(\begin{array}{c}
6 \\
-1+i \\
0 \\
-1-i
\end{array}\right)</script><p>◾</p>
<h1 id="Q6"><a href="#Q6" class="headerlink" title="Q6"></a>Q6</h1><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200509235256.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<script type="math/tex; mode=display">
\begin{aligned}
A_{N}(f * g)&=\sum_{m=0}^{N-1}[(f * g)(m)]e^{\frac{-2\pi imn}{N}} \\
&=\sum_{m=0}^{N-1}[\sum_{n=0}^{N-1}f(n)g(m-n)]e^{\frac{-2\pi imn}{N}} \\
&=\sum_{n=0}^{N-1}f(n)\sum_{m=0}^{N-1}g(m-n)e^{\frac{-2\pi i(m-n)n}{N}}e^{\frac{-2\pi in^2}{N}} \\
&=\sum_{n=0}^{N-1}f(n)e^{\frac{-2\pi in^2}{N}}\sum_{m=0}^{N-1}g(m-n)e^{\frac{-2\pi i(m-n)n}{N}} \\
&=\left(A_{N} f\right) \cdot\left(A_{N} g\right)\\
\end{aligned}</script><p>◾</p>
<h1 id="Q7"><a href="#Q7" class="headerlink" title="Q7"></a>Q7</h1><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200509235307.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<p>Suppose length of f is N: $f=\{f[0],f[1],…,f[N-1]\}$<br>Then </p>
<script type="math/tex; mode=display">F(f)_k=\sum_{n=0}^{N-1} f[n] e^{\frac{-j 2 \pi k n}{N}}=\sum_{n=0}^{N-1} f[n] W^{n k}=f[0]+f[1] W^{k}+f[2] W^{2 k}+\cdots+f[N-1] W^{(N-1) k}</script><p>here $W=-\frac{2\pi i}{N}$.<br>$\tau(f)$ is a circular right shifted signal by 1 unit. Then $\tau(f)$ is $\tau(f)=\{f[N-1], f[0], f[1], \cdots,f[N-2]\}$<br>The DFT of $\tau(f)$ by definition is :</p>
<script type="math/tex; mode=display">F(\tau(f))_k=\sum_{n=0}^{N-1} \tau(f)[n]e^{\frac{-j 2 \pi k n}{N}}=\sum_{n=0}^{N-1} \tau(f)[n] W^{n k}=f[N-1]+f[0] W^{k}+f[1] W^{2 k}+\cdots+f[N-2] W^{(N-1) k}</script><p>Now use the property that $W^kW^{(N-1)k}=1$, and rewrite the $F(\tau(f))_k$</p>
<script type="math/tex; mode=display">\begin{aligned}
F(\tau(f))_k&=\sum_{n=0}^{N-1} \tau(f)[n]e^{\frac{-j 2 \pi k n}{N}}\\
&=\sum_{n=0}^{N-1} \tau(f)[n] W^{n k}\\
&=W^kW^{(N-1)k}\left[ f[N-1]+f[0] W^{k}+f[1] W^{2 k}+\cdots+f[N-2] W^{(N-1)k}\right] \\
&=W^k\left[ f[N-1]W^{(N-1)k}+f[0]+f[1] W^{k}+\cdots+f[N-2] W^{(N-2)k}\right]\\
&=W^k\tau(f)=e^{-\frac{2\pi ik}{N}}\tau(f)_k
\end{aligned}</script><p>So the relation is $F(\tau(f))=e^{-\frac{2\pi ik}{N}}\tau(f)$.<br>◾</p>
<blockquote>
<p>有的地方我省略了，不懂的话私信。</p>
</blockquote>
]]></content>
      <categories>
        <category>5004</category>
      </categories>
  </entry>
  <entry>
    <title>CS224n-12 Subword Models 解决OOV问题</title>
    <url>/2020/CS224n-12/</url>
    <content><![CDATA[<ul>
<li>Subword Models 解决OOV问题</li>
</ul><p>OOV： out-of-vocabulary即单词不在词汇库里的情况<br>之前的模型都是基于单词层面的，但是对于一个新单词“asd”没有解决方案。一个朴素的想法就是“拆分”，把长单词拆成几个单词的组合。相对于中文来说，就是一个新的词组去按照每个字的意思去理解单词的意思。<br>下面是解决方案。</p><a id="more"></a>

<h1 id="Character-Level-Model"><a href="#Character-Level-Model" class="headerlink" title="Character-Level Model"></a>Character-Level Model</h1><ul>
<li>字符级别操作，直接把每个字母当做基本单元，然后训练单词的Embedding。</li>
</ul>
<p>但是其输入的序列更长了，使得数据更稀疏且长程的依赖关系更难学习，训练速度也会降低。下面是几种具体的方案。</p>
<h2 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h2><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200502235959.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>CNN相当于把连续的几个字符，全部枚举，拼起来，然后Embedding。</p>
<h2 id="BLSTM"><a href="#BLSTM" class="headerlink" title="BLSTM"></a>BLSTM</h2><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200502235847.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>双向RNN遍历字符，直接输出Embedding，简单粗暴。</p>
<h2 id="字母单词同时Embedding"><a href="#字母单词同时Embedding" class="headerlink" title="字母单词同时Embedding"></a>字母单词同时Embedding</h2><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200503000654.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>详细介绍：<a href="https://www.hankcs.com/nlp/cs224n-character-aware-neural-language-models.html" target="_blank" rel="noopener">https://www.hankcs.com/nlp/cs224n-character-aware-neural-language-models.html</a><br>字符级别的CNN+Highway Network可以提取丰富的语义和结构信息。这个模型将其他网络当成积木一样，构建了更好的语言模型。</p>
<h2 id="LSTM-BGRU"><a href="#LSTM-BGRU" class="headerlink" title="LSTM+BGRU"></a>LSTM+BGRU</h2><p>和上面那个好像。<br><a href="https://arxiv.org/abs/1610.03017" target="_blank" rel="noopener">Fully Character-Level Neural Machine Translation without Explicit Segmentation</a>中利用了多层的convolution, pooling与highway layer来解决这一问题，其中encoder的结构如下图所示：</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200502235621.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<p>输入的字符先被映射到character embedding。然后与窗口大小不同的卷积核进行卷积操作再将输出联结起来，例如上图中有三种窗口大小分别为3，4，5的卷积核，相当于学习了基于字符的trigram, 4-grams, 5-grams。然后对卷积的输出进行max pooling操作，相当于选择最显著的特征产生segment embedding。由此我们从最基础的输入的character embedding得到了系统中认为语言学上有意义的segment embedding。然后将这些特征经过Highway Network(有些类似于Residual network，方便深层网络中信息的流通，不过加入了一些控制信息流量的gate）和双向的GRU，这样得到最终的encoder output。之后decoder再利用Attention机制以及character level GRU进行decode。</p>
<p>实验结果显示，基于字符的模型能更好的处理OOV的问题，而且对于多语言场景，能更好的学习各语言间通用的词素。</p>
<h1 id="字母组合"><a href="#字母组合" class="headerlink" title="字母组合"></a>字母组合</h1><p>字母的的暴力组合可以优化的思路就是，只选有意义的（高频）的当做组合。</p>
<h2 id="Byte-Pair-Encoding"><a href="#Byte-Pair-Encoding" class="headerlink" title="Byte Pair Encoding"></a>Byte Pair Encoding</h2><p>基本单元介于字符与单词之间的模型称作Subword Model。那么Subword如何选择呢？一种方法是Byte Pair Encoding,简称BPE。 BPE最早是一种压缩算法，基本思路是把经常出现的byte pair用一个新的byte来代替，例如假设(‘A’, ’B‘）经常顺序出现，则用一个新的标志’AB’来代替它们。</p>
<p>给定了文本库，我们的初始词汇库仅包含所有的单个的字符，然后不断的将出现频率最高的n-gram pair作为新的ngram加入到词汇库中，直到词汇库的大小达到我们所设定的某个目标为止。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200503001623.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>例如，假设我们的文本库中出现的单词及其出现次数为 {‘l o w’: 5, ‘l o w e r’: 2, ‘n e w e s t’: 6, ‘w i d e s t’: 3}，我们的初始词汇库为{ ‘l’, ‘o’, ‘w’, ‘e’, ‘r’, ‘n’, ‘w’, ‘s’, ‘t’, ‘i’, ‘d’}，出现频率最高的ngram pair是(‘e’,’s’) 9次，所以我们将’es’作为新的词汇加入到词汇库中，由于’es’作为一个整体出现在词汇库中，这时文本库可表示为 {‘l o w’: 5, ‘l o w e r’: 2, ‘n e w es t’: 6, ‘w i d es t’: 3}，这时出现频率最高的ngram pair是(‘es’,’t’) 9次，将’est’加入到词汇库中，文本库更新为{‘l o w’: 5, ‘l o w e r’: 2, ‘n e w est’: 6, ‘w i d est’: 3}，新的出现频率最高的ngram pair是(‘l’,’o’)7次，将’lo’加入到词汇库中，文本库更新为{‘lo w’: 5, ‘lo w e r’: 2, ‘n e w est’: 6, ‘w i d est’: 3}。以此类推，直到词汇库大小达到我们所设定的目标。这个例子中词汇量较小，对于词汇量很大的实际情况，我们就可以通过BPE逐步建造一个较小的基于subword unit的词汇库来表示所有的词汇。</p>
<h2 id="SentencePiece"><a href="#SentencePiece" class="headerlink" title="SentencePiece"></a>SentencePiece</h2><p>谷歌的NMT模型用了BPE的变种，称作wordpiece model，BPE中利用了n-gram count来更新词汇库，而wordpiece model中则用了一种贪心算法来最大化语言模型概率，即选取新的n-gram时都是选择使得perplexity减少最多的ngram。进一步的，sentencepiece model将词间的空白也当成一种标记，可以直接处理sentence，而不需要将其pre-tokenize成单词。下面是解决方案。</p>
<h1 id="Hybrid-Model：只对新词character-level"><a href="#Hybrid-Model：只对新词character-level" class="headerlink" title="Hybrid Model：只对新词character level"></a>Hybrid Model：只对新词character level</h1><p>character level本来是解决word Embedding的OOV问题的，直接重新打破word Embedding 有点亏，就单纯对新词进行Embedding就好了。</p>
<p>其结构如下图所示，大部分还是依赖于比较高效的word level模型，但遇到例子中的”cute”这样的OOV词汇，我们就需要建立一个character level的表示，decode时遇到<unk>这个表示OOV的特殊标记时，就需要character level的decode，训练过程是end2end的，不过损失函数是word部分与character level部分损失函数的加权叠加。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200503002052.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></unk></p>
<h1 id="其他思路：FastText-embeddings"><a href="#其他思路：FastText-embeddings" class="headerlink" title="其他思路：FastText embeddings"></a>其他思路：FastText embeddings</h1><p>对于任何一个单词，把他内部的可能全枚举出来，然后在word embeddings的过程中都生成一个向量。相当于扩充了单词集。</p>
<p>其基本思路是将每个word表示成bag of character n-gram以及单词本身的集合，例如对于where这个单词和n=3的情况，它可以表示为 _<wh,whe,her,ere,re>,<where> ，_其中”&lt;”,”&gt;”为代表单词开始与结束的特殊标记。假设对于word $w$ ，其n-gram集合用 $=G_W$ 表示，每个n-gram的矢量表示为 <img alt="[公式]" data-src="https://www.zhihu.com/equation?tex=%5Cvec%7Bz_g%7D"> ，则每个单词可以表示成其所有n-gram的矢量和的形式，而center word $w$ 与context word $c$ 的分数就可表示成 <img alt="[公式]" data-src="https://www.zhihu.com/equation?tex=s%28w%2Cc%29%3D%5Csum_%7Bg%5Cin+G_w%7D%5Cvec%7Bz_g%7D%5ET%5Cvec%7Bv_c%7D"> 的形式，之后就可以按照经典的word2vec算法训练得到这些特征向量。<br>这种方式既保持了word2vec计算速度快的优点，又解决了遇到training data中没见过的oov word的表示问题，可谓一举两得。</where></wh,whe,her,ere,re></p>
<blockquote>
<p>参考： <a href="https://zhuanlan.zhihu.com/p/69414965" target="_blank" rel="noopener">知乎这篇</a></p>
</blockquote>
]]></content>
      <categories>
        <category>CS224n</category>
      </categories>
  </entry>
  <entry>
    <title>CS224n-11 CNN在nlp的应用</title>
    <url>/2020/CS224n-11/</url>
    <content><![CDATA[<blockquote>
<p>这一节主要讲cnn在nlp中的应用，然后讲了几篇paper的思路。站在现在看CNN其实对于nlp并没有爆发性的突破，但是CNN也算是提取局部特征的思路，可以学习2017年以前那些人的尝试过程，也蛮有意思吧。</p>
</blockquote><a id="more"></a>
<h1 id="CNN介绍"><a href="#CNN介绍" class="headerlink" title="CNN介绍"></a>CNN介绍</h1><p>这些定义和CV里一模一样，简单介绍一下怎么操作的。</p>
<ul>
<li>为什么要引入CNN？<br>因为语言（文本数据）是依托于“短语”组成的“句子”，而对于短语的划分难度较大，倒不如直接暴力的枚举出所有的连续词组当做“短语”。</li>
<li>举个例子：“tentative deal reached to keep government open” 用长度是3的卷积来，就得到了：<br>tentative deal reached, deal reached to, reached to keep, to keep government, keep government open这样的新局部组合。<br>（最简单的2维卷积）<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200425220011.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></li>
</ul>
<h2 id="Filter-Kernel"><a href="#Filter-Kernel" class="headerlink" title="Filter (Kernel)"></a>Filter (Kernel)</h2><p>文本都是一维<em>K (embedding 长度)，所以卷积核也是 C </em> K。C是卷积核长度。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200425220434.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<h2 id="Padding"><a href="#Padding" class="headerlink" title="Padding"></a>Padding</h2><p>边缘用0向外扩充，和图像一样。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200425220548.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<h2 id="多个Channel并行"><a href="#多个Channel并行" class="headerlink" title="多个Channel并行"></a>多个Channel并行</h2><p>多个卷积核一起工作，和图像一样。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200425220710.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<h2 id="Pooling-池化"><a href="#Pooling-池化" class="headerlink" title="Pooling 池化"></a>Pooling 池化</h2><p>最大池化，平均池化等操作。没什么好讲的。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200425220816.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<h2 id="Stride-步长"><a href="#Stride-步长" class="headerlink" title="Stride 步长"></a>Stride 步长</h2><p>默认的步长是1，设置了就可以跳跃。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200425222644.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<h2 id="局部池化"><a href="#局部池化" class="headerlink" title="局部池化"></a>局部池化</h2><p>例：local max pool<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200425222745.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<h2 id="k-max-pooling"><a href="#k-max-pooling" class="headerlink" title="k-max pooling"></a>k-max pooling</h2><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200425225426.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<h2 id="Dilation-跨越卷积"><a href="#Dilation-跨越卷积" class="headerlink" title="Dilation 跨越卷积"></a>Dilation 跨越卷积</h2><p>就是跳着一层，去提取特征。CV也常用吧。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200425225528.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<h1 id="Paper-Single-Layer-CNN-for-Sentence-Classification-2014"><a href="#Paper-Single-Layer-CNN-for-Sentence-Classification-2014" class="headerlink" title="Paper: Single Layer CNN for Sentence Classification 2014"></a>Paper: Single Layer CNN for Sentence Classification 2014</h1><blockquote>
<p>这篇文章上学期我还用过哈哈哈哈哈哈。<a href="https://arxiv.org/pdf/1408.5882.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1408.5882.pdf</a></p>
</blockquote>
<p>输入是一句话，输出是二分类（正负态度）。下面这张图包含了整个过程。太简单，不解释了。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200425234203.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>他也使用了其他技巧比如 Dropout。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200425235351.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br> L2 constraint s for rows of softmax, s = 3 。 softmax的参数限制到3？ 这里是为什么，没懂。</p>
<h1 id="其他技巧"><a href="#其他技巧" class="headerlink" title="其他技巧"></a>其他技巧</h1><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200426000001.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<h2 id="起飞飞飞飞飞：残差网络"><a href="#起飞飞飞飞飞：残差网络" class="headerlink" title="起飞飞飞飞飞：残差网络"></a>起飞飞飞飞飞：残差网络</h2><p>另外参考：<a href="https://zhuanlan.zhihu.com/p/42706477" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/42706477</a><br>其实之前也提到过了，lstm有效就是跨层链接。而对于cell外面，也可以使用这种方法ResNet。应该是在16年左右？当时听到这些名词感觉很神奇，好像作者何凯明还是广州人。 思路如图，就是跨越链接，避免网络太深。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200426000540.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>这种思路被验证是有效的。左边没有门控，右边有门控。</p>
<blockquote>
<p>这里我有个疑问，为何没有门控的还晚一年。</p>
</blockquote>
<h2 id="BatchNorm"><a href="#BatchNorm" class="headerlink" title="BatchNorm"></a>BatchNorm</h2><p>另外参考：<a href="https://blog.csdn.net/wzy_zju/article/details/81262453" target="_blank" rel="noopener">https://blog.csdn.net/wzy_zju/article/details/81262453</a><br><a href="https://www.jianshu.com/p/86530a0a3935" target="_blank" rel="noopener">https://www.jianshu.com/p/86530a0a3935</a><br>原理就是对于每一个batch正则，保持batch都在相同的分布上，这样会避免<strong>internal covariate shift</strong>的现象。</p>
<p>具体的原因之后遇到了再深究吧。</p>
<h2 id="1-1-Convolutions"><a href="#1-1-Convolutions" class="headerlink" title="1*1 Convolutions"></a>1*1 Convolutions</h2><p>看起来1<em>1好像没有任何改变，但是实际上可以控制厚度(filter的数量)。<br>1、<strong>降维（ dimension reductionality ）</strong>。比如，一张500 </em> 500且厚度depth为100 的图片在20个filter上做1<em>1的卷积，那么结果的大小为500</em>500*20。</p>
<p>2、<strong>加入非线性</strong>。卷积层之后经过激励层，1*1的卷积在前一层的学习表示上添加了非线性激励（ non-linear activation ），提升网络的表达能力；</p>
<h2 id="应用举例"><a href="#应用举例" class="headerlink" title="应用举例"></a>应用举例</h2><p>  seq2seq de enocoder y用cnn<img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200426112425.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<p> <img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200426112508.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200426112521.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<h1 id="更深，更大，更强-VC-CNN"><a href="#更深，更大，更强-VC-CNN" class="headerlink" title="更深，更大，更强: VC-CNN"></a>更深，更大，更强: VC-CNN</h1><p>这个网络是参考的VGGnet，所以就很大，当然表现也有所提升。具体就不细讲了。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200426114208.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<h1 id="QRNN"><a href="#QRNN" class="headerlink" title="QRNN"></a>QRNN</h1><p>RNN速度慢必须串行，所以就有了QRNN，来结合CNN提高速度。<br>参考：<a href="https://blog.csdn.net/u011961856/article/details/77431869" target="_blank" rel="noopener">https://blog.csdn.net/u011961856/article/details/77431869</a><br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200426120024.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<p>具体思路是，把LSTM的三个门控放到CNN的pooling层，做成类似与LSTM的效果。</p>
<blockquote>
<p>这节课讲的都是一些high-level的思路，具体的细节还有待揣摩。</p>
</blockquote>
]]></content>
      <categories>
        <category>CS224n</category>
      </categories>
  </entry>
  <entry>
    <title>MSBD5004 Mathematical Methods for Data Analysis Homework 4</title>
    <url>/2020/MSBD5004-Mathematical-Methods-for-Data-Analysis-Homework-4/</url>
    <content><![CDATA[<blockquote>
<p>这次作业感觉有点简单啊。🤧 最后一题凭感觉写的，不知道对不对，如果有问题请在留言板告诉我。<br>希望大家留言板支持一下博主，打公式真的好累。☹️ 给个例子让你们参考一下。<br><a id="more"></a><br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200424084444.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
</blockquote>
<h1 id="Q1"><a href="#Q1" class="headerlink" title="Q1"></a>Q1</h1><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200417021144.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br><strong><em>Solution:</em></strong> </p>
<script type="math/tex; mode=display">
\begin{aligned}
\|A\| =\sup _{\|x\|_{V}=1}\|A x\|_{\mathbb{R}}=\sup _{\|x\|_{V}=1}\|\langle a,x \rangle\|=\sup _{\|x\|_{V}=1}\sqrt{|\sum a_ix_i|} =\sqrt{\max(a_i)}
\end{aligned}</script><p>◾</p>
<h1 id="Q2"><a href="#Q2" class="headerlink" title="Q2"></a>Q2</h1><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200417021154.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br><strong><em>Solution:</em></strong></p>
<script type="math/tex; mode=display">
\begin{aligned}
&f_{1}(\boldsymbol{x})=f_{1}\left(\boldsymbol{x}^{(0)}\right)+ D f_{1}\left(\boldsymbol{x}^{(0)}\right)\left(\boldsymbol{x}-\boldsymbol{x}^{(0)}\right)+o\left(|| \boldsymbol{x}-\boldsymbol{x}^{(0)} \|\right)\\
&f_{2}(\boldsymbol{x})=f_{2}\left(\boldsymbol{x}^{(0)}\right)+D f_{2}\left(\boldsymbol{x}^{(0)}\right)\left(\boldsymbol{x}-\boldsymbol{x}^{(0)}\right)+o\left(\left\|\boldsymbol{x}-\boldsymbol{x}^{(0)}\right\|\right)\\
&\vdots\\
&f_{n}(\boldsymbol{x})=f_{i}\left(\boldsymbol{x}^{(0)}\right)+D f_{n}\left(\boldsymbol{x}^{(0)}\right)\left(\boldsymbol{x}-\boldsymbol{x}^{(0)}\right)+o\left(\left\|\boldsymbol{x}-\boldsymbol{x}^{(0)}\right\|\right).\\\\
&So, F(\boldsymbol{x})=F\left(\boldsymbol{x}^{(0)}\right)+D F\left(\boldsymbol{x}^{(0)}\right)\left(\boldsymbol{x}-\boldsymbol{x}^{(0)}\right)+o\left(\left\|\boldsymbol{x}-\boldsymbol{x}^{(0)}\right\|\right).\\
& \text{where} D F\left(\boldsymbol{x}^{(0)}\right): V \rightarrow \mathbb{R} \text{ defined by} DF\left(\boldsymbol{x}^{(0)}\right)(\boldsymbol{y})=\left[\begin{array}{l}
D f_{1}\left(\boldsymbol{x}^{(0)}\right)(\boldsymbol{y}) \\
D f_{2}\left(\boldsymbol{x}^{(0)}\right)(\boldsymbol{y}) \\
\qquad \vdots\\
D f_{n}\left(\boldsymbol{x}^{(0)}\right)(\boldsymbol{y}) \\
\end{array}\right]
\end{aligned}</script><p>In particular, if $V$ is a Hilbert space,</p>
<script type="math/tex; mode=display">D F(\boldsymbol{x})(\boldsymbol{y})=\left[\begin{array}{c}\left\langle\nabla f_{1}(\boldsymbol{x}), \boldsymbol{y}\right\rangle \\ \left\langle\nabla f_{2}(\boldsymbol{x}), \boldsymbol{y}\right\rangle \\ \vdots \\ \left\langle\nabla f_{n}(\boldsymbol{x}), \boldsymbol{y}\right\rangle\end{array}\right], \quad \forall \boldsymbol{x} \in V</script><p>◾</p>
<h1 id="Q3"><a href="#Q3" class="headerlink" title="Q3"></a>Q3</h1><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200417021207.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br><strong><em>Solution:</em></strong><br>（a)<br>$\nabla f(\boldsymbol{x})=\boldsymbol{A}^T(\boldsymbol{A} \boldsymbol{x}-\boldsymbol{b})+2\lambda\boldsymbol{x}$<br>$\nabla^2 f(\boldsymbol{x})=\boldsymbol{A}^T\boldsymbol{A} +2\lambda$<br>(b)<br>$\nabla f(\boldsymbol{X})=\boldsymbol{b}^T\boldsymbol{X}\boldsymbol{c}=\boldsymbol{c}\boldsymbol{b}^T$<br>$\nabla^2 f(\boldsymbol{x})=0$<br>(c)<br>$\nabla f(\boldsymbol{x})=\boldsymbol{x}^T(\boldsymbol{A}+\boldsymbol{A}^T)$<br>$\nabla^2 f(\boldsymbol{x})=(\boldsymbol{A}+\boldsymbol{A}^T)$<br>(d)<br>$\nabla f(\boldsymbol{X})=\boldsymbol{b}^T\boldsymbol{X}\boldsymbol{c}+\boldsymbol{c}^T\boldsymbol{X}^T\boldsymbol{b}$<br>$\nabla^2 f(\boldsymbol{X})=\boldsymbol{c}\boldsymbol{b}^T+\boldsymbol{c}\boldsymbol{b}^T$<br>(e)<br>$\nabla f(\boldsymbol{X})=\boldsymbol{A}\boldsymbol{X}\boldsymbol{B}+\boldsymbol{B}\boldsymbol{X}\boldsymbol{A}$<br>$\nabla^2 f(\boldsymbol{X})=\boldsymbol{B}\boldsymbol{A}+\boldsymbol{A}\boldsymbol{B}$</p>
]]></content>
      <categories>
        <category>5004</category>
      </categories>
  </entry>
  <entry>
    <title>杂记-要结束了？</title>
    <url>/2020/%E6%9D%82%E8%AE%B0/</url>
    <content><![CDATA[<p>又有感而发，开始写杂乱无章了。<br>我一直觉得，任何一个学期。<br>学期刚开始，学的都是轻轻松松，又不用复习太多，就很有兴趣，兴致勃勃。<br>学期要结束，就得开始准备复习，准备考试，紧紧张张，学的就很有收获。<br>但是学期中，就比如过去的几周，就是一段煎熬的时光，自己难以找到锚来提供动力，开始疲惫，拖沓，平静的黑夜里在海面飘荡。<br>（所以，我很感激我本科四年，几乎每门课都有期中考，强行把我的学期划分，才让我不至于那么荒废时光。</p><a id="more"></a>
<p>但是，学期中和学期末两个阶段的跨度其实就是一瞬间的事情。<br>比如说今天。当我突然发现，5004已经换了老师，而且还只剩下四周就要毕业的时候。</p>
<p>心情复杂。</p>
<p>一方面在于四周之后意味着我彻底没有课再上，(没有phd打算)，离社畜更近。<br>另一方面在于，我并没有完成准备好成为社畜的plan。<br>224N没学完，OS，推荐的深度模型，LINUX的操作，也还都没有掌握。</p>
<p>还有不到40天，主要待学习内容：</p>
<ul>
<li>CS224N P11-P20 必完成</li>
<li>反复复习机器学习：<a href="http://www.huaxiaozhuan.com/" target="_blank" rel="noopener">http://www.huaxiaozhuan.com/</a></li>
<li>《Unix 环境高级编程第三版》前三章</li>
<li>《增长黑客》当做兴趣看</li>
<li>结课</li>
</ul>
<p>555，想想要结课了就难受。</p>
]]></content>
      <categories>
        <category>杂乱无章</category>
      </categories>
      <tags>
        <tag>hide</tag>
      </tags>
  </entry>
  <entry>
    <title>CS224n-10 问答系统QA介绍</title>
    <url>/2020/CS224n-10/</url>
    <content><![CDATA[<blockquote>
<p>这一节主要在介绍数据集和task。对于模型没太深究。</p>
</blockquote>
<ul>
<li>问答系统QA</li>
</ul>
<p>一般的project组成部分，很容易理解，不解释了。<br><a id="more"></a><br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200419213835.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h2><p>搜索引擎，语言助手比如siri，经常需要回答人类的问题。<br>可以分成两部分：</p>
<ol>
<li>从很多的文档中找到对应的文档。</li>
<li>对于一个文档和一个问题，判断是否文档可以回答这个问题，答案是什么。类似于阅读理解。本节课主要讲这个。</li>
</ol>
<p>例子如图：<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200419220439.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<h2 id="数据集介绍SQuAD"><a href="#数据集介绍SQuAD" class="headerlink" title="数据集介绍SQuAD"></a>数据集介绍SQuAD</h2><p>Stanford Question Answering Dataset SQuAD是斯坦福搞的数据集，表现良好。<br>举例：<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200419232140.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>对于任何一段话，一个问题一般有三个答案，如果预测回答的答案对了，那就得一分。然后会比较准确率，回撤率，F1值等指标。主要看F1.<br>对于第一版的数据可以看出，经过几年的发展，bert已经表现比人还好。<img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200419233229.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<p>对于SQuAD 2.0的改进，主要是数据集添加了&lt;该问题无答案&gt;的label，也更符合人类的场景，增加了难度。如图：<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200419234920.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>增加难度之后，bert表现依然不错。排名靠前的都是bert。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200419235414.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<h2 id="SQuAD的缺陷"><a href="#SQuAD的缺陷" class="headerlink" title="SQuAD的缺陷"></a>SQuAD的缺陷</h2><p>问题还是太简单，只需要找到实体，不能解释原因。<br>不需要提前的额外知识，答案就在一个很小的段落里。</p>
<h1 id="一些方案介绍"><a href="#一些方案介绍" class="headerlink" title="一些方案介绍"></a>一些方案介绍</h1><h2 id="Stanford-Attentive-Reader"><a href="#Stanford-Attentive-Reader" class="headerlink" title="Stanford Attentive Reader"></a>Stanford Attentive Reader</h2><p>这个方案是2017年的cs224N的TA做的。思路很简单，用lstm扫描问题，用Attention扫描文章，然后用一个矩阵乘起来，通过softmax得到概率。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200420001227.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>最后表现还不错。</p>
<h2 id="Stanford-Attentive-Reader-1"><a href="#Stanford-Attentive-Reader-1" class="headerlink" title="Stanford Attentive Reader++"></a>Stanford Attentive Reader++</h2><p>改进版的TA方案是对于文章也用BLSTM*3层，然后输入的时候也输入词性。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200420002038.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<blockquote>
<p>好多细节，也没听懂，之后看代码吧。</p>
<h2 id="BiDAF"><a href="#BiDAF" class="headerlink" title="BiDAF"></a>BiDAF</h2><p>另一个经典的网络。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200420003652.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>最后都是讲具体的模型，太细节了，讲的又快，还是到时候挑几个看代码吧。</p>
</blockquote>
]]></content>
      <categories>
        <category>CS224n</category>
      </categories>
  </entry>
  <entry>
    <title>AutoML-调参迈入蒸汽时代</title>
    <url>/2020/AutoML/</url>
    <content><![CDATA[<blockquote>
<p>抽象，再抽象。     AutoML体验有感。</p>
</blockquote><p>抽象这个词我真的是越来越喜欢了。小时候把看不懂的文字或者画叫抽象，虽然那些东西我现在依然不懂，但是现在对于抽象这两个字多少有点认识。本科的时候老师说“数学是自然科学的抽象”，我感触最深的就是线性代数，线性代数在之后的各个学科基本都有应用，大部分和维数有关的都可以用线性代数来表示。</p><a id="more"></a>

<p>其实，在程序语言里，抽象很好理解，抽象就是定义一个class。举例或者应用，就是对于一个class实例化/初始化。而什么东西需要定义class呢？就是那些可以重复使用，属性共通的东西。比如：定义一个“男孩”，那男孩就拥有自身属性“身高，体重，年龄”，男孩拥有自身功能“写作业，拍照，搬砖”。</p>
<p>而再抽象，就是进一步的去找到共性。比如“男孩”之上可以抽象“人类”，“人类”之上可以抽象“生物”。越高级(这里的高级并不是说厉害，而是更多次的抽象)的定义，就意味可以代表更多的东西，有更多的功能。</p>
<p>在我今天体验完AutoML之后就感受到了，自己傻乎乎的手动调参，手动cv网格搜索，手动去尝试所有的分类模型，回归模型是多落后的一件事。有了AutoML可以说，没有任何机器学习基础的人都能短时间内得到一个表现很不错的模型。(面临失业555😩)</p>
<p>AutoML就是对于我们去用sklearn里的模型训练，调参，验证的过程进行抽象，然后封装。</p>
<hr>
<h1 id="AutoML"><a href="#AutoML" class="headerlink" title="AutoML"></a>AutoML</h1><p>话说18年好像AutoML就已经挺火了，不过一直局限于课本算法，没有怎么体验过，这两天苦于调参，尝试了一下，表现还不错。原理不复杂，如图。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200418221344.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<h2 id="出现原因"><a href="#出现原因" class="headerlink" title="出现原因"></a>出现原因</h2><p>机器学习的应用需要大量的人工干预，这些人工干预表现在：特征提取、模型选择、参数调节等机器学习的各个方面。AutoML 试图将这些与特征、模型、优化、评价有关的重要步骤进行自动化地学习，使得机器学习模型无需人工干预即可被应用。</p>
<p><strong>也就是只需要输入数据，然后自动调参，自动选模型，自动找特征。这里的“自动”可以是遍历，也可以是通过某种策略。反正就是暴力出奇迹。</strong></p>
<h2 id="AutoML问题定义"><a href="#AutoML问题定义" class="headerlink" title="AutoML问题定义"></a>AutoML问题定义</h2><p><strong>AutoML 的主要问题可以由三部分构成：特征工程、模型选择、算法选择。</strong></p>
<h3 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a><strong>特征工程</strong></h3><p>特征工程在机器学习中有着举足轻重的作用。<strong>在 AutoML 中，自动特征工程的目的是自动地发掘并构造相关的特征，使得模型可以有最优的表现。</strong>除此之外，还包含一些特定的特征增强方法，例如特征选择、特征降维、特征生成、以及特征编码等。这些步骤目前来说都没有达到自动化的阶段。</p>
<p>上述这些步骤也伴随着一定的参数搜索空间。第一种搜索空间是方法自带的，例如PCA自带降维参数需要调整。第二种是特征生成时会将搜索空间扩大。</p>
<h3 id="模型选择"><a href="#模型选择" class="headerlink" title="模型选择"></a><strong>模型选择</strong></h3><p><strong>模型选择包括两个步骤：选择一个模型，设定它的参数。</strong>相应地，AutoML的目的就是自动选择出一个最合适的模型，并且能够设定好它的最优参数。</p>
<h3 id="算法选择"><a href="#算法选择" class="headerlink" title="算法选择"></a><strong>算法选择</strong></h3><p>对于算法选择，<strong>AutoML 的目的是自动地选择出一个优化算法，以便能够达到效率和精度的平衡。</strong>常用的优化方法有 SGD、L-BFGS、GD 等。使用哪个优化算法、对应优化算法的配置，也需要一组搜索空间。</p>
<h4 id="从全局看"><a href="#从全局看" class="headerlink" title="从全局看"></a><strong>从全局看</strong></h4><p>将以上三个关键步骤整合起来看，<strong>一个完整的 AutoML 过程可以分成这么两类</strong>：一类是将以上的三个步骤整合成一个完整的 pipeline；另一类则是 Network Architecture Search，能够自动地学习到最优的网络结构。在学习的过程中，对以上三个问题都进行一些优化。<br>总之，机器学习的各种包xgb，sklearn都打包好，接口设计好，光扔准备好的数据就好了。</p>
<h1 id="Azure-Google-阿里云"><a href="#Azure-Google-阿里云" class="headerlink" title="Azure,Google,阿里云"></a>Azure,Google,阿里云</h1><h2 id="Azure"><a href="#Azure" class="headerlink" title="Azure"></a>Azure</h2><p>Azure是学校给的资源，100美元的额度，还挺多的。Azure产品上整体体验功能很多，但是前端和汉化做的不够好，难以理解模块之间的逻辑关系。<br>首先登录<a href="https://ml.azure.com/" target="_blank" rel="noopener">https://ml.azure.com/</a>，确保账号有钱。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200418225757.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>然后准备好数据集，输入可以是csv的格式，label的那一列在哪无所谓，id列在也可以后期不输入模型。<br>然后选择“自动化ML”也就是automl，选择刚才的数据集。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200418230336.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>随便选择一个模型的名字，然后选择label列y。最后选择计算的资源，按照自己的需求选吧，反正肯定越大越好。<br>最后选择模型，回归，分类，时间预测(还没用过，时间戳的格式可能有点复杂)，以及这个模型的评价指标，验证方法，训练时间，迭代次数等超参数。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200418230731.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<p>然后，大概经过一个小时的等待，实验就完成了。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200418231011.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>输出的模型是选择的评价指标最好的模型，一般大概率是一个集成模型Ensemble。点击模型可以看到具体的所有尝试过模型和特征提取方法的组合。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200418231124.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>更nb的是他还可以对特征可视化，分析和模型的内部情况。随便上几张图感受一下。</p>
<ul>
<li><p>可以看出不同特征的权重差异<br><img alt="可以看出不同特征的权重差异" data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200418231349.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
</li>
<li><p>可以看出特征和y的相关性情况<br><img alt="可以看出特征和y的相关性情况" data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200418231401.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
</li>
</ul>
<p>但是训练完的模型必须部署之后才能预测，部署又需要搞服务，和服务器一系列的东西，太工程化了，做研究就不太适合。</p>
<h2 id="Google-Cloud"><a href="#Google-Cloud" class="headerlink" title="Google Cloud"></a>Google Cloud</h2><p>Google的产品永远是我最喜欢的，简洁，逻辑简单，功能强大。Cloud也不例外。<br>由于我去年申请了google cloud的免费试用一年，还有很多余额，刚好体验了一下。<br>AutoML模块链接：<a href="https://cloud.google.com/automl/?_ga=2.81364951.-1987914321.1587187760" target="_blank" rel="noopener">https://cloud.google.com/automl/</a><br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200418231836.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>普通的回归分类任务选择Tables。(其他的任务我看了一下都是近两年的热门，图像物品检测，翻译等，google在深度学习上的耕耘在这就变现了)。<br>然后上传数据集，需要提前准备存储空间。上传完长这样。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200418233034.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>注意的是如果id类没有进行onehot，这里一定要手动改成分类变量，或者直接剔除。<br>训练一个小时到几个小时不等，可以定义不同的超参数，选择不同的特征训练多次。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200418234516.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>训练好模型可以对比在验证集上的表现，不过google看不到具体是用哪个模型。</p>
<p>和Azure类似，google也展示了特征的权重。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200418234659.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>两边最终得到的模型表现接近，特征权重也很接近。这可能就说明了，AutoML已经把特征“榨干”了吧，逼近了特征的上限。</p>
<p>google优秀的一点是，可以直接上传测试集得到预测结果。这一点比Azure优秀多了。</p>
<h2 id="阿里云"><a href="#阿里云" class="headerlink" title="阿里云"></a>阿里云</h2><p>在阿里云的PAI里，也有AutoML的功能，但是明显阿里云做的不够详细，只有召回和图片分类，没有给机器学习部分投入太大的研究。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200418235050.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<p>如果我上学期就用上这个AutoML，那做kaggle比赛不是美滋滋？😍只需要构造特征，剩下的用AutoML逼近特征上限就好了。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>AutoML</tag>
      </tags>
  </entry>
  <entry>
    <title>pytorch再接触</title>
    <url>/2020/pytorch2/</url>
    <content><![CDATA[<p>本次是MSBD5002的第二次作业，作业要求用MLP实现二分类和多分类的任务。多分类其实是对于图片分类，所以我也照着MNIST的CNNdemo改了个CNN的模型，CNN效果会好一点。但是由于数据集本身的原因，准确率没能上90%。</p><a id="more"></a>
<p>额外引用了skorch。skorch是基于pytorch的外部工具，集成了很多基础功能，使得训练过程变得异常简单。一个net.fit()就能搞定。</p>
<blockquote>
<p>记录一下过程，仅供参考。以下正文。</p>
</blockquote>
<hr>
<h1 id="Neural-Networks-Models-for-Binary-Classifcation-Data-Sets"><a href="#Neural-Networks-Models-for-Binary-Classifcation-Data-Sets" class="headerlink" title="Neural Networks Models for Binary Classifcation Data Sets"></a>Neural Networks Models for Binary Classifcation Data Sets</h1><h2 id="Define-the-network"><a href="#Define-the-network" class="headerlink" title="Define the network"></a>Define the network</h2><p>For first task we need to set of single hidden layer neural network models, and I choice stochastic gradient descent algorithm by minimizing the cross-entropy loss. By use PyTorch, it’s pretty easy to define my own network jusk as<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net_1hidden</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, n_feature, n_hidden, n_output=<span class="number">2</span>)</span>:</span></span><br><span class="line">        super(Net_1hidden, self).__init__()</span><br><span class="line">        self.hidden = torch.nn.Linear(n_feature, n_hidden)   <span class="comment"># hidden layer</span></span><br><span class="line">        self.out = torch.nn.Linear(n_hidden, n_output)   <span class="comment"># output layer</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = Fun.relu(self.hidden(x))      <span class="comment"># activation function for hidden layer we choose rele</span></span><br><span class="line">        x = F.softmax(self.out(x), dim=<span class="number">-1</span>)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><br>For this net both <code>n_feature</code> and <code>n_hidden</code> are needed to be given a parameter.  <code>n_feature</code> depends on the feature of X, and <code>n_hidden</code> are needed to be be choice by cross validation.<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200415172243.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg#center">  </p>
<h2 id="Build-the-pipeline"><a href="#Build-the-pipeline" class="headerlink" title="Build the pipeline"></a>Build the pipeline</h2><p>To make the train process easier, it’s better to build a hole pipeline include the read data, split the data into different parts and shuffle the data to make the model more stable.<br>So I used scikit-learn compatible neural network library that wraps PyTorch. The goal of skorch is to make it possible to use PyTorch with sklearn. This is achieved by providing a wrapper around PyTorch that has an sklearn interface. In that sense, skorch is the spiritual successor to nolearn, but instead of using Lasagne and Theano, it uses PyTorch.<br>So it’s easy to fit the model by <code>net.fit(train_X,train_Y)</code>.</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> skorch <span class="keyword">import</span> NeuralNetClassifier</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_data</span><span class="params">(filename)</span>:</span></span><br><span class="line">    data = np.load(<span class="string">'./datasets/bi-class/'</span>+filename)</span><br><span class="line">    train_X,test_X = torch.FloatTensor(data[<span class="string">'train_X'</span>]),torch.FloatTensor(data[<span class="string">'test_X'</span>])</span><br><span class="line">    train_Y,test_Y = torch.LongTensor(data[<span class="string">'train_Y'</span>]),torch.LongTensor(data[<span class="string">'test_Y'</span>])</span><br><span class="line">    print(<span class="string">'\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;'</span>+filename,data[<span class="string">'train_X'</span>].shape,data[<span class="string">'test_X'</span>].shape)</span><br><span class="line">    <span class="keyword">return</span> train_X,test_X,train_Y,test_Y</span><br><span class="line"></span><br><span class="line">net = NeuralNetClassifier(</span><br><span class="line">        Net_1hidden(n_feature=n_feature, n_hidden=<span class="number">10</span>, n_output=<span class="number">2</span>),</span><br><span class="line">        max_epochs=<span class="number">20</span>,</span><br><span class="line">        lr=<span class="number">0.1</span>,</span><br><span class="line">        optimizer=torch.optim.SGD,</span><br><span class="line">        criterion=torch.nn.CrossEntropyLoss,</span><br><span class="line">        iterator_train__shuffle=<span class="literal">True</span>,</span><br><span class="line">        )</span><br><span class="line">net.fit(train_X,train_Y)</span><br></pre></td></tr></table></figure>
<p>To make the program more clear, I just choice max_epochs is 20 which by test several times. And I didn’t use early stopping tech because all dataset is small enough and doesn’t need too much time to train.</p>
<h2 id="Cross-validation-to-find-best-parameter"><a href="#Cross-validation-to-find-best-parameter" class="headerlink" title="Cross validation to find best parameter"></a>Cross validation to find best parameter</h2><p>In the assignment description, we needed to find the best hidden units H for each dataset. So I used the <code>GridSearchCV</code> from <code>sklearn</code>. GridSearchCV implements a “fit” and a “score” method. It also implements “predict”, “predict_proba”, “decision_function”, “transform” and “inverse_transform” if they are implemented in the estimator used.Which is very useful for search best parameter. The <code>NeuralNet</code> class allows to directly access parameters of the <code>pytorch module</code> by using the <code>module__</code> prefix.</p>
<p>For each dataset, it is done by randomly sampling 80% of the training instances to train a classifier and then testing it on the remaining 20%. Which means 5-flods.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">params = &#123;<span class="string">'module__n_hidden'</span>: [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>],&#125;</span><br><span class="line">gs = GridSearchCV(net, params, refit=<span class="literal">False</span>, cv=<span class="number">5</span>, scoring=<span class="string">'accuracy'</span>)</span><br></pre></td></tr></table></figure><br>By this two function we can find best number of hidden between 1 to 10.</p>
<p>After train process and I find the best value is:</p>
<script type="math/tex; mode=display">
\begin{array}{cc}
\text { filename }& \text { best n value }  \\
diabetes.npz& 8\\
breast\_cancer.npz& 10\\
iris.npz& 10\\
wine.npz& 1\\
digit.npz& 8\\
\end{array}</script><p>It’s weird for <code>wine.npz</code>‘s best hidden number is 1. And I will discuss it on next part.</p>
<h2 id="All-result"><a href="#All-result" class="headerlink" title="All result"></a>All result</h2><p>On all five dataset, we can see the model performance as follows .</p>
<p><style type="text/css"><br>.tg  {border-collapse:collapse;border-spacing:0;}<br>.tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}<br>.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}<br>.tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}
</style></p>
<table class="tg">
  <tr>
    <th class="tg-0pky">filename</th>
    <th class="tg-0pky">best_params</th>
    <th class="tg-0pky">train_acc</th>
    <th class="tg-0pky">test_acc</th>
    <th class="tg-0pky">test_AUC</th>
    <th class="tg-0pky">train_time</th>
  </tr>
  <tr>
    <td class="tg-0pky">diabetes.npz</td>
    <td class="tg-0pky">8</td>
    <td class="tg-0pky">0.652</td>
    <td class="tg-0pky">0.647</td>
    <td class="tg-0pky">0.500</td>
    <td class="tg-0pky">0.725</td>
  </tr>
  <tr>
    <td class="tg-0pky">breast-cancer.npz</td>
    <td class="tg-0pky">10</td>
    <td class="tg-0pky">0.952</td>
    <td class="tg-0pky">0.963</td>
    <td class="tg-0pky">0.957</td>
    <td class="tg-0pky">0.568</td>
  </tr>
  <tr>
    <td class="tg-0pky">iris.npz</td>
    <td class="tg-0pky">10</td>
    <td class="tg-0pky">1.000</td>
    <td class="tg-0pky">1.000</td>
    <td class="tg-0pky">1.000</td>
    <td class="tg-0pky">0.214</td>
  </tr>
  <tr>
    <td class="tg-0pky">wine.npz</td>
    <td class="tg-0pky">1</td>
    <td class="tg-0pky">0.401</td>
    <td class="tg-0pky">0.389</td>
    <td class="tg-0pky">0.500</td>
    <td class="tg-0pky">0.244</td>
  </tr>
  <tr>
    <td class="tg-0pky">digit.npz</td>
    <td class="tg-0pky">8</td>
    <td class="tg-0pky">0.959</td>
    <td class="tg-0pky">0.935</td>
    <td class="tg-0pky">0.939</td>
    <td class="tg-0pky">0.833</td>
  </tr>
</table>

<p>As we can see, more hidden unit means more train time, because it need more computing .<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200417005311.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>Model performance well on <code>breast-cancer</code>, <code>iris.npz</code>, <code>digit.npz</code>.But for the <code>diabetes.npz</code> and <code>wine.npz</code> the model seems not work. There are several reasons for this problem. </p>
<ol>
<li>The feature and label of  dataset is meaningless.</li>
<li>The model is underfitting, because the epoch is only 20.</li>
<li>The model is too easy and con’t get the relationship.</li>
</ol>
<p>For find the reason, i try 2 hidden layers and add more epoch.<br>And the train result like follows:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;diabetes.npz (615, 8) (153, 8)</span><br><span class="line">1layer</span><br><span class="line">epoch:   0, loss: 0.716,accuracy: 0.346</span><br><span class="line">epoch: 100, loss: 0.664,accuracy: 0.647</span><br><span class="line">epoch: 200, loss: 0.644,accuracy: 0.647</span><br><span class="line">epoch: 300, loss: 0.635,accuracy: 0.647</span><br><span class="line">epoch: 400, loss: 0.631,accuracy: 0.647</span><br><span class="line">epoch: 500, loss: 0.628,accuracy: 0.647</span><br><span class="line">2layer</span><br><span class="line">epoch:   0, loss: 0.706,accuracy: 0.353</span><br><span class="line">epoch: 100, loss: 0.689,accuracy: 0.647</span><br><span class="line">epoch: 200, loss: 0.676,accuracy: 0.647</span><br><span class="line">epoch: 300, loss: 0.668,accuracy: 0.647</span><br><span class="line">epoch: 400, loss: 0.661,accuracy: 0.647</span><br><span class="line">epoch: 500, loss: 0.657,accuracy: 0.647</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;wine.npz (142, 13) (36, 13)</span><br><span class="line">1layer</span><br><span class="line">epoch:   0, loss: 0.912,accuracy: 0.389</span><br><span class="line">epoch: 100, loss: 0.912,accuracy: 0.389</span><br><span class="line">epoch: 200, loss: 0.912,accuracy: 0.389</span><br><span class="line">epoch: 300, loss: 0.912,accuracy: 0.389</span><br><span class="line">epoch: 400, loss: 0.912,accuracy: 0.389</span><br><span class="line">epoch: 500, loss: 0.912,accuracy: 0.389</span><br><span class="line">2layer</span><br><span class="line">epoch:   0, loss: 0.912,accuracy: 0.389</span><br><span class="line">epoch: 100, loss: 0.912,accuracy: 0.389</span><br><span class="line">epoch: 200, loss: 0.912,accuracy: 0.389</span><br><span class="line">epoch: 300, loss: 0.912,accuracy: 0.389</span><br><span class="line">epoch: 400, loss: 0.912,accuracy: 0.389</span><br><span class="line">epoch: 500, loss: 0.912,accuracy: 0.389</span><br></pre></td></tr></table></figure><br>As we can see, no matter how many epoch and how many layers for this two dataset. The model all don’t work. So I think it is the first reason. The feature and label of  dataset is meaningless.</p>
<h1 id="Neural-Networks-Models-for-Multi-class-Data-Sets"><a href="#Neural-Networks-Models-for-Multi-class-Data-Sets" class="headerlink" title="Neural Networks Models for Multi-class Data Sets"></a>Neural Networks Models for Multi-class Data Sets</h1><h2 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h2><p>For this dataset, we have train with 10000 image, and test with 1000 image. And the label is 0-9,  ten different classes. For each image, it is a 784 dimensions array, which can convert to 28*28 Square picture.<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200416195751.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<p>As we can see, there are some shoes, clothes, skirts, T-Shirts and each one class represent one number between 0-9.</p>
<h2 id="Build-a-2-hidden-layers-net"><a href="#Build-a-2-hidden-layers-net" class="headerlink" title="Build a 2 hidden layers net"></a>Build a 2 hidden layers net</h2><p>By use pytorch, it’s pretty easy to define a network. Again I still use relu as activate function, CrossEntropy as loss function. And I define the input feature is a flatten array with 784, and output layer is 10 which equal to the class number.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net_2hidden</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, n_hidden1,  n_hidden2, n_output = <span class="number">10</span>, n_feature = <span class="number">784</span>)</span>:</span></span><br><span class="line">        super(Net_2hidden, self).__init__()</span><br><span class="line">        self.hidden1 = torch.nn.Linear(n_feature, n_hidden1)</span><br><span class="line">        self.hidden2 = torch.nn.Linear(n_hidden1, n_hidden2)</span><br><span class="line">        self.out = torch.nn.Linear(n_hidden2, n_output)   <span class="comment"># output layer</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x1 = Fun.relu(self.hidden1(x))</span><br><span class="line">        x2 = Fun.relu(self.hidden2(x1))</span><br><span class="line">        x =  self.out(x2)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><br>And then I use GridSearchCV to try different number of hidden units. And also I used cross validation (randomly sampling 80% of the training instances to train a classifier and then testing it on the remaining 20%). I set the max epochs is 30 for all dataset. And this time I used Adma instead of SGD. Because by experiment,  Adma is faster than SGD to convergence.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line">net = NeuralNetClassifier(</span><br><span class="line">        Net_2hidden(n_hidden1=<span class="number">500</span>, n_hidden2=<span class="number">100</span>),</span><br><span class="line">        max_epochs=<span class="number">30</span>,</span><br><span class="line">        lr=<span class="number">0.001</span>,</span><br><span class="line">        optimizer=torch.optim.Adam,<span class="comment">#torch.optim.SGD,</span></span><br><span class="line">        criterion=torch.nn.CrossEntropyLoss,</span><br><span class="line">        iterator_train__shuffle=<span class="literal">True</span>,</span><br><span class="line">        )</span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">'module__n_hidden1'</span>: [<span class="number">50</span>,<span class="number">75</span>,<span class="number">100</span>],<span class="comment">#,500],</span></span><br><span class="line">    <span class="string">'module__n_hidden2'</span>: [<span class="number">10</span>,<span class="number">15</span>,<span class="number">20</span>],<span class="comment">#100]</span></span><br><span class="line">&#125;</span><br><span class="line">gs = GridSearchCV(net, params, refit=<span class="literal">False</span>, cv=<span class="number">5</span>, scoring=<span class="string">'accuracy'</span>)</span><br><span class="line">train_X,train_Y = torch.FloatTensor(train_images),torch.LongTensor(train_labels)</span><br><span class="line">gs.fit(train_X,train_Y)</span><br><span class="line">print(gs.best_score_, gs.best_params_)</span><br></pre></td></tr></table></figure><br>After <code>10 minutes</code> train and test, GridSearchCV get the best params with <code>{&#39;module__n_hidden1&#39;: 75, &#39;module__n_hidden2&#39;: 20}</code>.<br>I was surprised to see that the first layer was 75 instead of 100, because in general, the larger the number of cells or the closer to the input layer model, the better the performance. After many experiments, I have come to a conclusion. The first hidden layer is 75 instead of 100, mainly because the largest parameter of the second hidden layer is 20, and the span before 100 to 20 is too large, which may cause too much loss here. Therefore, for the latter layer is 20 units, the first layer chooses 75 units to perform better.</p>
<p>And the final model get the <code>accuracy with 84%</code> on the 1000 test dataset. For each class, the accuracy as follows.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">       <span class="class"><span class="keyword">class</span>    <span class="title">precision</span>    <span class="title">recall</span>  <span class="title">f1</span>-<span class="title">score</span>   <span class="title">support</span></span></span><br><span class="line"><span class="class">           0       0.78      0.78      0.78       107</span></span><br><span class="line"><span class="class">           1       0.93      0.95      0.94       105</span></span><br><span class="line"><span class="class">           2       0.78      0.82      0.80       111</span></span><br><span class="line"><span class="class">           3       0.78      0.75      0.77        93</span></span><br><span class="line"><span class="class">           4       0.74      0.80      0.77       115</span></span><br><span class="line"><span class="class">           5       0.93      0.90      0.91        87</span></span><br><span class="line"><span class="class">           6       0.63      0.56      0.59        97</span></span><br><span class="line"><span class="class">           7       0.91      0.95      0.93        95</span></span><br><span class="line"><span class="class">           8       0.97      0.93      0.95        95</span></span><br><span class="line"><span class="class">           9       0.94      0.93      0.93        95</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">    <span class="title">accuracy</span>                           0.83      1000</span></span><br><span class="line"><span class="class">   <span class="title">macro</span> <span class="title">avg</span>       0.84      0.84      0.84      1000</span></span><br><span class="line"><span class="class"><span class="title">weighted</span> <span class="title">avg</span>       0.83      0.83      0.83      1000</span></span><br></pre></td></tr></table></figure><br>As we can see, the class 6 get the lowest accuracy.</p>
<h2 id="Improve-build-CNN-net"><a href="#Improve-build-CNN-net" class="headerlink" title="Improve: build CNN net"></a>Improve: build CNN net</h2><p>As we know, CNN make a good performance on image. So I try a 3<em>3 CNN model, try to improve the performance  of model.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Cnn</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, dropout=<span class="number">0.4</span>)</span>:</span></span><br><span class="line">        super(Cnn, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">32</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>)</span><br><span class="line">        self.conv2_drop = nn.Dropout2d(p=dropout)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">1600</span>, <span class="number">800</span>) <span class="comment"># 1600 = number channels * width * height</span></span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">800</span>, <span class="number">10</span>)</span><br><span class="line">        self.fc1_drop = nn.Dropout(p=dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = torch.relu(F.max_pool2d(self.conv1(x), <span class="number">2</span>))</span><br><span class="line">        x = torch.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), <span class="number">2</span>))</span><br><span class="line">        <span class="comment"># flatten over channel, height and width = 1600</span></span><br><span class="line">        x = x.view(<span class="number">-1</span>, x.size(<span class="number">1</span>) * x.size(<span class="number">2</span>) * x.size(<span class="number">3</span>))</span><br><span class="line">        x = self.fc1_drop(torch.relu(self.fc1(x)))</span><br><span class="line">        x = torch.softmax(self.fc2(x), dim=<span class="number">-1</span>)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><br>After many attempts, I chose <code>max_epics = 200</code>, the <code>learning rate is 0.0005</code>, and the <code>optimizer is Adam.</code> The internal parameters of the model have been fixed after several attempts. In the end, <em>*88.8% of the accuracy</em></em> is obtained in 1000 test sets.<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">  epoch    train_loss    valid_acc    valid_loss     dur</span><br><span class="line">-------  ------------  -----------  ------------  ------</span><br><span class="line">      1        5.0852       0.7520        0.9469  0.3805</span><br><span class="line">     50        0.1847       0.8795        0.3360  0.3779</span><br><span class="line">    100        0.0694       0.8860        0.3733  0.3614</span><br><span class="line">    150        0.0336       0.8855        0.4257  0.3691</span><br><span class="line">    200        0.0175       0.8865        0.4704  0.3666</span><br><span class="line">Accuracy on test: 0.888</span><br></pre></td></tr></table></figure><br>Again I compute the accuracy for each class.<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">        <span class="class"><span class="keyword">class</span>  <span class="title">precision</span>    <span class="title">recall</span>  <span class="title">f1</span>-<span class="title">score</span>   <span class="title">support</span></span></span><br><span class="line"><span class="class">           0       0.91      0.80      0.85       107</span></span><br><span class="line"><span class="class">           1       0.99      0.99      0.99       105</span></span><br><span class="line"><span class="class">           2       0.82      0.84      0.83       111</span></span><br><span class="line"><span class="class">           3       0.91      0.85      0.88        93</span></span><br><span class="line"><span class="class">           4       0.85      0.85      0.85       115</span></span><br><span class="line"><span class="class">           5       0.93      0.95      0.94        87</span></span><br><span class="line"><span class="class">           6       0.66      0.75      0.71        97</span></span><br><span class="line"><span class="class">           7       0.92      0.97      0.94        95</span></span><br><span class="line"><span class="class">           8       0.97      0.97      0.97        95</span></span><br><span class="line"><span class="class">           9       0.98      0.93      0.95        95</span></span><br><span class="line"><span class="class">           </span></span><br><span class="line"><span class="class">    <span class="title">accuracy</span>                           0.89      1000</span></span><br><span class="line"><span class="class">   <span class="title">macro</span> <span class="title">avg</span>       0.89      0.89      0.89      1000</span></span><br><span class="line"><span class="class"><span class="title">weighted</span> <span class="title">avg</span>       0.89      0.89      0.89      1000</span></span><br></pre></td></tr></table></figure><br>As we can see, still for the class 6 it’s hard to classify, only 66% accuracy.</p>
<h2 id="Compare-CNN-and-MLP"><a href="#Compare-CNN-and-MLP" class="headerlink" title="Compare CNN and MLP"></a>Compare CNN and MLP</h2><p>By  tensorboard, we can intuitively compare the loss trends of the two models. When I set the maximum number of iterations of both models to 50, the MLP of the two layers decreased significantly faster in terms of training loss, but in the loss of the test set, the MLP of the two layers first decreased and then increased. Fitted. So the optimal number of iterations for two-layer MLP is around 10 words.</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200417202326.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<p>For the CNN model, because I added the characteristics of the Dropout layer and the CNN model itself, the iteration of the model to 50 layers is still in a decline in loss, and the accuracy of the verification set is increasing.</p>
<h2 id="Error-analysis-and-Optimization-direction"><a href="#Error-analysis-and-Optimization-direction" class="headerlink" title="Error analysis and Optimization direction"></a>Error analysis and Optimization direction</h2><p>In order to further study why it is wrong, I printed out a sample of prediction errors. I chose the most representative group to explain. </p>
<p>In the picture, we can see that these six pictures are all shoes, and their classification also belongs to [5,7,9].<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200417014003.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>The prediction range is also [5,7,9], but the model does not find the difference between shoes. To be honest, it’s hard for the naked eye to see the obvious difference between [5,7,9]. Therefore, it’s understandable that the model is not clear.</p>
<p>For the above question, I think we can use the <strong><em>hierarchical prediction method</em></strong>. For example, train a model to distinguish whether shoes or clothes are needed. Then train a model for shoes to capture the subtle differences between shoes. In this way, I think the accuracy can be further improved.</p>
]]></content>
      <categories>
        <category>pytorch</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>pytorch初体验</title>
    <url>/2020/pytorch1/</url>
    <content><![CDATA[<p>上一次写神经网络应该还是大三的时候学TensorFlow，当时学了也没怎么用，最近作业需要pytorch，刚好整理一下pytorch的入门第一讲。<br>pytorch和numpy在很多地方相似，使用简单，最近使用量有超过TF的势头。<br>这一节通过对于一个简单的numpy网络，一步一步改进使用pytorch的高级接口。</p><a id="more"></a>
<ul>
<li>Step 0: numpy 定义每一步的操作，包括Forward, loss, Backward, updata weight<br>（如果这里看不懂需要去看神经网络的基本知识）</li>
</ul>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"><span class="comment"># 随机创建一些训练数据</span></span><br><span class="line">x = np.random.randn(N, D_in)</span><br><span class="line">y = np.random.randn(N, D_out) </span><br><span class="line">w1 = np.random.randn(D_in, H)</span><br><span class="line">w2 = np.random.randn(H, D_out)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass</span></span><br><span class="line">    h = x.dot(w1) <span class="comment"># N * H</span></span><br><span class="line">    h_relu = np.maximum(h, <span class="number">0</span>) <span class="comment"># N * H</span></span><br><span class="line">    y_pred = h_relu.dot(w2) <span class="comment"># N * D_out</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute loss</span></span><br><span class="line">    loss = np.square(y_pred - y).mean()</span><br><span class="line">    <span class="keyword">if</span> it%<span class="number">100</span>==<span class="number">0</span>: print(it, loss)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Backward pass</span></span><br><span class="line">    <span class="comment"># compute the gradient</span></span><br><span class="line">    grad_y_pred = <span class="number">2.0</span> * (y_pred - y)</span><br><span class="line">    grad_w2 = h_relu.T.dot(grad_y_pred)</span><br><span class="line">    grad_h_relu = grad_y_pred.dot(w2.T)</span><br><span class="line">    grad_h = grad_h_relu.copy()</span><br><span class="line">    grad_h[h&lt;<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    grad_w1 = x.T.dot(grad_h)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># update weights of w1 and w2</span></span><br><span class="line">    w1 -= learning_rate * grad_w1</span><br><span class="line">    w2 -= learning_rate * grad_w2</span><br></pre></td></tr></table></figure>
<ul>
<li>Step 1: 现在把数据类型换成torch的数据接口</li>
</ul>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"><span class="comment"># 随机创建一些训练数据</span></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line">w1 = torch.randn(D_in, H)</span><br><span class="line">w2 = torch.randn(H, D_out)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line">  <span class="keyword">for</span> it <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass</span></span><br><span class="line">    h = x.mm(w1) <span class="comment"># N * H</span></span><br><span class="line">    h_relu = h.clamp(min=<span class="number">0</span>) <span class="comment"># N * H #上下限</span></span><br><span class="line">    y_pred = h_relu.mm(w2) <span class="comment"># N * D_out</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute loss</span></span><br><span class="line">    loss = (y_pred - y).pow(<span class="number">2</span>).sum().item()</span><br><span class="line">    <span class="keyword">if</span> it%<span class="number">100</span>==<span class="number">0</span> :print(it, loss)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Backward pass</span></span><br><span class="line">    <span class="comment"># compute the gradient</span></span><br><span class="line">    grad_y_pred = <span class="number">2.0</span> * (y_pred - y)</span><br><span class="line">    grad_w2 = h_relu.t().mm(grad_y_pred)</span><br><span class="line">    grad_h_relu = grad_y_pred.mm(w2.t())</span><br><span class="line">    grad_h = grad_h_relu.clone()</span><br><span class="line">    grad_h[h&lt;<span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    grad_w1 = x.t().mm(grad_h)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># update weights of w1 and w2</span></span><br><span class="line">    w1 -= learning_rate * grad_w1</span><br><span class="line">    w2 -= learning_rate * grad_w2</span><br></pre></td></tr></table></figure>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200415130238.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>通过对比，可以发现基本没有差异，就是矩阵计算的符号有所改变。</p>
<ul>
<li>Step 2:  PyTorch的一个重要功能就是autograd，也就是说只要定义了forward pass(前向神经网络)，计算了loss之后，PyTorch可以自动求导计算模型所有参数的梯度。一个PyTorch的Tensor表示计算图中的一个节点。如果<code>x</code>是一个Tensor并且<code>x.requires_grad=True</code>那么<code>x.grad</code>是另一个储存着<code>x</code>当前梯度(相对于一个scalar，常常是loss)的向量。</li>
</ul>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机创建一些训练数据</span></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line">w1 = torch.randn(D_in, H, requires_grad=<span class="literal">True</span>)</span><br><span class="line">w2 = torch.randn(H, D_out, requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass</span></span><br><span class="line">    y_pred = x.mm(w1).clamp(min=<span class="number">0</span>).mm(w2)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute loss</span></span><br><span class="line">    loss = (y_pred - y).pow(<span class="number">2</span>).sum() <span class="comment"># computation graph</span></span><br><span class="line">    <span class="keyword">if</span> it%<span class="number">100</span>==<span class="number">0</span>: print(it, loss.item())</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Backward pass</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># update weights of w1 and w2</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        w1 -= learning_rate * w1.grad</span><br><span class="line">        w2 -= learning_rate * w2.grad</span><br><span class="line">        w1.grad.zero_()</span><br><span class="line">        w2.grad.zero_()</span><br></pre></td></tr></table></figure>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200415131917.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<ul>
<li>Step 3:  调用torch.nn.Sequential来定义网络</li>
</ul>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"><span class="comment"># 随机创建一些训练数据</span></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line">model = torch.nn.Sequential(</span><br><span class="line">    torch.nn.Linear(D_in, H, bias=<span class="literal">False</span>), <span class="comment"># w_1 * x + b_1</span></span><br><span class="line">    torch.nn.ReLU(),</span><br><span class="line">    torch.nn.Linear(H, D_out, bias=<span class="literal">False</span>),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">torch.nn.init.normal_(model[<span class="number">0</span>].weight)</span><br><span class="line">torch.nn.init.normal_(model[<span class="number">2</span>].weight)</span><br><span class="line"></span><br><span class="line"><span class="comment"># model = model.cuda()</span></span><br><span class="line"></span><br><span class="line">loss_fn = nn.MSELoss(reduction=<span class="string">'sum'</span>)</span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass</span></span><br><span class="line">    y_pred = model(x) <span class="comment"># model.forward() </span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute loss</span></span><br><span class="line">    loss = loss_fn(y_pred, y) <span class="comment"># computation graph</span></span><br><span class="line">    <span class="keyword">if</span> it%<span class="number">100</span>==<span class="number">0</span> :print(it, loss.item())</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Backward pass</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># update weights of w1 and w2</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> model.parameters(): <span class="comment"># param (tensor, grad)</span></span><br><span class="line">            param -= learning_rate * param.grad</span><br><span class="line">            </span><br><span class="line">    model.zero_grad()</span><br></pre></td></tr></table></figure>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200415132645.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<ul>
<li>Step 4:  这一次我们不再手动更新模型的weights,而是使用optim这个包来帮助我们更新参数。 optim这个package提供了各种不同的模型优化方法，包括SGD+momentum, RMSProp, Adam等等。</li>
</ul>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机创建一些训练数据</span></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line">model = torch.nn.Sequential(</span><br><span class="line">    torch.nn.Linear(D_in, H, bias=<span class="literal">False</span>), <span class="comment"># w_1 * x + b_1</span></span><br><span class="line">    torch.nn.ReLU(),</span><br><span class="line">    torch.nn.Linear(H, D_out, bias=<span class="literal">False</span>),</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">torch.nn.init.normal_(model[<span class="number">0</span>].weight)</span><br><span class="line">torch.nn.init.normal_(model[<span class="number">2</span>].weight)</span><br><span class="line"></span><br><span class="line"><span class="comment"># model = model.cuda()</span></span><br><span class="line"></span><br><span class="line">loss_fn = nn.MSELoss(reduction=<span class="string">'sum'</span>)</span><br><span class="line"><span class="comment"># learning_rate = 1e-4</span></span><br><span class="line"><span class="comment"># optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)</span></span><br><span class="line"></span><br><span class="line">learning_rate = <span class="number">1e-6</span></span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass</span></span><br><span class="line">    y_pred = model(x) <span class="comment"># model.forward() </span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute loss</span></span><br><span class="line">    loss = loss_fn(y_pred, y) <span class="comment"># computation graph</span></span><br><span class="line">    <span class="keyword">if</span> it%<span class="number">100</span>==<span class="number">0</span> :print(it, loss.item())</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad() <span class="comment">#梯度初始化为零</span></span><br><span class="line">    <span class="comment"># Backward pass</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># update model parameters</span></span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200415133029.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<ul>
<li>Step 5: 这个模型继承自nn.Module类。如果需要定义一个比Sequential模型更加复杂的模型，就需要定义nn.Module模型。</li>
</ul>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line">N, D_in, H, D_out = <span class="number">64</span>, <span class="number">1000</span>, <span class="number">100</span>, <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机创建一些训练数据</span></span><br><span class="line">x = torch.randn(N, D_in)</span><br><span class="line">y = torch.randn(N, D_out)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TwoLayerNet</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, D_in, H, D_out)</span>:</span></span><br><span class="line">        super(TwoLayerNet, self).__init__()</span><br><span class="line">        <span class="comment"># define the model architecture</span></span><br><span class="line">        self.linear1 = torch.nn.Linear(D_in, H, bias=<span class="literal">False</span>)</span><br><span class="line">        self.linear2 = torch.nn.Linear(H, D_out, bias=<span class="literal">False</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        y_pred = self.linear2(self.linear1(x).clamp(min=<span class="number">0</span>))</span><br><span class="line">        <span class="keyword">return</span> y_pred</span><br><span class="line"></span><br><span class="line">model = TwoLayerNet(D_in, H, D_out)</span><br><span class="line">loss_fn = nn.MSELoss(reduction=<span class="string">'sum'</span>)</span><br><span class="line">learning_rate = <span class="number">1e-4</span></span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> range(<span class="number">500</span>):</span><br><span class="line">    <span class="comment"># Forward pass</span></span><br><span class="line">    y_pred = model(x) <span class="comment"># model.forward() </span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># compute loss</span></span><br><span class="line">    loss = loss_fn(y_pred, y) <span class="comment"># computation graph</span></span><br><span class="line">    <span class="keyword">if</span> it%<span class="number">100</span>==<span class="number">0</span> :print(it, loss.item())</span><br><span class="line"></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    <span class="comment"># Backward pass</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># update model parameters</span></span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200415133427.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<p>通过一步一步的改进，从numpy使用上了torch的接口，还真是收获满满的一天呢。🤪</p>
]]></content>
      <categories>
        <category>pytorch</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>MSBD5004 Mathematical Methods for Data Analysis Homework 3</title>
    <url>/2020/MSBD5004-Mathematical-Methods-for-Data-Analysis-Homework-3/</url>
    <content><![CDATA[<blockquote>
<p>最近学的开始有意思了。题也没那么好做了。<br>MSBD5004 Mathematical Methods for Data Analysis Homework 3</p>
</blockquote><h1 id="Q1"><a href="#Q1" class="headerlink" title="Q1"></a>Q1</h1><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200331112512.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p><p><strong><em>Solution:</em></strong> All use the standard inner product$\left\langle A,B\right \rangle =\sum_{1\le j\le n}\sum_{1\le i\le n}a_{i,j}b_{i,j}$.</p><a id="more"></a>


<h2 id="a"><a href="#a" class="headerlink" title="(a)"></a>(a)</h2><p>We can define the $A_{i=s,j=t}=1,A_{i\not=s,j\not=t}=0$, then we can get $E_{st}(X)=\langle A,X \rangle =x_{st}$.<br>◾</p>
<h2 id="b"><a href="#b" class="headerlink" title="(b)"></a>(b)</h2><p>We can define the $A_{i=j}=1,A_{i\not=j}=0$, then we can get $Tr(X)=\langle A,X \rangle =\sum_{i=1}^n x_{ii}$.<br>◾</p>
<h2 id="c"><a href="#c" class="headerlink" title="(c)"></a>(c)</h2><script type="math/tex; mode=display">f(x)=|\langle a,x \rangle |^2=(\sum_{i=1}^n a_ix_i)(\sum_{i=1}^n a_ix_i)=\sum_{i=1}^n\sum_{j=1}^n a_ia_jx_ix_j=\langle aa^T,xx^T \rangle</script><p>So we can define the $A=aa^T$.<br>◾</p>
<h1 id="Q2"><a href="#Q2" class="headerlink" title="Q2"></a>Q2</h1><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200331102810.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<h2 id="a-1"><a href="#a-1" class="headerlink" title="(a)"></a>(a)</h2><p><strong>Proof:</strong><br>If $\boldsymbol{x}, \boldsymbol{z} \in S_{1} \cap S_{2},$ then we can get </p>
<script type="math/tex; mode=display">\langle a_1, \boldsymbol{x} \rangle =\langle a_1,\boldsymbol{z} \rangle =b_1\\
\langle a_2, \boldsymbol{x} \rangle =\langle a_2,\boldsymbol{z} \rangle = b_2
$$For any $t \in \mathbb{R}$, we have
$$\langle a_1, (1+t) \boldsymbol{z}-t \boldsymbol{x}\rangle =(1+t)\langle a_1,\boldsymbol{z}\rangle -t\langle a_1,\boldsymbol{x}\rangle =b_1\\
\langle a_2, (1+t) \boldsymbol{z}-t \boldsymbol{x} \rangle =(1+t)\langle a_2,\boldsymbol{z}\rangle -t\langle a_2,\boldsymbol{x}\rangle = b_2</script><p>So $(1+t) \boldsymbol{z}-t \boldsymbol{x}\in S_{1}$ and $(1+t) \boldsymbol{z}-t \boldsymbol{x}\in S_{2}$ respectively.<br>So $(1+t) \boldsymbol{z}-t \boldsymbol{x} \in S_{1} \cap S_{2}$ for any $t \in \mathbb{R}$.<br>So $S_{1} \cap S_{2}$ is a plane.<br>◾</p>
<h2 id="b-1"><a href="#b-1" class="headerlink" title="(b)"></a>(b)</h2><p>①: $\boldsymbol{z}$ is solution of $\min _{\boldsymbol{x} \in S_{1} \cap S_{2}}|\boldsymbol{x}-\boldsymbol{y}|$<br>②: $\langle\boldsymbol{z}-\boldsymbol{y}, \boldsymbol{z}-\boldsymbol{x}\rangle=0,  \forall \boldsymbol{x} \in S_{1} \cap S_{2},\boldsymbol{z} \in S_{1} \cap S_{2}$</p>
<ul>
<li>$①\rightarrow②$ </li>
</ul>
<p>As (a) result, $(1+t) \boldsymbol{z}-t \boldsymbol{x} \in S_{1} \cap S_{2}$ for any $t \in \mathbb{R}$.<br>Since Z is closest to y on $S_{1} \cap S_{2}$, we have</p>
<script type="math/tex; mode=display">\begin{aligned}
\|  z-y \|^{2} & \leqslant\|(1+t) z-t x-y\|^{2} \\
&=\|(z-y)+t(z-x)\|^{2} \\
&\left.=\|z-y\|^{2}+t^{2}\|z-x\|^{2}+2 t\langle z-y, z-x\right\rangle \\
i \cdot e \cdot, \quad t\langle z &-y, z-x\rangle \ \geq -\frac{t^{2}}{2}\|z-x\|^{2}
\end{aligned}</script><p>If we choose $t&gt; 0$ , letting $t\rightarrow0_+$ gives $\langle z -y, z-x\rangle\geq 0$.<br>If we choose $t&gt; 0$ , letting $t\rightarrow0_-$ gives $\langle z -y, z-x\rangle\leq 0$.<br>Altogether, $z$ satisfies $\langle z -y, z-x\rangle= 0,\forall \boldsymbol{x} \in S_{1} \cap S_{2}$</p>
<ul>
<li>$②\rightarrow①$ </li>
</ul>
<p>Since$\langle \boldsymbol{z}-y, \boldsymbol{z}-x\rangle=0 , \forall \boldsymbol{x} \in S_{1} \cap S_{2}$</p>
<script type="math/tex; mode=display">\begin{aligned}
\|x-y\|^{2} &=\|(z-x)-(z-y)\|^{2} \\
&=\|z-x\|^{2}+\|z-y\|^{2}-2\langle z-x, z-y\rangle \\
&=\|z-y\|^{2}+\|z-x\|^{2} \geq\|z-y\|^{2} \quad \boldsymbol{x} \in S_{1} \cap S_{2}
\end{aligned}</script><p>This together with $\boldsymbol{z} \in S_{1} \cap S_{2}$ implies z minimizes $|\boldsymbol{z}-y|^{2}$ in $\boldsymbol{x} \in S_{1} \cap S_{2}$.<br>◾</p>
<h2 id="c-1"><a href="#c-1" class="headerlink" title="(c)"></a>(c)</h2><p>Because $\boldsymbol{z}$ need satisfies $\langle \boldsymbol{z} -y, \boldsymbol{z}-x\rangle= 0$, so set $\boldsymbol{z}=m a_{1}+n a_{2}+y$, and $\boldsymbol{z} \in S_{1} \cap S_{2}$ so we can get this two equation.</p>
<script type="math/tex; mode=display">\left\{\begin{array}{l}\langle m a_{1}+n a_{2}+y, a_{1}\rangle =b_{1} \\ \langle m a_{1}+n a_{2}+y_{2} a_{2}\rangle =b_{2}\end{array}\right.</script><p>$Simplify \downarrow$</p>
<script type="math/tex; mode=display">\left\{\begin{array}{l}
m\langle a_{1}, a_{1}\rangle +n\langle a_{2}, a_{1}\rangle =b_{1}-\langle a_{1}, y\rangle  \\
m\langle a_{1}, a_{2}\rangle +n\langle a_{2}, a_{2}\rangle =b_{2}-\langle a_{2}, y\rangle 
\end{array}\right.</script><p>$Simplify \downarrow$</p>
<script type="math/tex; mode=display">\left\{\begin{array}{l}
m=\frac{[b_{1}-\langle a_{1}, y\rangle ]\|a_2\|^2-[b_{2}-\langle a_{2}, y\rangle ]\langle a_1,a_2\rangle  }{\|a_1\|^2\|a_2\|^2-\langle a_1,a_2\rangle ^2}\\
n=\frac{[b_{1}-\langle a_{1}, y\rangle ]\langle a_1,a_2\rangle -[b_{2}-\langle a_{2}, y\rangle ]\|a_1\|^2 }{\langle a_1,a_2\rangle ^2-\|a_1\|^2\|a_2\|^2} 
\end{array}\right.</script><p>Then we can get the explicit solution is $\boldsymbol{z}=m a_{1}+n a_{2}+y$.<br>◾</p>
<h2 id="d"><a href="#d" class="headerlink" title="(d)"></a>(d)</h2><p>Suppose we have two solutions $\boldsymbol{z_1}$ and $\boldsymbol{z_2}$. Then<br>$\boldsymbol{z_1}$ is a solution, $\rightarrow$ $\langle \boldsymbol{z_1} -y, \boldsymbol{z_1}-\boldsymbol{z_2}\rangle= 0$.<br>$\boldsymbol{z_2}$ is a solution, $\rightarrow$ $\langle \boldsymbol{z_2} -y, \boldsymbol{z_2}-\boldsymbol{z_1}\rangle= 0$.<br>Taking difference leads to $\langle \boldsymbol{z_1} -\boldsymbol{z_2}, \boldsymbol{z_1}-\boldsymbol{z_2}\rangle= 0$.<br>So $|\boldsymbol{z_1}-\boldsymbol{z_2}|^2=0,\boldsymbol{z_1}=\boldsymbol{z_2}$ . It’s unique.<br>◾</p>
<h1 id="Q3"><a href="#Q3" class="headerlink" title="Q3"></a>Q3</h1><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200331102826.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<h2 id="a-2"><a href="#a-2" class="headerlink" title="(a)"></a>(a)</h2><p>For any $a \in H$, we claim that $a$ can be decomposed into a a part in training data space and a part which is orthogonal to it.</p>
<script type="math/tex; mode=display">a = a_s + \sum_{i=1}^Nc_i \boldsymbol{x}_i,where \boldsymbol{c}=[c_1,c_2,...c_N]^T \in \mathbb{R}^N,and \langle a_s, x_i \rangle=0,for i=1,2,...N</script><p>Therefore,</p>
<script type="math/tex; mode=display">
\begin{aligned}
&\sum_{i=1}^{N}\left(\left\langle\boldsymbol{a}, \boldsymbol{x}_{i}\right\rangle-y_{i}\right)^{2}+\lambda\|\boldsymbol{a}\|_{2}^{2} \\&=\sum_{i=1}^{N}\left(\left\langle a_s + \sum_{i=1}^Nc_i \boldsymbol{x}_i, \boldsymbol{x}_{i}\right\rangle-y_{i}\right)^{2}+\lambda\| a_s + \sum_{i=1}^Nc_i \boldsymbol{x}_i \|_{2}^{2}\\
&=\sum_{i=1}^{N}\left(\sum_{i=1}^Nc_i    \boldsymbol{x}_i \boldsymbol{x}_{j}-y_{i}\right)^{2}+\lambda(\sum_{i=1}^N\sum_{i=1}^Nc_i c_j   \boldsymbol{x}_i\boldsymbol{x}_{j} +\|a_s\|^2_2)\\
&=\|KC-y\|_2^2+\lambda C^TKC+\lambda  \|a_s\|^2_2
\end{aligned}</script><p>where $K=\left[\begin{array}{c}\boldsymbol{x}_{1} \\ \boldsymbol{x}_{2} \\ \vdots \\ \boldsymbol{x}_{N}\end{array}\right]\cdot \left[\begin{array}{c}\boldsymbol{x}_{1} , \boldsymbol{x}_{2} ,\dots ,\boldsymbol{x}_{N}\end{array}\right]$, $C=\left[\begin{array}{c}c_{1} \\ c_{2} \\ \vdots \\ c_{N}\end{array}\right] \in \mathbb{R}^{N}$<br>Because $|a_s|^2_2 \geq 0$, the objective function is minimized when $|a_s|^2_2=0$<br>Thus, the solution must in the form$a =  \sum_{i=1}^Nc_i \boldsymbol{x}_i$.<br>◾</p>
<h2 id="b-2"><a href="#b-2" class="headerlink" title="(b)"></a>(b)</h2><p>From (a) we can get </p>
<script type="math/tex; mode=display">
\begin{aligned}
&\min _{\boldsymbol{a} \in \mathbb{R}^{n}}\sum_{i=1}^{N}\left(\left\langle\boldsymbol{a}, \boldsymbol{x}_{i}\right\rangle-y_{i}\right)^{2}+\lambda\|\boldsymbol{a}\|_{2}^{2} 
\\&= \min _{\boldsymbol{c} \in \mathbb{R}^{N}} \|KC-y\|_2^2+\lambda C^TKC+\lambda  \|a_s\|^2_2
\end{aligned}</script><p>The unknowns from $\boldsymbol{a}\in \mathbb{R}^{n}$ become $\boldsymbol{c}\in \mathbb{R}^{N}$ N (N&lt;n), which has fewer unknowns than original formulation.</p>
]]></content>
      <categories>
        <category>5004</category>
      </categories>
  </entry>
  <entry>
    <title>CS224n-9-如何做好project?</title>
    <url>/2020/CS224n-9/</url>
    <content><![CDATA[<blockquote>
<p>这节主要是介绍project的要求，也重新提到了LSTM，GRU，还有一些trick. 比较杂。</p>
</blockquote><h1 id="project选择问题"><a href="#project选择问题" class="headerlink" title="project选择问题"></a>project选择问题</h1><ul>
<li>默认的Task: Building a textual question answering system for SQuAD<br>• Stanford Question Answering Dataset<br>• <a href="https://rajpurkar.github.io/SQuAD-explorer/" target="_blank" rel="noopener">https://rajpurkar.github.io/SQuAD-explorer/</a><br> 这个任务相当于在做英语阅读题，输入一段话和一个问题，输出是否有答案，答案是哪个单词。 </li>
<li>Custom Final Project： 大佬自己去研究吧</li>
</ul><a id="more"></a>

<h1 id="project的探索方向"><a href="#project的探索方向" class="headerlink" title="project的探索方向"></a>project的探索方向</h1><ol>
<li>找新的任务，用就的方法</li>
<li>调整神经网络的结构，优化性能</li>
<li>提出新的网络，并验证</li>
<li>分析项目，分析现有的模型如何理解语言</li>
<li>Rare theoretical project: Show some interesting, non-trivial properties of a model type, data, or a data representation 没理解<h2 id="往届优秀project"><a href="#往届优秀project" class="headerlink" title="往届优秀project"></a>往届优秀project</h2><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200318013542.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>通过诗集训练生成诗集。结构不复杂，替换数据集就是新任务，可以之后参考仿照着做。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200318013834.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>通过压缩数据长度，来优化计算速度。(很常见的方法)<h2 id="找方向，读论文"><a href="#找方向，读论文" class="headerlink" title="找方向，读论文"></a>找方向，读论文</h2>其他的方法去寻找论文  ，不过对我来说，我觉得找两个别人做好的项目，复现一下就不错了。🤪<br><a href="https://aclanthology.info" target="_blank" rel="noopener">https://aclanthology.info</a><br><a href="https://paperswithcode.com/sota" target="_blank" rel="noopener">https://paperswithcode.com/sota</a><br><a href="http://www.arxiv-sanity.com" target="_blank" rel="noopener">http://www.arxiv-sanity.com</a></li>
</ol>
<p>注意：<br>数据最好完整，任务可行，一点要有可以自动评价的指标。(很多任务都不好评价结果)</p>
<h2 id="找数据"><a href="#找数据" class="headerlink" title="找数据"></a>找数据</h2><p><a href="https://catalog.ldc.upenn.edu/" target="_blank" rel="noopener">https://catalog.ldc.upenn.edu/</a><br><a href="https://linguistics.stanford.edu/resources/resources-corpora" target="_blank" rel="noopener">https://linguistics.stanford.edu/resources/resources-corpora</a><br>机器翻译 <a href="http://statmt.org" target="_blank" rel="noopener">http://statmt.org</a><br>kaggle/github</p>
<blockquote>
<p>然后又讲了一遍梯度消失爆炸，LSTM，GRU 就不赘述了。 主要是理解GRU用一个门，控制两边的输入量。</p>
</blockquote>
<h1 id="翻译中词汇量太大的问题"><a href="#翻译中词汇量太大的问题" class="headerlink" title="翻译中词汇量太大的问题"></a>翻译中词汇量太大的问题</h1><p>一般语言中，常用词就几万个，但是低频词还有很多(十几万)，计算速度慢，如何解决呢？</p>
<ul>
<li>在训练和测试集上，都限制词汇量，删除含有低频词的样本。</li>
<li>Attention</li>
<li>噪声对比估计（NCE，Noise-Contrastive Estimation），判断出没有实际含义的词，剔除</li>
<li>Hierarchical softmax (word2vec的优化技巧)</li>
</ul>
<h1 id="做课堂project的基本步骤"><a href="#做课堂project的基本步骤" class="headerlink" title="做课堂project的基本步骤"></a>做课堂project的基本步骤</h1><ol>
<li>定义问题。比如：翻译、总结、问答</li>
<li>找数据集。最好是已经有了baseline</li>
<li>清洗数据。分开text数据和devtest数据</li>
<li>定义评价指标。不同任务评价指标不同。</li>
<li>建立baseline。比如LR，然后看baseline的得分，分析baseline的问题</li>
<li>尝试已经存在的网络模型。</li>
<li>分析数据。可视化，统计信息，查看错误预测，分析超参数</li>
<li>尝试其他的模型。</li>
</ol>
<h1 id="RNN的注意事项"><a href="#RNN的注意事项" class="headerlink" title="RNN的注意事项"></a>RNN的注意事项</h1><ol>
<li>使用LSTM或GRU：它使您的生活变得更加简单！</li>
<li>初始化递归矩阵为正交</li>
<li>用合理的（小）标度初始化其他矩阵</li>
<li>将“遗忘门”偏差初始化为1(默认为记住)</li>
<li>使用自适应学习率算法：Adam，AdaDelta</li>
<li>裁剪渐变的范数：1-5似乎是合理的与Adam或AdaDelta一起使用时的阈值。</li>
<li>Either only dropout vertically or look into using Bayesian Dropout (Gal and Gahramani – not natively in PyTorch)</li>
<li>要有耐心！</li>
</ol>
<h1 id="指导思想"><a href="#指导思想" class="headerlink" title="指导思想"></a>指导思想</h1><p>从简单入手，逐步增加模型复杂度<br>从小数据入手，可以快速迭代<br>不要怕过拟合，过拟合了可以降下来，但是证明了模型的拟合能力</p>
]]></content>
      <categories>
        <category>CS224n</category>
      </categories>
      <tags>
        <tag>project</tag>
      </tags>
  </entry>
  <entry>
    <title>MSBD5004 Mathematical Methods for Data Analysis Homework 2</title>
    <url>/2020/MSBD5004-Mathematical-Methods-for-Data-Analysis-Homework-2/</url>
    <content><![CDATA[<p>MSBD5004 Mathematical Methods for Data Analysis Homework 2</p><blockquote>
<p>基础证明，感觉题不多，还是继续打出来了。</p>
</blockquote><h1 id="Q1"><a href="#Q1" class="headerlink" title="Q1"></a>Q1</h1><p>Let $(V,|\cdot|)$ be a normed vector space.<br>(a) Prove that, for all $x, y \in V$,</p><a id="more"></a>


<script type="math/tex; mode=display">| \|\boldsymbol{x}\|-\|\boldsymbol{y}\| |\leq\|\boldsymbol{x}-\boldsymbol{y}\|</script><p>(b) Let $\left\{x_{k}\right\}_{k \in \mathbb{N}}$ be a convergent sequence in $V$ with limit $x \in V$. Prove that</p>
<script type="math/tex; mode=display">\lim _{k \rightarrow \infty}\left\|x_{k}\right\|=\|x\|</script><p>(Hint: Use part (a).)<br>(c) Let $\left\{x^{(k)}\right\}_{k \in \mathbb{N}}$ be a sequence in $V$ and $x, y \in V .$ Prove that, if</p>
<script type="math/tex; mode=display">x^{(k)} \rightarrow x, \text { and } x^{(k)} \rightarrow y,</script><p>then $x=y .$ (In other words, the limit of the same sequence in a normed vector space is unique.)</p>
<h2 id="a"><a href="#a" class="headerlink" title="(a)"></a>(a)</h2><p>Using the norm definition, we have that $|\boldsymbol{a}+\boldsymbol{b}| \leq|\boldsymbol{a}|+|\boldsymbol{b}|$.<br>$if :\boldsymbol{a}=|\boldsymbol{x}-\boldsymbol{y}| ,\boldsymbol{b}=|\boldsymbol{y}|, then |\boldsymbol{x}| \leq |\boldsymbol{x}-\boldsymbol{y}|  +|\boldsymbol{y}|$<br>$if :\boldsymbol{a}=|\boldsymbol{y}-\boldsymbol{x}| ,\boldsymbol{b}=|\boldsymbol{x}|, then |\boldsymbol{y}| \leq |\boldsymbol{y}-\boldsymbol{x}|  +|\boldsymbol{x}|$<br>From above we can get<script type="math/tex">\|\boldsymbol{x}\|-\|\boldsymbol{y}\| \leq\|\boldsymbol{x}-\boldsymbol{y}\| , and   \|\boldsymbol{y}\|-\|\boldsymbol{x}\| \leq\|\boldsymbol{x}-\boldsymbol{y}\|</script><br>So, $| |\boldsymbol{x}|-|\boldsymbol{y}| |\leq|\boldsymbol{x}-\boldsymbol{y}|$.◾</p>
<h2 id="b"><a href="#b" class="headerlink" title="(b)"></a>(b)</h2><p>Using the converges definition, we can get</p>
<script type="math/tex; mode=display">\lim _{k \rightarrow \infty}\left\|\boldsymbol{x}_{k}-\boldsymbol{x}\right\|=\left\|\lim _{k \rightarrow \infty}\boldsymbol{x}_{k}-\boldsymbol{x}\right\| = 0</script><p>Useing the conclusion of (a),</p>
<script type="math/tex; mode=display">| \lim _{k \rightarrow \infty}\|\boldsymbol{x}_{k}\|-\|\boldsymbol{x}\||=\left\|\lim _{k \rightarrow \infty}\boldsymbol{x}_{k}-\boldsymbol{x}\right\| = 0</script><p>Then, we get $\lim _{k \rightarrow \infty}\left|\boldsymbol{x}_{k}\right|=|\boldsymbol{x}|$.◾</p>
<h2 id="c"><a href="#c" class="headerlink" title="(c)"></a>(c)</h2><p><strong>Proof</strong>: Assume that as $k \rightarrow \infty$ then $x^{(k)} \rightarrow x$ and also $x^{(k)} \rightarrow y .$</p>
<ul>
<li>Let $\epsilon&gt;0$ be given and choose $N_{1} \in \mathbb{N}$ such that<br>$\left|x^{(k)}-x\right|&lt;\frac{\epsilon}{2}$. And also choose $N_{2} \in \mathbb{N}$ such that<br>$\left|x^{(k)}-y\right|&lt;\frac{\epsilon}{2}$.</li>
<li>Now choose $N=\max \left(N_{1}, N_{2}\right)$. Not that the choose the maximum of $N_{1}$ and $N_{2}$, then it will be true that regardless $\left|x^{(k)}-x\right|&lt;\frac{\epsilon}{2}$ and<br>$\left|x^{(k)}-y\right|&lt;\frac{\epsilon}{2}$. Now consider the following inequality:<script type="math/tex; mode=display">|x-y|=\left|x-x^{(k)}+x^{(k)}-y\right|=\left|\left(x-x^{(k)}\right)+\left(x^{(k)}-y\right)\right|</script></li>
<li>By the triangle inequality, we get that:<script type="math/tex; mode=display">|x-y|=\left|\left(x-x^{(k)}\right)+\left(x^{(k)}-y\right)\right| \leq\left|x-x^{(k)}\right|+\left|x^{(k)}-y\right|<\frac{\epsilon}{2}+\frac{\epsilon}{2}=\epsilon</script>Therefore $|x-y|&lt;\epsilon .$  $x-y$ is a number, and $\forall \epsilon&gt;0,|x-y|&lt;\epsilon$. So that $x=y$.◾</li>
</ul>
<h1 id="Q2"><a href="#Q2" class="headerlink" title="Q2"></a>Q2</h1><ol>
<li>Let $V$ be a vector space, and $\langle\cdot, \cdot\rangle$ be an inner product on $V$. Use the definition of inner product to prove the following.<br>(a) Prove that $\langle \boldsymbol{0}, x\rangle=\langle x,  \boldsymbol{0}\rangle= 0$ for any $x \in V .$ Here  $\boldsymbol{0}$ is the zero vector in $V$.<br>(b) Prove that the second condition<br>①<script type="math/tex">\left\langle\alpha x_{1}+\beta x_{2}, y\right\rangle=\alpha\left\langle x_{1}, y\right\rangle+\beta\left\langle x_{2}, y\right\rangle \quad \forall x_{1}, x_{2}, y \in V, \alpha, \beta \in \mathbb{R}</script> is equivalent to ②<script type="math/tex">\left\langle x_{1}+x_{2}, y\right\rangle=\left\langle x_{1}, y\right\rangle+\left\langle x_{2}, y\right\rangle \text { and }\langle\alpha x, y\rangle=\alpha\langle x, y\rangle, \quad \forall x_{1}, x_{2}, x, y \in V, \alpha \in \mathbb{R}</script></li>
</ol>
<h2 id="a-1"><a href="#a-1" class="headerlink" title="(a)"></a>(a)</h2><p>There are 3 condition of definition of inner product:</p>
<script type="math/tex; mode=display">
 \begin{array}{l}\text { (1) } \quad \forall x \in V, \quad\langle x, x\rangle \geq 0 \quad \text { and } \quad\langle x, x\rangle= 0 \Leftrightarrow x=0 \\ \text { (2) }\left.\quad\langle\alpha x_{1}+\beta x_{2}, y\rangle=\alpha\langle x_{1}, y\rangle+\beta\langle x_{2}, y\right\rangle \quad \forall \alpha, \beta \in R, \quad x_{1}, x_{2}, y \in V \\ \text { (3) }\left.\quad \langle x, y\right\rangle=\langle y, x\rangle\end{array}</script><p>Use (3) if $y= \boldsymbol{0}$, we can get  $\langle \boldsymbol{0}, x\rangle=\langle x,  \boldsymbol{0}\rangle$.<br>Use (2) if $y=x,  x_1=x_2=\boldsymbol{0},\alpha=\beta=1$, we can get $\langle \boldsymbol{0}, x\rangle=2*\langle \boldsymbol{0}, x\rangle$, so $\langle \boldsymbol{0}, x\rangle=0$<br>From above, we can get $\langle \boldsymbol{0}, x\rangle=\langle x,  \boldsymbol{0}\rangle= 0$. ◾</p>
<h2 id="b-1"><a href="#b-1" class="headerlink" title="(b)"></a>(b)</h2><p>①<script type="math/tex">\left\langle\alpha x_{1}+\beta x_{2}, y\right\rangle=\alpha\left\langle x_{1}, y\right\rangle+\beta\left\langle x_{2}, y\right\rangle \quad \forall x_{1}, x_{2}, y \in V, \alpha, \beta \in \mathbb{R}</script><br>②<script type="math/tex">\left\langle x_{1}+x_{2}, y\right\rangle=\left\langle x_{1}, y\right\rangle+\left\langle x_{2}, y\right\rangle \text { and }\langle\alpha x, y\rangle=\alpha\langle x, y\rangle, \quad \forall x_{1}, x_{2}, x, y \in V, \alpha \in \mathbb{R}.</script><br><strong>Proof</strong>: </p>
<ul>
<li><p>$①\rightarrow②$ :<br>set $\alpha=\beta=1$, we can get first equation of ②$\forall x_{1}, x_{2}, x, y \in V, \alpha \in \mathbb{R}.$.<br>set $x_1=x, \beta=0$, we can get second equation of ②$\forall x_{1}, x_{2}, x, y \in V, \alpha \in \mathbb{R}.$.</p>
</li>
<li><p>$②\rightarrow①$ :<br>set $x_1= \alpha x_1, x_2= \beta x_2$, we can get<br><script type="math/tex">\left\langle\alpha x_{1}+\beta x_{2}, y\right\rangle=\left\langle\alpha x_{1}, y\right\rangle+\left\langle\beta x_{2}, y\right\rangle=\alpha\left\langle x_{1}, y\right\rangle+\beta\left\langle x_{2}, y\right\rangle \quad \forall x_{1}, x_{2}, y \in V, \alpha, \beta \in \mathbb{R}</script>◾</p>
</li>
</ul>
<h1 id="Q3"><a href="#Q3" class="headerlink" title="Q3"></a>Q3</h1><p>$\mathbb{R}^{m \times n}$ is a vector space over $\mathbb{R}$. Show that $\langle\boldsymbol{A}, \boldsymbol{B}\rangle=\operatorname{trace}\left(\boldsymbol{A}^{T} \boldsymbol{B}\right) \text { for } \boldsymbol{A}, \boldsymbol{B} \in \mathbb{R}^{m \times n}$ is an inner product on $\mathbb{R}^{m \times n} .$ Here trace(.)  is the trace of a matrix, i.e., the sum of all diagonal entries.</p>
<p><strong>Proof</strong>:<br>For every $A=(A_{ij}) \in \mathbb{R}^{m\times n}$ we have <script type="math/tex">\langle A,A\rangle=\text{tr}(A^TA)=\sum_{i=1}^n(A^TA)_{ii}=\sum_{i=1}^n\sum_{j=1}^mA^T_{ij}A_{ji}=\sum_{i=1}^m\sum_{j=1}^nA_{ij}^2 \ge 0,</script> and <script type="math/tex">\langle A,A\rangle=\sum_{i=1}^m\sum_{j=1}^nA_{ij}^2 = 0\iff (A_{ij}=0 \quad \forall i,j) \iff A=0</script> Since <script type="math/tex">\text{tr}(X^T)=\text{tr}(X), \quad \text{tr}(X+Y)=\text{tr}(X)+\text{tr}(Y), \quad \text{tr}(\lambda X)=\lambda\text{tr}(X)</script> for every $X,Y \in \mathbb{R}^{n\times n}$, and $\lambda \in \mathbb{R}$, therefore, for every $A,B, C \in \mathbb{R}^{m\times n}$, and $\lambda \in \mathbb{R}$ we have</p>
<script type="math/tex; mode=display">\langle A,B\rangle=\text{tr}(B^TA)=\text{tr}((B^TA)^T)=\text{tr}(A^TB)=\langle B,A\rangle,\\
\langle \lambda A+B,C\rangle=\text{tr}(C^T(\lambda A+B))=\text{tr}(\lambda C^TA+C^TB)=\lambda\text{tr}(C^TA)+\text{tr}(C^TB)\\
=\lambda\langle A,C\rangle+\langle B,C\rangle</script><h1 id="Q4"><a href="#Q4" class="headerlink" title="Q4"></a>Q4</h1><p>Consider the polynomial kernel $K(\boldsymbol{x}, \boldsymbol{y})=\left(\boldsymbol{x}^{T} \boldsymbol{y}+1\right)^{2}$ for $\boldsymbol{x}, \boldsymbol{y} \in \mathbb{R}^{2} .$ Find an explicit feature map $\phi: \mathbb{R}^{2} \rightarrow \mathbb{R}^{6}$ satisfying $\langle\phi(\boldsymbol{x}), \phi(\boldsymbol{y})\rangle= K(\boldsymbol{x}, \boldsymbol{y}),$ where the inner product the standard inner product<br>in $\mathbb{R}^{6}$.<br><strong>Solution as follow:</strong></p>
<script type="math/tex; mode=display">
 \begin{array}{c}\phi\left(\left(\begin{array}{c}x_{1} \\ x_{2}\end{array}\right),\left(\begin{array}{c}y_{1} \\ y_2\end{array}\right)\right)=\left(1+x_{1} y_{1}+x_{2} y_2\right)^{2} \\ =1+\left(x_{1} y_{1}\right)^{2}+\left(x_{2} y_2\right)^{2}+2 x_{1} y_{1}+2 x_{2} y_2+2 x_{1} y_{1} x_{2} y_2\end{array}</script><script type="math/tex; mode=display">=\left(\begin{array}{llll}1 & \sqrt{2}x_{1} & \sqrt{2} x_{2} & x_{1}^{2}\sqrt{2} &x_{1} x_{2}  &x_{2}^{2}\end{array} \right)^{T} \left(\begin{array}{llll}1 & \sqrt{2}x_{1} & \sqrt{2} x_{2} & x_{1}^{2}\sqrt{2} &x_{1} x_{2}  &x_{2}^{2}\end{array} \right)</script><h1 id="Q5"><a href="#Q5" class="headerlink" title="Q5"></a>Q5</h1><p>(You don’t need to do anything for this question.) A good Matlab code and demonstration of kernel K-means can be found at <a href="http://www.dcs.gla.ac.uk/~srogers/firstcourseml/matlab/chapter6/kernelkmeans.html" target="_blank" rel="noopener">http://www.dcs.gla.ac.uk/~srogers/firstcourseml/matlab/chapter6/kernelkmeans.html</a> Read the code. Run the code in Matlab, if possible, to see how kernel K-means works for nonlinear data.</p>
]]></content>
      <categories>
        <category>5004</category>
      </categories>
      <tags>
        <tag>Homework</tag>
      </tags>
  </entry>
  <entry>
    <title>【分享整理】美图个性化push的探索之路</title>
    <url>/2020/%E7%BE%8E%E5%9B%BE%E4%B8%AA%E6%80%A7%E5%8C%96push/</url>
    <content><![CDATA[<blockquote>
<p>这篇文章是帮DataFunTalk社区整理的讲稿，也就是把展示的内容写成文字，挺费时间的，还好是比较感兴趣的话题。最后也学到了一些模型迭代的思路。<br>这个分享对我启发最大的是召回源完全可以当做特征加到排序里啊！！！我之前实习的时候，只想的是通过模型改变召回源的数量，从而控制下发的比例，真的太傻了5555</p>
</blockquote><a id="more"></a>
<hr>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200310141819.jpg?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<p><strong>导读：</strong> Push 作为一种有效的拉起 DAU 和召回用户的策略，近几年来被各类社交 App 广泛应用，随着深度神经网络在语音和图像识别上取得的巨大成功，AlphaGo 战胜人类围棋顶尖高手，以深度网络为基础的人工智能迎来第三次高潮。如何将深度模型应用于个性化 push 场景，从而减少无效 push 对用户的骚扰，是近年来一个关注的热点。本次分享讲从 Embedding，召回，排序，文案，内容池等多个方面介绍如何打造一个良好的 push 场景。</p>
<hr>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200310141817.jpg?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>本次分享主要介绍个性化push算法，包括业务背景，embedding召回和排序，不涉及系统架构。</p>
<h1 id="1-业务背景"><a href="#1-业务背景" class="headerlink" title="1. 业务背景"></a>1. 业务背景</h1><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200310144742.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>Push也就是推送通知，可以通过系统界面直接触达用户，当用户点击就会唤醒APP，是提高APP的日活，留存等指指标重要的环节之一。</p>
<h1 id="2-Embedding-演进"><a href="#2-Embedding-演进" class="headerlink" title="2.Embedding 演进"></a>2.Embedding 演进</h1><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200310141818.jpg?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<p>本次从三个算法层面介绍embedding：Word2Vec，Listing Embedding(参考Airbnb)在个性化push的应用，以及近两年流行的图相关的算法GCNs。</p>
<h2 id="2-1Word2Vec"><a href="#2-1Word2Vec" class="headerlink" title="2.1Word2Vec"></a>2.1Word2Vec</h2><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200310145635.jpg?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<ul>
<li>Feed也就是展示页的一个item，对于美图秀秀来说就是用户发的一张图，对于电商来说就是一个商品，本文统一称为feed。</li>
<li>Embedding就是把任何一个Feed转化为一个向量，服务于后面的召回和排序。Embedding是比较基础的过程，在最开始阶段，我们尝试了最基础的Work2Vec中的Skip-Gram的模型，通过对于用户的点击序列模仿Work2Vec中的一个句子。如图，我们有序列之后，定义窗口大小，通过中心词，就会得到Train Sample。如图：定义单侧窗口大小为2，就可以得到样本对，把样本对输入模型，就可以返回向量。在实验中，我们采用了60天的点击序列，输出向量设置为100维。</li>
</ul>
<h2 id="2-2Airbnb-Listing-Embedding"><a href="#2-2Airbnb-Listing-Embedding" class="headerlink" title="2.2Airbnb Listing Embedding"></a>2.2Airbnb Listing Embedding</h2><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200310151758.jpg?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>Airbnb listing Embedding 是2018年KDD的最佳论文，这里和Word2Vec主要的区别在于损失函数，模型本身和Word2Vec是保持一致的，所以我们先看Word2Vec的损失函数。</p>
<script type="math/tex; mode=display">
 \text { objective }=\operatorname{argmax}\left\{\sum_{(l, c t x) \in D_{p}} \log \frac{1}{1+e^{-\hat{v}_{c x x} v_{i}}}+\sum_{(l, c t x) \in D_{m}} \log \frac{1}{1+e^{\tilde{v}_{c x} v_{i}}}\right\}</script><p>损失函数由正负样本两部分组成，正样本对$D_p$来源于用户点击流生成的item pair，负样本对$D_m$通过当前的item+随机采样空间的其他item(这里假设随机采样的样本不是当前item的邻居)，Ctx表示上下文。这里需要注意的是在log里，正样本前面有负号，负样本没有负号。</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200310151909.jpg?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>但是，之前的构造只用了用户的点击数据，实际上用户还有点赞、分享等行为数据可以利用。所以，在Airbnb listing Embedding中，加入了Global Context这样一个概念：通过用户历史的点赞、分享对应的feed，与当前的feed构造出全局正样本对，加入到损失函数中。(如公式中的紫色部分)</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200310151921.jpg?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>同理，我们可以通过用户的点击“不喜欢”的行为来构造负样本(如公式中的红色部分)。除此之外，用户的浏览过但是没有点击的feed也可以随机采样之后当做负样本，加入到损失函数中(如公式中的蓝色部分)。</p>
<p>这样，就把Airbnb listing Embedding的策略引入到了美图秀秀的场景里。</p>
<h2 id="2-3Graph-Embedding"><a href="#2-3Graph-Embedding" class="headerlink" title="2.3Graph Embedding"></a>2.3Graph Embedding</h2><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200310151945.jpg?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>Graph Embedding是近几年比较流行的Embedding方法，主要策略可以分为三类：Shallow Embedding, Neighborhood autoencoder methods和GCN的方法。但是前两种方法涉及到不可拓展和直推式的缺陷，GCN可以避免以上的缺陷。</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200310151952.jpg?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>前面两种Embedding只用了用户的行为特征，但是没有考虑item的本身特征；另外，在之后的排序模型中，排序模型使用了item的自身属性进行排序。GCN就是把用户行为和item本身的特征联合起来，既能用上图的拓扑结构，又可以把握属性特征，把信息融合起来做Embedding。<br>在上图中，假设我们要计算A的Embedding，可以通过计算A的一阶近邻BC的信息聚合得到（Aggregate)，而BC的信息可以由二阶近邻DEC，EBFG的信息计算卷积（Convolution）计算得到。</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200310152001.jpg?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>具体来说，延展的过程中，主要包括对于高阶信息的汇总Aggregate，以及当前阶和邻阶节点上一阶的卷积之间信息的结合Combine。其中，Combine可以由很多操作，比如拼接，求和等。Aggregate的过程中，需要注意的一点是采用了Importance pooling，这里并不会对每个邻居节点都汇总，而是先计算一个Importance Factor(影响力因子)，影响力因子小于阈值的不参与加权，最后根据权重去加权求和。</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200310200130.jpg?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>构件图的不同形态：</p>
<ul>
<li>二分图形态：两种类型(Feeds,User)内部之间没有边，不同类型之间才有边；</li>
<li>单体图形态：根据用户同一时间段的行为，将Feeds之间关联起来。</li>
</ul>
<p>到此为止，我们介绍了Embedding所尝试的方法。</p>
<h1 id="3召回模型"><a href="#3召回模型" class="headerlink" title="3召回模型"></a>3召回模型</h1><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200310200618.jpg?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>召回主要采用了四个方面，全局召回(热榜，热搜，热词)，个性化召回(根据用户的行为，兴趣进行召回)，属性召回(也就是画像召回，通过机型，性别，年龄等)，最后是相关召回(包括相似，关键词召回等)。</p>
<h2 id="3-1个性化召回之YoutubeNet"><a href="#3-1个性化召回之YoutubeNet" class="headerlink" title="3.1个性化召回之YoutubeNet"></a>3.1个性化召回之YoutubeNet</h2><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200310200857.jpg?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>YoutubeNet是近两年比较流行的算法，他既可以做召回，也可以做排序。通过输入用户的行为序列得到用户和item的向量，然后就可以通过向量相似程度，对每个user相似的topN个item进行个性化召回，实验中相似率提升达到了1.661%。</p>
<h2 id="3-2个性化召回之聚类召回"><a href="#3-2个性化召回之聚类召回" class="headerlink" title="3.2个性化召回之聚类召回"></a>3.2个性化召回之聚类召回</h2><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200310203828.jpg?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>业务上，push也包含一个任务是实现将“工具类用户”转化成“社交类用户”，从而提高长期的DAU。在聚类召回阶段，可以通过对于用户的工具偏好特征去构建multi-hot的向量，然后进行用户群聚类，对于每个特定的用户群召回对应的榜单。</p>
<h2 id="3-3相关召回之相似召回-主要"><a href="#3-3相关召回之相似召回-主要" class="headerlink" title="3.3相关召回之相似召回(主要)"></a>3.3相关召回之相似召回(主要)</h2><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200310204300.jpg?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>相关召回在美图秀秀中是输出用户近期的item点击流，获取了对应的Embedding之后，可以通过计算Embedding的均值然后找余弦距离最小的候选项；或者直接将每个候选项去找余弦距离最小的候选项，最后进行汇总。<br>这里值得思考的一个问题是，何时利用好工具行为的特征，是在排序阶段，召回阶段，还是生成Embedding的阶段？经过实验，得到在Embedding阶段使用工具行为特征效果最好。</p>
<h2 id="3-4相关召回之聚类召回"><a href="#3-4相关召回之聚类召回" class="headerlink" title="3.4相关召回之聚类召回"></a>3.4相关召回之聚类召回</h2><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200310204939.jpg?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>聚类召回主要是为了实现多样性，避免同质化的内容。<br>通过对item的Embedding进行聚类，相当于每个item多了一个分类标签。通过统计用户对于每个类别的行为记录次数，按照倒叙进行排列。在召回阶段，按照排列好的顺序依次从每一个类别中抽取一个item，如果所有类别都抽了一遍，召回的数量仍然不够多，可以继续再抽一轮，直到候选数目足够。这样就实现了召回源的多样性。</p>
<h2 id="3-5相关召回之文案相关召回"><a href="#3-5相关召回之文案相关召回" class="headerlink" title="3.5相关召回之文案相关召回"></a>3.5相关召回之文案相关召回</h2><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200310205716.jpg?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>当选取了候选个item之后，发送push仍需要一条文字信息触达用户，这里简称文案。文案一般由编辑生成，会有很多候选项，所以也需要对于文案进行建模召回。主要有一下三个方案：</p>
<ul>
<li>关键词召回：通过对于历史的文案进行分词，得到每条文案的关键词，然后把用户对于文案的点击映射到对于关键词的点击，这样就能得到用户对于不同关键词的偏好。当我们新需要发送一条文案的时候，可以得到用户对于每条候选文案偏好度，召回偏好大的文案。</li>
<li>热词召回：通过计算全局哪些关键词最受欢迎，召回的过程中直接召回带有热门关键词的文案。</li>
<li>文案相似度召回：通过NLP的模型，比如BERT，生成每一条对应的Embedding，然后召回与用户点击过的文案余弦距离最小的文案。</li>
</ul>
<p>以上，就是所有的召回部分。</p>
<h1 id="4排序模型"><a href="#4排序模型" class="headerlink" title="4排序模型"></a>4排序模型</h1><h2 id="4-1LR-逻辑回归模型"><a href="#4-1LR-逻辑回归模型" class="headerlink" title="4.1LR 逻辑回归模型"></a>4.1LR 逻辑回归模型</h2><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200310210724.jpg?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>在排序模型的初始迭代阶段，使用了最简单的LR模型，LR的模型优点是模型浅，计算简单，解释性强，易于使用。但是缺点也显而易见，LR对于非线性特征拟合程度差；除此之外，交叉特征的生成依赖于大量尝试以及人工经验，所以尝试成本很高。</p>
<h2 id="4-2-xNFM模型"><a href="#4-2-xNFM模型" class="headerlink" title="4.2 xNFM模型"></a>4.2 xNFM模型</h2><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200310211221.jpg?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>通过对于LR，Wide&amp;Deep，deepFM，NFM，DCN，xNFM，xDeepFM模型的尝试与对比，最后选择的xNFM的模型。xNFM优点是组合了一阶和二阶的特征的优点，性能上也可以达到工业落地的需求。</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200310211553.jpg?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>xNFM不是业界主流的模型，而是在落地中对于NFM的变种。主要区别在于：</p>
<ul>
<li>模型的输入端为了降低模型参数规模，把id类特征和非id类特征分别进行Embedding，可以大大减少参数规模。</li>
<li>在上层网络，主要区别在于右侧。传统的NFM的弊端是只考虑了一个显性的二阶信息，而忽略了一阶信息(单特征)，所有增加了右边的网络用来捕捉单特征的信息。相比于LR，提升效果明显，点击流增加13.89%。</li>
</ul>
<h2 id="4-3-双塔模型"><a href="#4-3-双塔模型" class="headerlink" title="4.3 双塔模型"></a>4.3 双塔模型</h2><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200310213320.jpg?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>随着用户量的增加，计算量飙升，笛卡尔积之后会有千亿级别的计算量，使得模型更新周期变长，时效性降低。为了解决这个问题，我们提出了双塔的结构。<br>双塔的结构特别在，当user和item分别构建一个DNN的全连接的网络。这样设计优化主要体现在工程性能方面，存储量大大降低，预测阶段耗时也降低，从而实现了支持亿级别的用户高效计算。<br>从最初的双塔之后接入到内积，再到上图的双塔接入NFM，到最后再加入点击序列的信息，三个版本的迭代最终点击率累计提升23.9%。</p>
<h2 id="4-4-三塔模型"><a href="#4-4-三塔模型" class="headerlink" title="4.4 三塔模型"></a>4.4 三塔模型</h2><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200310213331.jpg?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>在之前也提到，我们有很多召回策略，但是召回源质量参差不齐，所以就需要解决对于召回源的选取。</p>
<ul>
<li>最初的想法是根据每个召回源的转化对排序结果进行socre reweight，但是弊端也很明显，因为召回源直接并不互斥，同个item会被多个召回源命中，所以reweight的规则也难以定义。</li>
<li>之后，为了个性化，直接把召回源信息加入到模型中。这里为什么不把召回源直接加入到item的特征中，而是单独的构造了一个塔呢？主要工程上的考虑，如果把召回源的信息加到item塔中，必须等item塔计算完成之后才能进行生产预测，会造成串行化，增加了延时。</li>
</ul>
<p>增加了召回源信息之后，点击率提高了3.06%。</p>
<h2 id="4-5-Field-wise-三塔模型"><a href="#4-5-Field-wise-三塔模型" class="headerlink" title="4.5 Field_wise 三塔模型"></a>4.5 Field_wise 三塔模型</h2><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200310213356.jpg?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<p>最后一版就是对于NFM模型的改进，在NFM左边的Bi-Interaction Layer中，Bi是Bi-linear的缩写，这一层其实是一个pooling层操作，它把很多个向量转换成一个向量，形式化如下：</p>
<script type="math/tex; mode=display">
 \begin{aligned} \boldsymbol{f}_{B I} &=\sum_{i=1}^{n} \sum_{j=i+1}^{n} x_{i} v_{i} \odot x_{j} v_{u} \\ &=\frac{1}{2}\left[\left(\sum_{i=1}^{n} x_{i} v_{i}\right)^{2}-\sum_{i=1}^{n}\left(x_{i} v_{i}\right)^{2}\right] \end{aligned}</script><p>$f_{bi}$的输入是整个的嵌入向量，xi ，xj是特征取值，vi， vj是特征对应的嵌入向量。中间的操作表示对应位置相乘。所以原始的嵌入向量任意两个都进行组合，对应位置相乘结果得到一个新向量；然后把这些新向量相加，就得到了Bi-Interaction的输出。这个输出只有一个向量。</p>
<p>这里参考FM到FFM的改进过程，引入Field的概念。由于BI层不同的类别特征所表达是权重不相同，而BI层捕捉不到这个信息，所以可以对于每个向量相乘前可以加上权重。但是，这样会导致参数过多，而同属于一个field的变量权重应该相近，所以对于BI层进行同类别的权重$w_{i,j}$共享而会使用相同参数的点积来计算:</p>
<script type="math/tex; mode=display">
 f_{F w B I}=\sum_{i=1}^{m} \sum_{j=i+1}^{m} w_{i j}\left(\sum_{k i n F_{i}} x_{i k} v_{i k}\right) \odot\left(\sum_{k \text { in } F_{j}} x_{j k} v_{j k}\right)</script><p>从而得到了Field_wise 三塔模型。模型上线后最终得到了点击率5.68%的提升。</p>
<p>到此为止，我们分别介绍了Embedding，召回，排序三部分。Embedding作为底层的服务辅助召回和排序；在召回部分，主要介绍召回的各个策略；排序部分主要是模型由LR到Field_wise 三塔模型的迭代过程。<br>美图个性化 push AI 探索之路的介绍到此结束。</p>
<blockquote>
<p>这个分享对我启发最大的是召回源完全可以当做特征加到排序里啊！！！我之前实习的时候，只想的是通过模型改变召回源的数量，从而控制下发的比例，真的太傻了5555</p>
</blockquote>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>推荐系统</tag>
        <tag>分享记录</tag>
      </tags>
  </entry>
  <entry>
    <title>CSIT5500-2 分治</title>
    <url>/2020/CSIT5500-2-%E5%88%86%E6%B2%BB/</url>
    <content><![CDATA[<blockquote>
<p>算法理解了就很简单，写代码也容易，但是表达清楚原理就很麻烦。如果没看懂就去看大神的博客吧。</p>
</blockquote><h1 id="分治法"><a href="#分治法" class="headerlink" title="分治法"></a>分治法</h1><p>分治法其实很常见，在并归排序的过程也用上了。<br>接下来举一个例子：</p><h2 id="寻找平面内最近的一对点"><a href="#寻找平面内最近的一对点" class="headerlink" title="寻找平面内最近的一对点"></a>寻找平面内最近的一对点</h2><p><a href="https://blog.csdn.net/weixin_37540865/article/details/78201399" target="_blank" rel="noopener">https://blog.csdn.net/weixin_37540865/article/details/78201399</a>。</p><a id="more"></a>


<ul>
<li>暴力：计算n个点两两距离，O(N^2)</li>
<li>分治：<ul>
<li>对于所有有点，按照一个轴排序O(nlog(n))，一分为二</li>
<li>找到左右各自最短距离dl, dr</li>
<li>合并起来<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200303222758.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></li>
</ul>
</li>
</ul>
<p>这里复杂就复杂在合并的时候考虑的情况太多。如果这个点的x坐标和中间数的差值大于d，那么就不用考虑这个点了。也就是说我们仅仅需要考虑如下中间的带状区域里的点：<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200303222858.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>d=min(dl,dr)<br>然后需要对灰色带里的两边分别排序，从上到下各自遍历一遍：</p>
<ul>
<li>遍历的时候，只需要看对面的上下d距离的正方形里有没有点，然后计算距离就好了，这一步的复杂度是O(1)</li>
<li>左遍历一遍，高2d，长度为d的矩形内最多最多边角6个点，因为如果超过6个点就不满足最小距离是d</li>
</ul>
<blockquote>
<p>我虽然理解了，表达实在是费劲，没理解的还是去看上面那篇博客吧</p>
</blockquote>
<h2 id="第k大数"><a href="#第k大数" class="headerlink" title="第k大数"></a>第k大数</h2><p>仿照快速排序，随机选一个值当做阈值，然后一分为二，如果左边只有k-1个数，那么就选对了；如果一边多一边少，就继续在多的那边选</p>
]]></content>
  </entry>
  <entry>
    <title>CS224n-8 机器翻译,seq2seq,Attention</title>
    <url>/2020/CS224n-8/</url>
    <content><![CDATA[<p>这一节：机器翻译，seq2seq(翻译的本质)，attention(提升seq2seq)</p><hr><h1 id="统计机器翻译"><a href="#统计机器翻译" class="headerlink" title="统计机器翻译"></a>统计机器翻译</h1><p>1990s-2010s: Statistical Machine Translation<br>统计翻译是传统方法，可以大概了解一下背景。<br>task：输入语言x的语句，输出语言y的语句。<br>需要得到一个y，让概率最大化：</p><a id="more"></a>


<script type="math/tex; mode=display">
 \operatorname{argmax}_{y} P(y | x) =  \operatorname{argmax}_{y} P(x|y)P(y)</script><p>$P(x|y)$是翻译模型，评价x和y的匹配程度；P(y) 是语言模型第6讲的时候已经讲过，就是评价语句是否通顺。</p>
<p>除了满足<strong>匹配程度</strong>和<strong>语句通顺</strong>两个条件，alignment(一一对应)程度也可以考虑，模型就变成了</p>
<script type="math/tex; mode=display">
 \operatorname{argmax}_{y} P(y | x) =  \operatorname{argmax}_{y} P(x,a |y)P(y)</script><p>对应度是很复杂的一个东西，举例说明：<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200304123056.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200304123125.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200304123213.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>所以，统计模型的翻译缺点显而易见：</p>
<ul>
<li>太多的人工规则</li>
<li>数据稀疏没解决</li>
<li>需要大量的语料对应</li>
<li>特征工程较为复杂</li>
</ul>
<h1 id="神经网络翻译模型"><a href="#神经网络翻译模型" class="headerlink" title="神经网络翻译模型"></a>神经网络翻译模型</h1><p>2014年google通过Neural Machine Translation (NMT) 也就是seq2seq实现了机器翻译，效果显著。</p>
<h2 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h2><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200304123616.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>左边通过RNN Encoding了输入语句(也就是转成了向量), 右边通过另一个RNN decoding了语句(通过向量转成了另一种语言)。 语言和语言直接，通过隐藏层的向量传递意思。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200304130801.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<h2 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h2><p>训练与RNN的训练类似，区别在于decoder 传递梯度到encoder的过程。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200304131042.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>这里注意，我们只需要考虑输入x和预测y与真实y的差距，所以是end2end。</p>
<h2 id="decoding贪婪算法的缺点"><a href="#decoding贪婪算法的缺点" class="headerlink" title="decoding贪婪算法的缺点"></a>decoding贪婪算法的缺点</h2><p>假如我们decode的过程中，只一个词一个词往后生成，选择当前最优解，如果前面出错，会导致整体输出的语句概率变小，不是全局最优解。</p>
<p>对于任何一个可能的输出y，需要最大化概率：</p>
<script type="math/tex; mode=display">
 \begin{aligned} P(y | x) &=P\left(y_{1} | x\right) P\left(y_{2} | y_{1}, x\right) P\left(y_{3} | y_{1}, y_{2}, x\right) \ldots, P\left(y_{T} | y_{1}, \ldots, y_{T-1}, x\right) \\ &=\prod_{t=1}^{T} P\left(y_{t} | y_{1}, \ldots, y_{t-1}, x\right) \end{aligned}</script><p>所以简单方法是暴力枚举出所有可能出现的情况y，然后选出概率最大的那个；当然暴力方法太昂贵，所以可以使用Beam Search。</p>
<blockquote>
<p>何时结束：把句子结尾当成一个符号，加入训练</p>
</blockquote>
<h2 id="Beam-search-decoding"><a href="#Beam-search-decoding" class="headerlink" title="Beam search decoding"></a>Beam search decoding</h2><p>核心思想：每一步寻找k个可能的候选项，然后再对着k个进行下一步探索，直到句子结束。（k一般是5-10）</p>
<blockquote>
<p>这里一般用score=log(P(y|x))，这样就分数越大越好</p>
<ul>
<li>Beam search 也不能100%保证全局最优，k越大，越能保证</li>
<li>但是Beam search的效率大大增加</li>
</ul>
</blockquote>
<ul>
<li>举一个例子，当K=2：<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200304143548.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></li>
<li>何时停止：</li>
</ul>
<p>设定阈值，步长阈值：比如超过30个单词就停止；候选项阈值：比如有5句候选就停止。</p>
<ul>
<li>长度不公平的问题：</li>
</ul>
<p>按照上面的计算，句子越短，分数越长，这个标准更倾向于选择短句子。<br>解决也很简单，对于分数socre 规范化(Normalize) 除以句子的长度，就得到了这个句子每个单词的得分。</p>
<script type="math/tex; mode=display">
 \frac{1}{t} \sum_{i=1}^{t} \log P_{\mathrm{LM}}\left(y_{i} | y_{1}, \ldots, y_{i-1}, x\right)</script><h2 id="神经网络翻译模型的优点"><a href="#神经网络翻译模型的优点" class="headerlink" title="神经网络翻译模型的优点"></a>神经网络翻译模型的优点</h2><ul>
<li>表现好：速度快，更流畅(语言模型更好)，对于短语翻译好</li>
<li>端对端：不需要考虑内部的问题</li>
<li>不需要人工干预：没有特征工程，模型可以应用到不同语言之间</li>
</ul>
<h2 id="神经网络翻译模型的缺点"><a href="#神经网络翻译模型的缺点" class="headerlink" title="神经网络翻译模型的缺点"></a>神经网络翻译模型的缺点</h2><ul>
<li>难解释：不好debug</li>
<li>难以控制：模型的输出不好控制，所以有时候需要模型之后加入规则干预</li>
</ul>
<h2 id="如何评价翻译模型"><a href="#如何评价翻译模型" class="headerlink" title="如何评价翻译模型"></a>如何评价翻译模型</h2><p>其实评价翻译好不好，最简单就是让人去读，但是总得有一个自动打分的小工具，于是有了BLEU。<br>BLEU (Bilingual Evaluation Understudy)</p>
<ul>
<li><p>Bleu通过对比机器翻译和真人翻译的数据集，通过计算n-Gram，以及句子长度(防止太啰嗦)来评价</p>
</li>
<li><p>BLEU也不太完美，因为翻译其实有很多种正确表达，这样对于预测集的依赖太大。</p>
<h2 id="机器翻译解决了吗"><a href="#机器翻译解决了吗" class="headerlink" title="机器翻译解决了吗?"></a>机器翻译解决了吗?</h2><p>机器翻译虽然取得了很大进展，但是仍然不完美。</p>
<ul>
<li>比如没办法读懂新词</li>
<li>依赖语料库的来源，不同语料库风格不一样，eg ： 聊天语料 vs 百科语料</li>
<li>没有读懂上下文。比如小说中，有时候需要理解剧情才能更好的翻译。</li>
<li>必须要有大量数据集训练。成本很高。</li>
</ul>
</li>
</ul>
<h2 id="Seq2Seq的其他用途"><a href="#Seq2Seq的其他用途" class="headerlink" title="Seq2Seq的其他用途"></a>Seq2Seq的其他用途</h2><p>其实有很多test都需要用到Seq2Seq：<br>  • Summarization (long text → short text)   总结<br>    • Dialogue (previous utterances → next utterance)  对话<br>    • Parsing (input text → output parse as sequence) 语法分析<br>    • Code generation (natural language → Python code) 写代码</p>
<h1 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h1><ul>
<li><p>Seq2Seq的问题在于，一个向量代表整句话就很容易损失太多信息；而且encoding是从结尾出去的，容易丢失开头的信息。</p>
</li>
<li><p>核心想法就是: decoder的每一步，通过和encoder 直接连接，只着重于当前的这个位置。</p>
</li>
</ul>
<h2 id="从图理解"><a href="#从图理解" class="headerlink" title="从图理解"></a>从图理解</h2><p>对于decoder的每一步，把RNN的输出和encoder的RNN输出进行点乘，通过softmax进行规范，得到一个概率值。这个概率值说明，现在在预测哪个位置。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200304154800.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200304155439.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>然后就这样做完了。</p>
<h2 id="公式解释"><a href="#公式解释" class="headerlink" title="公式解释"></a>公式解释</h2><p>这里，更朴素的思想是每次decoder的时候，把之前的encoder的对应向量拿过来，拼接；但是位置太难找了，所有就用了概率位置来寻找位置。</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200304160308.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<h2 id="Attention的优点"><a href="#Attention的优点" class="headerlink" title="Attention的优点"></a>Attention的优点</h2><ul>
<li>提升了表现</li>
<li>解决了seq2seq的瓶颈</li>
<li>解决了梯度消失问题(类似与上一讲的highway)</li>
<li>给了一点可解释性(有了概率的对应关系alignment)</li>
</ul>
<h2 id="Attention的其他用途"><a href="#Attention的其他用途" class="headerlink" title="Attention的其他用途"></a>Attention的其他用途</h2><p>Attention不仅仅可以用在翻译上，还可以用在任何seq2seq的任务。<br><strong>朴素定义attention</strong>:<br>• Given a set of vector values, and a vector query, attention is a technique to compute a weighted sum of the values, dependent on the query.<br>（给一组向量，和一个待查询的向量，Attention可以计算出那组向量的权重）</p>
<p>再理解Attention：</p>
<ul>
<li>求和权重的过程就是选择的过程，决定了那个输入值更重要</li>
<li>Attention是一种获取依赖于其他表示形式（查询）的任意组表示形式（值）的固定大小表示形式的方法。</li>
</ul>
<h2 id="Attention的变种"><a href="#Attention的变种" class="headerlink" title="Attention的变种"></a>Attention的变种</h2><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200304161747.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<blockquote>
<p>Attention 一定程度上和LSTM思想相似，就是通过额外的线路，去注意前面的信息。<br>妙啊！！！</p>
</blockquote>
]]></content>
      <categories>
        <category>CS224n</category>
      </categories>
      <tags>
        <tag>Attention</tag>
        <tag>机器翻译</tag>
      </tags>
  </entry>
  <entry>
    <title>CS224n-7 梯度消失,LSTM,GRU,BLSTM</title>
    <url>/2020/CS224n-7/</url>
    <content><![CDATA[<blockquote>
<p>这一节因为RNN梯度消失引入了LSTM，GRU。LSTM和GRU的构造思想都是在RNN的主线内，并行一条线，传递其他信息。解决梯度问题，也可以在cell外加一条线，比如双向RNN，多层RNN。</p>
</blockquote><hr><p>RNN的梯度消失与爆炸：<br>原因：由于Wh的权值共享，当Wh的最大特征值大于大于小于1 就会造成$W_h^n$的指数，所以造成梯度消失或者爆炸<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200302125410.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200204175150.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p><a id="more"></a>


<ul>
<li><p>梯度消失的问题：<br>远处的信息(梯度)会消失，会对之后的输入没有影响</p>
</li>
<li><p>梯度爆炸的问题：<br>每次迈出的步太大，导致无法收敛<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200204174949.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
</li>
<li><p>Gradient clipping：解决梯度爆炸，idea: 如果梯度大于v，那就除以v<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200204181404.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
</li>
</ul>
<h1 id="lstm"><a href="#lstm" class="headerlink" title="lstm"></a>lstm</h1><p>斯坦福的课好就好在，他会告诉你每一个模型为什么诞生，解决了什么问题。<br>对于lstm来说，就是解决了rnn单线传输的问题，防止长期信息丢失。以及梯度消失和爆炸。<br>单线传输就只能杂糅之前的所有信息，而lstm就可以有两条线C和H。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200204222854.png"><br>这张图包含了所有信息。</p>
<ul>
<li>三个门：forget,input,output只是抽象出来的概念，通过各自共享的参数W，U，b来输入一个0-1的数值，辅助向下。</li>
<li>其中c是用来更新“记忆”</li>
<li>h用来作为隐藏层，和rnn的单线传播一样</li>
</ul>
<h2 id="为何门控要用sigmoid，传播要用tanh？"><a href="#为何门控要用sigmoid，传播要用tanh？" class="headerlink" title="为何门控要用sigmoid，传播要用tanh？"></a>为何门控要用sigmoid，传播要用tanh？</h2><p>Sigmoid的输出在0-1之同，符合门控的物理定义，且当输入较大或较小时，其输出会非常接近1或0，从而保证该门开或关，在生成候选记亿时，使用<strong>tanh函数，是因为其输出在-1-1之间，这与大多数场景下特征分布是0中心的吻合</strong>。此外，<strong>tanh函数在输入为0近相比 Sigmoid函数有更大的梯度，通常使模型收敛更快。</strong></p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200204222854.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<h1 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h1><p>GRU是lstm的简化，只有两个门，减少了参数。也没有了cell state。<br>rt用来控制上一轮的h在这轮的输入大小，ut控制新旧的比例。<br>这里巧妙的地方在于ut。新的和旧的权重和为1。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200204224730.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<h1 id="LSTM-vs-GRU"><a href="#LSTM-vs-GRU" class="headerlink" title="LSTM vs GRU"></a>LSTM vs GRU</h1><p>两个差不多，效果上没有明显差别。<br>一般先尝试LSTM。</p>
<h1 id="其他思路解决梯度消失-爆炸问题："><a href="#其他思路解决梯度消失-爆炸问题：" class="headerlink" title="其他思路解决梯度消失/爆炸问题："></a>其他思路解决梯度消失/爆炸问题：</h1><p>首先，要明确，梯度的消失爆炸不仅仅是rnn，任何deepmodel在深度方面都会面临，而简单rnn是长度上的梯度问题。</p>
<h2 id="解决思路1-Residual-connections"><a href="#解决思路1-Residual-connections" class="headerlink" title="解决思路1 Residual connections"></a>解决思路1 Residual connections</h2><p>skip connection 跨越隐藏层链接。</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200204225836.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<h2 id="思路2-Dence-Connect"><a href="#思路2-Dence-Connect" class="headerlink" title="思路2 Dence Connect"></a>思路2 Dence Connect</h2><p>也就是中间层相互链接一下。连得越多，梯度问题就越复杂，越稳定。</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200204230034.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<h1 id="其他两种网络"><a href="#其他两种网络" class="headerlink" title="其他两种网络"></a>其他两种网络</h1><h2 id="Bidirectional-RNNs-双向rnn"><a href="#Bidirectional-RNNs-双向rnn" class="headerlink" title="Bidirectional RNNs 双向rnn"></a>Bidirectional RNNs 双向rnn</h2><p>双向rnn可以解决语言中单向歧义的问题。比如下图的“terrible”<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200204230855.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<p>terrible 如果单向很容易理解为负向词，但是双向，就增加了exciting的作用，似的模型更稳定。</p>
<h2 id="多层rnn"><a href="#多层rnn" class="headerlink" title="多层rnn"></a>多层rnn</h2><p>rnn也可以在深度上做文章，不仅仅是长度上。但是一般来说“3-5”合适。训练一般来说是一层一层训练。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200204231035.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
]]></content>
      <categories>
        <category>CS224n</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>LSTM/GRU</tag>
      </tags>
  </entry>
  <entry>
    <title>CS224n-6 语言模型, n-Gram, RNN</title>
    <url>/2020/CS224n-6/</url>
    <content><![CDATA[<p>为什么先写P6呢，因为P4是反向传播，公式太多，P5是语法分析，枯燥乏味。为了防止没有更新下去的动力，先来写P6。接下来的三讲P6-P8都是由助教Abby讲的，逻辑超级清楚，一步一步循序渐进。爱了爱了。<a href="https://www.bilibili.com/video/av61620135?p=6" target="_blank" rel="noopener">B站链接</a><br>P6 语言模型-&gt;RNN模型的进化，P7 LSTM，P8 Attention<br><img alt="附图" data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200302021352.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>附上Abby靓照</p><a id="more"></a>
<hr>
<p><strong>Language Modeling</strong> is the task of predicting what word comes next.<br>根据前面前半句，预测后半句。就比如输入法的联想候选词，搜索栏弹出的候选搜索项目，都属于语言模型。<br>为什么要研究语言模型呢？因为很多任务里都会涉及到，比如：</p>
<ul>
<li>Predictive typing 预测之后的输入</li>
<li>Speech recognition 语音识别</li>
<li>Handwriting recognition 手写识别</li>
<li>Spelling/grammar correction 语法纠正</li>
<li>Authorship identification </li>
<li>Machine translation 机器翻译</li>
<li>Summarization 文章总结</li>
<li>Dialogue 对话系统</li>
<li>etc.<br>所以，这一节很重要。</li>
</ul>
<h1 id="n-Gram语言模型"><a href="#n-Gram语言模型" class="headerlink" title="n-Gram语言模型"></a>n-Gram语言模型</h1><p>传统方法训练语言模型，就用的<a href="https://leeee.top/2020/CS224n-2-word2vec-word-Senses/">CS224n-2-word2vec-word-Senses</a>之前提到过的<strong>n-Gram语言模型</strong>，原理也很简单，就是通过统计频率：前半句出现过，之后最有可能跟着的词是什么。</p>
<p><strong>n-Gram</strong>： 就是连续的n个词(一般不会大于5)当做一个最小单元，统计出现的频率。</p>
<p><strong>n-Gram语言模型的假设</strong>：第t+1个词的选择，只依赖于前n-1个词。</p>
<blockquote>
<p>这里有点马尔科夫链和时间序列ARIMA模型的内味了。 </p>
</blockquote>
<p>根据假设就能得到：<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200302025657.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<blockquote>
<p>举个栗子：天气很好，我想吃___<br>如果这里用4-Gram 模型，那填空的位置，只与前面三个字”我想吃”有关，假如，之前的数据集里出现了1000词“火锅”，500次“糖”，那么这里肯定填“火锅”</p>
</blockquote>
<ul>
<li>想法越简单，问题就必然存在：</li>
</ul>
<ol>
<li>分母为0怎么办？ “我想吃”这三个字数据集里没有<br>S: <strong>backoff</strong> 4-Gram退化成3-Gram，只看前两个词“想吃”，因为数据集里可能有“他想吃”</li>
<li>分子为0怎么办？假如这里的语境是“我脑子有问题，我想吃翔”，但是数据集里没出现过这个短语<br>S:  <strong>smoothing</strong> 对于没出现的词都加一个小数量。<blockquote>
<p>(我感觉没啥用啊，翔还是不会被选中)</p>
</blockquote>
</li>
<li>存储问题，n-Gram越小，情况越多，需要存储的空间太大<br>S: 增加n</li>
<li>稀疏性问题，没办法解决</li>
</ol>
<h1 id="窗口语言模型"><a href="#窗口语言模型" class="headerlink" title="窗口语言模型"></a>窗口语言模型</h1><p>任务：输入前几个单词，输出之后可能的单词概率</p>
<p>比如说：用第三讲的窗口模型，就可以转化为一个分类器，候选种类是所有可能出现的单词。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200302032724.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>解决了n-Gram的稀疏性问题，也不需要储存大量的频率(只需要储存词向量)</p>
<ul>
<li>想法越简单，问题就必然存在：</li>
</ul>
<ol>
<li>窗口的大小不好确定，太小了不准确，太大了权重W得变长，训练的也不好。W的长度=n*词向量长度。</li>
<li>窗口内的单词权重一样，没有利用上位置信息</li>
</ol>
<h1 id="BOOM-RNN"><a href="#BOOM-RNN" class="headerlink" title="BOOM! RNN"></a>BOOM! RNN</h1><p>这个时候，再来介绍RNN就顺理成章了。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200302034025.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<p>RNN优点：</p>
<ul>
<li>长度没有限制</li>
<li><strong>理论上</strong>可以用上之前的所有信息</li>
<li>输入的长度和模型大小无关</li>
<li>权值共享，对于每个输入处理都是一样的</li>
</ul>
<p>想法越简单，问题就必然存在：</p>
<ul>
<li>计算太慢</li>
<li>RNN对于之前的信息(无论重要与否)都会容易丢失（梯度消失）<blockquote>
<p>🐟的记忆只有3s.</p>
</blockquote>
</li>
</ul>
<h2 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h2><p>训练一个RNN的数据集就是一个corpus语料库，然后开始预测，每一步都计算loss（预测值和真实值的偏差），直到模型收敛。<br>这里用交叉熵作为损失：<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200302035733.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>当我们跑完一轮之后(一般跑一段话，或者一个句子就行)，就可以得到当前的参数对应的loss，对于每个位置的损失求平均就好，然后计算梯度，得到新的参数，然后用新的参数去训练后面的语料。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200302035921.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200302040022.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<h2 id="RNN反向传播"><a href="#RNN反向传播" class="headerlink" title="RNN反向传播"></a>RNN反向传播</h2><p>反向传播也就是当我们计算梯度的时候，发挥作用。<br>这里用了“backpropagation through time”。因为我们得到的loss J是加起来这一批的loss，所以我们求导的时候也是对于每次的预测都进行求导(实际上用了链式法则)<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200302040907.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<h2 id="RNN语言模型的评价指标"><a href="#RNN语言模型的评价指标" class="headerlink" title="RNN语言模型的评价指标"></a>RNN语言模型的评价指标</h2><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200302120224.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>困惑度的理解可以参考知乎<a href="https://www.zhihu.com/question/58482430" target="_blank" rel="noopener">这篇文章</a></p>
<blockquote>
<p><strong>困惑度Perplexity</strong>就是模型对于测试数据认知，如果说模型很容易生成测试数据集，那么困惑度就小。<br>换一种理解：<strong>给测试集的句子赋予较高概率值的语言模型较好,当语言模型训练完之后，测试集中的句子都是正常的句子，那么训练好的模型就是在测试集上的概率越高越好。</strong></p>
</blockquote>
<p>困惑度不需要应用什么任务，直接输入数据，就能比较模型好坏。</p>
<ul>
<li>模型困惑度比较<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200302120612.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>可以发现lstm&gt;RNN&gt;5-gram</li>
</ul>
<h1 id="RNN的其他任务-当然LSTM也可以"><a href="#RNN的其他任务-当然LSTM也可以" class="headerlink" title="RNN的其他任务(当然LSTM也可以)"></a>RNN的其他任务(当然LSTM也可以)</h1><ul>
<li>词性标注<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200302120841.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></li>
<li><p>句子分类（eg：情感分类）<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200302120926.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
</li>
<li><p>encoder 问答系统</p>
</li>
</ul>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200302121101.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<ul>
<li>语音识别等</li>
</ul>
<p>◾</p>
<blockquote>
<p>下节课讲LSTM，GRU，多层LSTM，想想还有点小激动呢</p>
</blockquote>
]]></content>
      <categories>
        <category>CS224n</category>
      </categories>
      <tags>
        <tag>NLP</tag>
        <tag>RNN</tag>
      </tags>
  </entry>
  <entry>
    <title>MSBD5004 Mathematical Methods for Data Analysis Homework 1</title>
    <url>/2020/MSBD5004-Mathematical-Methods-for-Data-Analysis-Homework-1/</url>
    <content><![CDATA[<p>MSBD5004 Mathematical Methods for Data Analysis Homework 1<br>20635526 LiYuan</p><h1 id="Q1"><a href="#Q1" class="headerlink" title="Q1"></a>Q1</h1><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200301103136.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p><h1 id="a"><a href="#a" class="headerlink" title="( a )"></a>( a )</h1><p>By norm definition, we can see:</p><a id="more"></a>


<ul>
<li>Zero vector:<br>$\forall x \in V, |\boldsymbol{x}|_{\infty}=\max _{1 \leq i \leq n}\left|x_{i}\right|\geq0$ .<br>And only when $X=0$ then $|x|_{\infty}=0$.</li>
<li>positive homogeneity:<br>$\forall x \in V$ and $\alpha \in \mathbb{R}$, $|\boldsymbol{\alpha x}|_{\infty}=\max _{1 \leq i \leq n}\left|\alpha x_{i}\right|=\left|\alpha \right||\boldsymbol{ x}|_{\infty}$.</li>
<li>triangle inequality:<br>$\forall x, y \in V$, $|\boldsymbol{x+y}|_{\infty}= \max _{1 \leq i \leq n}\left|x_{i}+y_i\right|<br>\leq \max _{1 \leq i \leq n}\left|x_{i}\right|+\max _{1 \leq j \leq n}\left|y_{j}\right| =|\boldsymbol{x}|_{\infty}+|\boldsymbol{y}|_{\infty}$ </li>
</ul>
<p>So, $|\boldsymbol{x}|_{\infty}=\max _{1 \leq i \leq n}\left|x_{i}\right|$ is indeed a norm on $\mathbb{R}^{n}$.◾</p>
<h2 id="b"><a href="#b" class="headerlink" title="( b )"></a>( b )</h2><ul>
<li><p>Proof. </p>
<p>Let $|x|_{p}=\left(\sum_{i}\left|x_{i}\right|^{p}\right)^{\frac{1}{p}} .$ Observe that for all $x$ we have that</p>
<script type="math/tex; mode=display">
\max _{i}\left|x_{i}\right| \leq\|x\|_{p}</script><p>and that</p>
<script type="math/tex; mode=display">
\|x\|_{p} \leq\left(\sum_{i} \max _{i}\left|x_{i}\right|^{p}\right)^{\frac{1}{p}}</script><p>Thus,</p>
<script type="math/tex; mode=display">
\max _{i}\left|x_{i}\right| \leq\|x\|_{p} \leq\left(\sum_{i} \max _{i}\left|x_{i}\right|^{p}\right)^{\frac{1}{p}}</script><p>but then,</p>
<script type="math/tex; mode=display">\left(\sum_{i} \max _{i}\left|x_{i}\right|^{p}\right)^{\frac{1}{p}}=\left(n \cdot \max _{i}\left|x_{i}\right|^{p}\right)^{\frac{1}{p}}=n^{\frac{1}{p}} \cdot \max _{i}\left|x_{i}\right|</script><p>Thus </p>
<script type="math/tex; mode=display">
\max _{i}\left|x_{i}\right| \leq\|x\|_{p} \leq n^{\frac{1}{p}} \cdot \max _{i}\left|x_{i}\right|</script><p>however, $\lim _{p \rightarrow \infty} n^{\frac{1}{p}}=1,$ so</p>
<script type="math/tex; mode=display">
\max _{i}\left|x_{i}\right| \leq \lim _{p \rightarrow \infty}\|x\|_{p} \leq \max _{i}\left|x_{i}\right|</script><p>or rather, that $|x|_{\infty}=\lim _{p \rightarrow \infty}|x|_{p}=\max _{i}\left|x_{i}\right|$.<a href="https://notgnoshi.github.io/l-infinity-norm/" target="_blank" rel="noopener">◾</a></p>
</li>
</ul>
<h1 id="c"><a href="#c" class="headerlink" title="( c )"></a>( c )</h1><ul>
<li>Proof.<br>$|\boldsymbol{x}|_{\infty}=\max _{1 \leq i \leq n}\left|x_{i}\right|\leq\sum_{i=1}^n\left|x_{i}\right|=|\boldsymbol{x}|_{1}$<br>$|\boldsymbol{x}|_{1}=\sum_{i=1}^n\left|x_{i}\right|\leq n*\max _{1 \leq i \leq n}\left|x_{i}\right|=n|\boldsymbol{x}|_{\infty}$</li>
</ul>
<p>So that $|\boldsymbol{x}|_{\infty} \leq|\boldsymbol{x}|_{1} \leq n|\boldsymbol{x}|_{\infty}, \quad \forall \boldsymbol{x} \in \mathbb{R}^{n}$.◾</p>
<h1 id="Q2"><a href="#Q2" class="headerlink" title="Q2"></a>Q2</h1><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200301104035.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<h2 id="a-1"><a href="#a-1" class="headerlink" title="( a )"></a>( a )</h2><ul>
<li>Proof:</li>
</ul>
<p>Running through all $x \neq 0$ is equivalent to running through all $y:=\frac{x}{|x|_2}$ with $|y|_2=1$</p>
<script type="math/tex; mode=display">
\|\boldsymbol{A}\|_{2}=\sup _{\boldsymbol{x} \in \mathbb{R}^{n}, \boldsymbol{x} \neq 0} \frac{\|\boldsymbol{A} \boldsymbol{x}\|_{2}}{\|\boldsymbol{x}\|_{2}}=\sup _{\boldsymbol{x} \in \mathbb{R}^{n}, \boldsymbol{x} \neq 0}\left\|A \frac{x}{\|x\|_2}\right\|_2=
\sup _{\boldsymbol{y} \in \mathbb{R}^{n}, \|y\|_2 =1}\left\|A y\right\|_2=\max_{\boldsymbol{y} \in \mathbb{R}^{n}, \|y\|_2 =1}\left\|A y\right\|_2</script><p>◾</p>
<h2 id="b-1"><a href="#b-1" class="headerlink" title="( b )"></a>( b )</h2><p>By norm definition, we can see:</p>
<ul>
<li>Zero vector:<br>$\forall A \in V^{m \times n}$,<script type="math/tex; mode=display">\|\boldsymbol{A}\|_{2}=\max _{\boldsymbol{x} \in \mathbb{R}^{n},\|\boldsymbol{x}\|_{2}=1}\|\boldsymbol{A} \boldsymbol{x}\|_{2}\geq\max_{0\leq i \leq m}(\sum_{j = 1}^{n} a_{i,j}x_j)</script>Because $|\boldsymbol{x}|_2=1$, so not all $x_j=0$, So $|\boldsymbol{x}|_2 \geq 0$.<br>And only when all $a_{i,j}=0$,then $|\boldsymbol{A}|_{2}=0$, So $|\boldsymbol{A}|_{2}=0\Leftrightarrow \mathbf{A}=0$</li>
<li>positive homogeneity:<br>$\forall A \in V$ and $\alpha \in R$, <script type="math/tex">\|\alpha\boldsymbol{A}\|_{2}=\sup _{\boldsymbol{x} \in \mathbb{R}^{n}, \boldsymbol{x} \neq \mathbf{0}} \frac{\|\alpha\boldsymbol{A} \boldsymbol{x}\|_{2}}{\|\boldsymbol{x}\|_{2}}=\alpha\sup _{\boldsymbol{x} \in \mathbb{R}^{n}, \boldsymbol{x} \neq \mathbf{0}} \frac{\|\boldsymbol{A} \boldsymbol{x}\|_{2}}{\|\boldsymbol{x}\|_{2}}=\alpha\|\boldsymbol{A}\|_{2}</script></li>
<li>triangle inequality:<br>$\forall A,B \in V$,<script type="math/tex; mode=display">
\|\boldsymbol{A+B}\|_{2}=\sup _{\boldsymbol{x} \in \mathbb{R}^{n}, \boldsymbol{x} \neq 0} \frac{\|\boldsymbol{A} \boldsymbol{x}+\boldsymbol{B} \boldsymbol{x}\|_{2}}{\|\boldsymbol{x}\|_{2}}
\leq\sup _{\boldsymbol{x} \in \mathbb{R}^{n}, \boldsymbol{x} \neq 0} \frac{\|\boldsymbol{A} \boldsymbol{x}\|_{2}}{\|\boldsymbol{x}\|_{2}}+\sup _{\boldsymbol{x} \in \mathbb{R}^{n}, \boldsymbol{x} \neq 0} \frac{\|\boldsymbol{B} \boldsymbol{x}\|_{2}}{\|\boldsymbol{x}\|_{2}}=\|\boldsymbol{A}\|_{2}+\|\boldsymbol{B}\|_{2}</script>So,  $|\cdot|_{2}$is indeed a norm on $\mathbb{R}^{m\times n}$.◾</li>
</ul>
<h2 id="c-1"><a href="#c-1" class="headerlink" title="( c )"></a>( c )</h2><p>From the definition we have $\forall \boldsymbol{A} \in \mathbb{R}^{m \times n},\forall\boldsymbol{|x|}\neq \mathbf{0}$,</p>
<script type="math/tex; mode=display">\|\boldsymbol{A} \boldsymbol{x}\|_{2}\leq \sup _{\boldsymbol{x} \in \mathbb{R}^{n}, \boldsymbol{x} \neq \mathbf{0}}\|\boldsymbol{A} \boldsymbol{x}\|_{2} =\|\boldsymbol{A}\|_{2}\|\boldsymbol{x}\|_{2}</script><p>◾</p>
<h2 id="d"><a href="#d" class="headerlink" title="( d )"></a>( d )</h2><p>$\forall \boldsymbol{A} \in \mathbb{R}^{m \times n},\forall\boldsymbol{B} \in \mathbb{R}^{m \times n}$,</p>
<script type="math/tex; mode=display">\|\boldsymbol{A}\boldsymbol{B}\|_{2}=\max _{\boldsymbol{x} \in \mathbb{R}^{n},\|\boldsymbol{x}\|_{2}=1}\|\boldsymbol{AB} \boldsymbol{x}\|_{2} = \max _{\boldsymbol{x} \in \mathbb{R}^{n},\|\boldsymbol{x}\|_{2}=1}\|\boldsymbol{A(Bx)}\|_{2} \leq  \|A\|\max _{\boldsymbol{x} \in \mathbb{R}^{n},\|\boldsymbol{x}\|_{2}=1}\|\boldsymbol{(Bx)}\|_{2}</script><p>by ( c ) above. Thus</p>
<script type="math/tex; mode=display">\|\boldsymbol{A}\boldsymbol{B}\|_{2}\leq  \|\boldsymbol{A}\|_2\max _{\boldsymbol{x} \in \mathbb{R}^{n},\|\boldsymbol{x}\|_{2}=1}\|\boldsymbol{(Bx)}\|_{2}= \|\boldsymbol{A}\|_2 \|\boldsymbol{B}\|_2</script><p><a href="https://www.sciencedirect.com/topics/mathematics/matrix-norm" target="_blank" rel="noopener">◾</a></p>
<h1 id="Q3"><a href="#Q3" class="headerlink" title="Q3"></a>Q3</h1><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200301223359.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<ul>
<li>Proof. </li>
</ul>
<p>We’re basically after:</p>
<script type="math/tex; mode=display">\arg \min_{b} \sum_{i = 1}^{m} \left| {a}_{i} - b \right|</script><p>One should notice that $\frac{\mathrm{d} \left | x \right | }{\mathrm{d} x} = \operatorname{sign} \left( x \right)$ (Being more rigorous would say it is a Sub Gradient of the non smooth $L_1$ Norm function).<br>Hence, deriving the sum above yields $\sum_{i = 1}^{m} \operatorname{sign} \left( {a}_{i} - b \right)$.<br>This equals to zero only when the number of positive items equals the number of negative which happens when $b = \operatorname{median} \left\{ {a}_{1}, {a}_{2}, \cdots, {a}_{m} \right\}$.<a href="https://math.stackexchange.com/questions/113270/the-median-minimizes-the-sum-of-absolute-deviations-the-l-1-norm" target="_blank" rel="noopener">◾</a></p>
<h1 id="Q4"><a href="#Q4" class="headerlink" title="Q4"></a>Q4</h1><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200301223421.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<h2 id="a-2"><a href="#a-2" class="headerlink" title="( a )"></a>( a )</h2><p>Because $z_j$ is average of some $x_i$, so $z_j$ located at center of these $x_i$ , so $z_j$ is in the entries. So $z_j$ also are nonnegative.◾</p>
<h2 id="b-2"><a href="#b-2" class="headerlink" title="( b )"></a>( b )</h2><p>If each vector sums to one, $\mathbf{1}^{T} x_{k}=1$ for all $k$ then the same is true for the average:</p>
<p><script type="math/tex">\mathbf{1}^{T} z_{j}=\frac{1}{\left|G_{j}\right|} \sum_{k \in G_{j}} \mathbf{1}^{T} x_{k}=\frac{\left|G_{j}\right|}{\left|G_{j}\right|}=1</script>◾</p>
<h2 id="c-2"><a href="#c-2" class="headerlink" title="( c )"></a>( c )</h2><p>The $i$th entry of group represenative $z_j$is the fraction of the vectors in group $j$that have $i$th entry one. If it is equal to one, all vectors in the group have $i$thentry one. If it is close to one, most vectors in the group haveith entry one. If it zero, no vectors in the group haveith entry one.<a href="https://www.coursehero.com/file/p67cqc5/a-Suppose-the-original-vectors-x-i-are-nonnegative-ie-their-entries-are/" target="_blank" rel="noopener">◾</a></p>
<h1 id="Q5"><a href="#Q5" class="headerlink" title="Q5"></a>Q5</h1><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200301234639.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
]]></content>
      <categories>
        <category>5004</category>
      </categories>
      <tags>
        <tag>范数</tag>
        <tag>Kmeans</tag>
        <tag>Homework</tag>
      </tags>
  </entry>
  <entry>
    <title>通过ssh免密部署github</title>
    <url>/2020/github-ssh/</url>
    <content><![CDATA[<p>之前在部署博客到github page的时候每当遇到hexo deploy，遇到了<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git@github.com: Permission denied (publickey).</span><br><span class="line">fatal: 无法读取远程仓库。</span><br><span class="line">请确认您有正确的访问权限并且仓库存在。</span><br></pre></td></tr></table></figure><br>搞的我百思不得其解，ssh和github的连接明明是搞好的。最后定位到问题是系统ssh-key代理被误删了。具体是什么操作误删我就没定位到，可能是因为用了zsh的shell之后，和之前bash的路径不对？算了，这篇就总结搭载ssh的过程。</p><a id="more"></a>
<p>具体怎么搞ssh参考这篇<a href="https://blog.csdn.net/u013778905/article/details/83501204" target="_blank" rel="noopener">GitHub如何配置SSH Key</a>。</p>
<h1 id="设置git的user-name和email"><a href="#设置git的user-name和email" class="headerlink" title="设置git的user name和email"></a>设置git的user name和email</h1><p>如果你是第一次使用，或者还没有配置过的话需要操作一下命令，自行替换相应字段。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git config --global user.name &quot;xxxxxx&quot;</span><br><span class="line">git config --global user.email  &quot;xxxxx@gmail.com&quot;</span><br></pre></td></tr></table></figure><br>说明：git config —list 查看当前Git环境所有配置，还可以配置一些命令别名之类的</p>
<h1 id="检查-生成ssh-key"><a href="#检查-生成ssh-key" class="headerlink" title="检查/生成ssh key"></a>检查/生成ssh key</h1><p>ssh key 由一个公钥(id_rsa.pub)和私钥(id_rsa)组成，构成ssh通道的安全。<br>可以通过cd ~/.ssh   然后ls  查看。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200226175214.png"><br>上图中，我有两组ssh key。<br>如果没有，就生成一下。</p>
<blockquote>
<p>ssh-keygen -t rsa -C “xxxxxxx@qq.com”</p>
</blockquote>
<h1 id="获取公钥添加到github里"><a href="#获取公钥添加到github里" class="headerlink" title="获取公钥添加到github里"></a>获取公钥添加到github里</h1><blockquote>
<p>cat id_rsa.pub<br>然后复制到github -&gt; settting -&gt; ssh and GPG keys -&gt; new SSHkey</p>
</blockquote>
<p>然后拷贝进去。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200226175610.png"></p>
<h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><div class="note primary">
            <blockquote><p>$ ssh -T git@github.com<br>Hi ! You’ve successfully authenticated, but GitHub does not provide shell access.</p></blockquote>
          </div>
<p>说明运行成功，恭喜你拜托了https步入SSH时代。</p>
<h1 id="解决多个秘钥ssh权限问题"><a href="#解决多个秘钥ssh权限问题" class="headerlink" title="解决多个秘钥ssh权限问题"></a>解决多个秘钥ssh权限问题</h1><p>通常一台电脑生成一个ssh不会有这个问题，当一台电脑生成多个ssh的时候，就可能遇到这个问题，解决步骤如下：</p>
<h2 id="Could-not-open-a-connection-to-your-authentication-agent，则先执行如下命令即可："><a href="#Could-not-open-a-connection-to-your-authentication-agent，则先执行如下命令即可：" class="headerlink" title="Could not open a connection to your authentication agent，则先执行如下命令即可："></a>Could not open a connection to your authentication agent，则先执行如下命令即可：</h2><p><code>ssh-agent bash</code></p>
<h2 id="查看系统ssh-key代理-执行如下命令"><a href="#查看系统ssh-key代理-执行如下命令" class="headerlink" title="查看系统ssh-key代理,执行如下命令"></a>查看系统ssh-key代理,执行如下命令</h2><p><code>$ ssh-add -l</code></p>
<p>　　以上命令如果输出 The agent has no identities. 则表示没有代理。如果系统有代理，可以执行下面的命令清除代理:<br><code>$ ssh-add -D</code></p>
<h2 id="然后依次将不同的ssh添加代理，执行命令如下："><a href="#然后依次将不同的ssh添加代理，执行命令如下：" class="headerlink" title="然后依次将不同的ssh添加代理，执行命令如下："></a>然后依次将不同的ssh添加代理，执行命令如下：</h2><p><code>$ ssh-add ~/.ssh/id_rsa</code><br><code>$ ssh-add ~/.ssh/aysee</code></p>
<p>　你会分别得到如下提示：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">2048 8e:71:ad:88:78:80:b2:d9:e1:2d:1d:e4:be:6b:db:8e /Users/aysee/.ssh/id_rsa (RSA)</span><br><span class="line">2048 8e:71:ad:88:78:80:b2:d9:e1:2d:1d:e4:be:6b:db:8e /Users/aysee/.ssh/id_rsa (RSA)</span><br></pre></td></tr></table></figure><br>　　如果使用 ssh-add ~/.ssh/id_rsa的时候报如下错误，则需要先运行一下 ssh-agent bash 命令后再执行 ssh-add …等命令<br><code>Could not open a connection to your authentication agent.</code></p>
<h2 id="配置-ssh-config-文件"><a href="#配置-ssh-config-文件" class="headerlink" title="配置 ~/.ssh/config 文件"></a>配置 ~/.ssh/config 文件</h2><p>　　如果没有就在~/.ssh目录创建config文件，该文件用于配置私钥对应的服务器<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Default github user(first@mail.com)</span><br><span class="line">Host github.com</span><br><span class="line">HostName github.com</span><br><span class="line">User git</span><br><span class="line">IdentityFile C:/Users/username/.ssh/id_rsa</span><br><span class="line"># aysee (company_email@mail.com)</span><br><span class="line">Host github-aysee</span><br><span class="line">`HostName github.com</span><br><span class="line">User git</span><br><span class="line">IdentityFile C:/Users/username/.ssh/aysee</span><br></pre></td></tr></table></figure><br>Host随意即可，方便自己记忆，后续在添加remote是还需要用到。 配置完成后，在连接非默认帐号的github仓库时，远程库的地址要对应地做一些修改，比如现在添加second帐号下的一个仓库test，则需要这样添加：</p>
<p><code>git remote add test git@github-aysee:ay-seeing/test.git</code><br><code>#并非原来的git@github.com:ay-seeing/test.git</code><br>ay-seeing 是github的用户名</p>
<h2 id="测试-ssh"><a href="#测试-ssh" class="headerlink" title="测试 ssh"></a>测试 ssh</h2><p><code>ssh -T git@github.com</code><br>你会得到如下提示，表示这个ssh公钥已经获得了权限<br><code>Hi USERNAME! You&#39;ve successfully authenticated, but github does not provide shell access.</code></p>
<p>参考：<a href="https://www.cnblogs.com/ayseeing/p/4445194.html" target="_blank" rel="noopener">https://www.cnblogs.com/ayseeing/p/4445194.html</a></p>
]]></content>
      <categories>
        <category>工程</category>
      </categories>
      <tags>
        <tag>ssh</tag>
        <tag>github</tag>
        <tag>hexo</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>MSBD5009 并行计算介绍</title>
    <url>/2020/MSBD5009-1-%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[<h1 id="并行计算parallel-programming"><a href="#并行计算parallel-programming" class="headerlink" title="并行计算parallel programming"></a>并行计算parallel programming</h1><blockquote>
<p>更新：这门课太硬核，换课了</p>
</blockquote><p>选这门课主要是想提高编程能力，顺便了解一下os相关知识，本科没学过操作系统和编译原理什么的，经常遇到了云里雾里的。<br>还有以前还去碰过CUDA，自己瞎研究深度学习的项目，最后连CUDA和TF的版本适配都没解决，害，一把辛酸泪。<br>第一节课遇到各种线程进程cache，中文都不知道是啥，听得云里雾里的。</p><a id="more"></a>

<hr>
<p>这门课的分数构成：<br>50分的三次编程作业，每次作业是对已经有的代码填空。<br>50分的考试，有编程填题，也有简答题。</p>
<hr>
<p>三本参考书：</p>
<ul>
<li>Introduction to Parallel Computing 2nd edition</li>
<li>An Introduction to Parallel Programming</li>
<li>Programming Massively Parallel Processors:<br>A Hands-on Approach 3rdd Edition</li>
</ul>
<blockquote>
<p>不出意外是不会看了🤣，以后需要再说吧。</p>
</blockquote>
<h1 id="并行计算的基本背景"><a href="#并行计算的基本背景" class="headerlink" title="并行计算的基本背景"></a>并行计算的基本背景</h1><h2 id="为什么我们需要一度的提高性能-表现？"><a href="#为什么我们需要一度的提高性能-表现？" class="headerlink" title="为什么我们需要一度的提高性能/表现？"></a>为什么我们需要一度的提高性能/表现？</h2><p>随着数据的增长和计算的需求(基因计算，深度学习，天文计算，天气模型，蛋白质计算等等)增加，cpu的性能越来越不够用，简单的办法就是增加核心数。<br>核心数增加了就需要让程序能充分利用起来各个核心，就像老板跟员工派任务一样，需要充分榨干劳动力。</p>
<h2 id="为什么需要构建并行系统"><a href="#为什么需要构建并行系统" class="headerlink" title="为什么需要构建并行系统"></a>为什么需要构建并行系统</h2><p>芯片的瓶颈难以突破，只有从系统上高效调用。<br>瓶颈：高密度的晶状体-&gt; 更快的芯片-&gt;增加耗能-&gt;增加发热-&gt;导致芯片不稳定<br>所以需要多核合作。</p>
<h2 id="为什么需要写并行的程序"><a href="#为什么需要写并行的程序" class="headerlink" title="为什么需要写并行的程序"></a>为什么需要写并行的程序</h2><p>直接改写串行的程序可能会遇到各种复杂的问题，数据结构，算法设计方面的。改写出来的可能依然不高效。</p>
<h2 id="怎么写并行程序"><a href="#怎么写并行程序" class="headerlink" title="怎么写并行程序"></a>怎么写并行程序</h2><ul>
<li>任务划分<br>例子：改卷每人改一道题</li>
<li>数据划分<br>例子：改卷每人改100张卷</li>
</ul>
<p>需要解决多核合作的问题：</p>
<ul>
<li><p>Communication – one or more cores send their current partial sums to another core. 相互沟通</p>
</li>
<li><p>Load balancing – share the work evenly among the cores so that one is not heavily loaded. 任务量均衡</p>
</li>
<li><p>Synchronization – because each core works at its own pace, make sure cores do not get too far ahead of the rest. 齐头并进</p>
</li>
</ul>
<h2 id="concurrent-parallel-distributed"><a href="#concurrent-parallel-distributed" class="headerlink" title="concurrent,parallel,distributed"></a>concurrent,parallel,distributed</h2><p>• Concurrent computing – In a program multiple tasks can be in progress at any instant. 程序同时处理多个任务    </p>
<p>• Parallel computing – In a program multiple tasks cooperate closely to solve a problem.<br>多个任务协作</p>
<p>• Distributed computing – A program may need to cooperate with other programs to solve a problem.<br>程序之间协作</p>
<blockquote>
<p>没搞懂这里的tasks和program之间的区别</p>
</blockquote>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li>并行系统是计算趋势</li>
<li>串行的程序不能用上多核</li>
<li>要学习如何要调用内核</li>
<li>也需要可靠的开发技术</li>
</ul>
<h1 id="硬件和操作系统"><a href="#硬件和操作系统" class="headerlink" title="硬件和操作系统"></a>硬件和操作系统</h1><h2 id="冯·诺伊曼模型"><a href="#冯·诺伊曼模型" class="headerlink" title="冯·诺伊曼模型"></a>冯·诺伊曼模型</h2><p>[百度百科]<br>冯·诺依曼型计算机一般具有以下五个功能：必须具有长期记忆程序、数据、中间结果及最终运算结果的能力；能够完成各种算术、逻辑运算和数据传送等数据加工处理的能力；能够根据需要控制程序走向，并能根据指令控制机器的各部件协调操作；能够按照要求将处理结果输出给用户。</p>
<p>冯·诺依曼型计算机从本质上讲是采取串行顺序处理的工作机制，即使有关数据巳经准备好，也必须逐条执行指令序列。而提高计算机性能的根本方向之一是并行处理。因此，近年来人们谋求突破传统冯·诺依曼体制的束缚，这种努力被称为非诺依曼化。对所谓非诺依曼化的探讨仍在争议中，一般认为它表现在以下三个方面的努力。<br>　　（1）在冯·诺依曼体制范畴内，对传统冯·诺依曼机进行改造，如采用多个处理部件形成流水处理，依靠时间上的重叠提高处理效率；又如组成阵列机结构，形成单指令流多数据流，提高处理速度。这些方向已比较成熟，成为标准结构；<br>　　（2）用多个冯·诺依曼机组成多机系统，支持并行算法结构。这方面的研究目前比较活跃；<br>　　（3）从根本上改变冯·诺依曼机的控制流驱动方式。例如，采用数据流驱动工作方式的数据流计算机，只要数据已经准备好，有关的指令就可并行地执行。这是真正非诺依曼化的计算机，它为并行处理开辟了新的前景，但由于控制的复杂性，仍处于实验探索之中。</p>
<h2 id="Central-processing-unit-CPU"><a href="#Central-processing-unit-CPU" class="headerlink" title="Central processing unit (CPU)"></a>Central processing unit (CPU)</h2><p>• Control unit - responsible for deciding which instruction in a program should be executed. (the boss) 控制单元</p>
<p>• Arithmetic and logic unit (ALU) - responsible for executing the actual instructions. (the worker) 计算单元</p>
<h2 id="关键terms"><a href="#关键terms" class="headerlink" title="关键terms"></a>关键terms</h2><p>• Register – very fast storage, part of the CPU.</p>
<p>• Program counter – stores address of the next instruction to be executed.</p>
<p>• Bus – wires that connect the CPU and memory.</p>
<p>冯·诺伊曼模型的瓶颈在于CPU和内存的分离，cpu的寄存器太小，必须和内存交换数据，但是互联的速率有限。</p>
<h2 id="Locality"><a href="#Locality" class="headerlink" title="Locality"></a>Locality</h2><p>• The same or nearby locations are accessed frequently.<br>• Spatial locality – accessing a nearby location.<br>• Temporal locality – accessing in the near future.</p>
<h2 id="从cpu到cache的问题"><a href="#从cpu到cache的问题" class="headerlink" title="从cpu到cache的问题"></a>从cpu到cache的问题</h2><p>由于cache分三级，很有可能写入不连续。<br>–直写式  通过在写入高速缓存时更新主内存中的数据来处理此问题。<br>–回写式 将缓存cache中的数据标记为脏数据。当高速缓存行由内存中的新高速缓存行替换时，脏行将写入内存。</p>
<h2 id="缓存映射Cache-Mapping"><a href="#缓存映射Cache-Mapping" class="headerlink" title="缓存映射Cache Mapping"></a>缓存映射Cache Mapping</h2><p>• 完全关联–可以在缓存中的任何位置放置新行。<br>• 直接映射–每条缓存行在缓存中都有一个唯一的位置，将为其分配该位置。<br>• n向集合关联–每个高速缓存行可以放置在高速缓存中n个不同位置之一中。</p>
<h2 id="缓存逐出Cache-Eviction"><a href="#缓存逐出Cache-Eviction" class="headerlink" title="缓存逐出Cache Eviction"></a>缓存逐出Cache Eviction</h2><p>•缓存比主内存小得多。<br>•当缓存已满时，需要在内存中添加新行以替换或逐出缓存中的行。<br>•常见的缓存逐出策略包括LRU / MRU（最近最少使用/最近使用）和LFU（最近最少使用）。</p>
<h2 id="虚拟内存"><a href="#虚拟内存" class="headerlink" title="虚拟内存"></a>虚拟内存</h2><p>•如果我们运行非常大的程序或访问<strong>非常大</strong>的数据集的程序，则所有指令和数据可能无法放入主存储器。<br>•虚拟内存用作<strong>辅助存储的缓存</strong>。<br>•它利用<strong>时空局部性</strong>原理。<br>•它仅将正在运行的程序的活动部分保留在主存储器中。<br>•<strong>交换空间Swap space</strong>–辅助存储区，用于保持非活动（部分）正在运行的程序。<br>•<strong>虚拟的页page</strong>–数据和指令块。大多数系统具有固定的页面大小，当前范围为4到16 KB。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200226170253.png"></p>
<h2 id="虚拟页码"><a href="#虚拟页码" class="headerlink" title="虚拟页码"></a>虚拟页码</h2><p>•编译程序时，其页面为分配的虚拟页码。<br>•运行程序时，将创建一个表，该表将虚拟页码映射到物理地址。<br>•页表用于将虚拟地址转换为物理地址。</p>
<h2 id="转换后备缓冲器（Translation-lookaside-buffer-TLB）"><a href="#转换后备缓冲器（Translation-lookaside-buffer-TLB）" class="headerlink" title="转换后备缓冲器（Translation-lookaside buffer TLB）"></a>转换后备缓冲器（Translation-lookaside buffer TLB）</h2><p>•使用页表有可能显着增加每个程序的整体运行时间。<br>•TLB是处理器中的特殊地址转换缓存。<br>•它在非常<strong>快的内存中从页表中缓存了少量条目</strong>（通常为16–512）。<br>•页面错误–尝试访问页面表中页面的有效物理地址，但该页面仅存储在磁盘上。</p>
<h2 id="指令级并行（Instruction-Level-Parallelism-ILP）"><a href="#指令级并行（Instruction-Level-Parallelism-ILP）" class="headerlink" title="指令级并行（Instruction Level Parallelism ILP）"></a>指令级并行（Instruction Level Parallelism ILP）</h2><p>•试图通过使多个处理器组件或功能单元同时执行指令来提高处理器性能。<br>•流水线Pipelining-功能单元是分阶段安排的。<br>•多个问题-可以同时启动多个指令。</p>
<h2 id="硬件多线程Hardware-multithreading"><a href="#硬件多线程Hardware-multithreading" class="headerlink" title="硬件多线程Hardware multithreading"></a>硬件多线程Hardware multithreading</h2><p>•并非总是有机会同时执行不同的线程。<br>•硬件多线程为系统提供了一种在当前正在执行的任务停滞后继续进行有用工作的方法。<br>– 例如，当前任务必须等待从内存加载数据。<br>•细粒度-处理器在每条指令后在线程之间切换，跳过停滞的线程。<br>–优点：可以避免因停转而浪费机器时间。<br>–缺点：准备好执行长指令序列的线程可能必须等待执行每条指令。<br>•粗粒度-仅切换等待耗时的操作完成而停止的线程。<br>–优点：切换线程几乎不需要即时。<br>–缺点：处理器可以在较短的停顿时间内空闲，并且线程切换也将导致延迟。<br>•同步多线程（SMT）-细粒度多线程的变体。<br>•允许多个线程使用多个功能单元。</p>
]]></content>
      <categories>
        <category>MSBD5009</category>
      </categories>
      <tags>
        <tag>并行计算</tag>
      </tags>
  </entry>
  <entry>
    <title>CSIT5500-1 算法基础</title>
    <url>/2020/CSIT5500-1-%E6%8E%92%E5%BA%8F/</url>
    <content><![CDATA[<p>这是学校csit5500的一门课，听着名字就知道很经典。第一节课主要是算法评估，排序，搜索树，红黑树</p><h1 id="算法评估"><a href="#算法评估" class="headerlink" title="算法评估"></a>算法评估</h1><p>这一节就解释，为什么用O(n)来表示算法的复杂度。</p><ul>
<li>不能简单用cpu的时间，因为不固定</li>
<li>不同级数之间差异大，同一个级数内差异不大</li>
</ul><a id="more"></a>


<p>其他的点：</p>
<ul>
<li>比复杂度的时候，只看最高阶；</li>
<li>对数的级数都是一样的；loga n = logb n/(logb a)</li>
</ul>
<p>算法需要最差评估复杂度，一般不用证明，举例就行。</p>
<p>eg：Worst-Case Analysis of Binary Search<br>二分搜索最差的情况就是一直排除到最后一半只有一个元素的时候。<br>复杂度如下：</p>
<script type="math/tex; mode=display">
\begin{aligned} T(n) & \leq T(n / 2)+O(1) \\ & \leq T(n / 4)+O(1)+O(1) \\ & \leq T\left(n / 2^{k}\right)+k \cdot O(1) \end{aligned}</script><p>k可以人为指定成log2(n)</p>
<script type="math/tex; mode=display">
\begin{aligned} T(n) & \leq T(1)+\log _{2} n \cdot O(1) \\ &=O(1)+O(\log n) \\ &=O(\log n) \end{aligned}</script><h1 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h1><p>又到了经典的排序环节，直接引用我觉得写得最完整的两个博文<a href="https://www.cnblogs.com/onepixel/articles/7674659.html" target="_blank" rel="noopener">十大排序动图演示</a><br><a href="https://leetcode.com/problems/sort-an-array/discuss/276916/Python-bubble-insertion-selection-quick-merge-heap-objects" target="_blank" rel="noopener">python十大排序</a> </p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200225022848.png"></p>
<p>课上跳过了最简单的主要讲了O(nlogn)的三个，并归，快速，堆。</p>
<h2 id="并归merge"><a href="#并归merge" class="headerlink" title="并归merge"></a>并归merge</h2><p>简单的dc思路，先对数组分成两半，左右各自排序，然后用两个指针同时扫一遍，合起来。<br>这个过程递归到，两半只有一个元素的时候，就可以了。</p>
<ul>
<li>最坏情况复杂度<br>并归有两个过程，第一，遍历数组，统计长度，复杂度O(N).<br>第二，merge.<br>最好情况是，左：12345 右：6789，这样复杂度是O(N/2)=O(N).<br>最差情况是，左：13579 右：2468，这样复杂度也是O(N).<br>所以，两个过程加起来也是O(N)。</li>
</ul>
<p>然后进入到递归的过程：与二分搜索相似</p>
<script type="math/tex; mode=display">
\begin{aligned} T(n) & \leq 2 T(n / 2)+O(n) \\ & \leq 2(2 T(n / 4)+O(n / 2))+O(n) \\ & \leq 4 T(n / 4)+O(n)+O(n) \\ & \leq 2^{k} T\left(n / 2^{k}\right)+k \cdot O(n) \end{aligned}</script><p>直接取k=log2n</p>
<script type="math/tex; mode=display">
\begin{aligned} T(n) & \leq 2^{\log _{2} n} T(1)+\log _{2} n \cdot O(n) \\ & \leq O(n)+O(n \log n) \\ & \leq O(n \log n) \end{aligned}</script><p>所以最坏情况也是这个，并归排序复杂度是稳定的。<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">MergeSort</span><span class="params">(lists)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(lists)&lt;<span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> lists</span><br><span class="line">    mid = int(len(lists)/<span class="number">2</span>)</span><br><span class="line">    print(mid)</span><br><span class="line">    left = MergeSort(lists[:mid])</span><br><span class="line">    print(left)</span><br><span class="line">    right = MergeSort(lists[mid:])</span><br><span class="line">    l = r =<span class="number">0</span></span><br><span class="line">    res = []</span><br><span class="line">    <span class="keyword">while</span> l &lt; len(left) <span class="keyword">and</span> r &lt; len(right):</span><br><span class="line">        <span class="keyword">if</span> left[l] &lt; right[r]:</span><br><span class="line">            res.append(left[l])</span><br><span class="line">            l+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            res.append(right[r])</span><br><span class="line">            r+=<span class="number">1</span></span><br><span class="line">    res +=left[l:]</span><br><span class="line">    res +=right[r:]</span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure></p>
<h2 id="快速"><a href="#快速" class="headerlink" title="快速"></a>快速</h2><p>快排的思路是任选一个元素，然后把数组分成两半，再分别对两半进行这个过程。也是dc的思路。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">	<span class="comment"># @quickSort</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quickSort</span><span class="params">(array)</span>:</span></span><br><span class="line">	<span class="keyword">if</span> len(array) &lt; <span class="number">2</span>:  <span class="comment"># 基线条件（停止递归的条件）</span></span><br><span class="line">		<span class="keyword">return</span> array</span><br><span class="line">	<span class="keyword">else</span>:  <span class="comment"># 递归条件</span></span><br><span class="line">		baseValue = array[<span class="number">0</span>]  <span class="comment"># 选择基准# 由所有小于基准值的元素组成的子数组</span></span><br><span class="line">		less = [m <span class="keyword">for</span> m <span class="keyword">in</span> array[<span class="number">1</span>:] <span class="keyword">if</span> m &lt; baseValue]<span class="comment"># 包括基准在内的同时和基准相等的元素，在上一个版本的百科当中，并没有考虑相等元素</span></span><br><span class="line">		equal = [w <span class="keyword">for</span> w <span class="keyword">in</span> array <span class="keyword">if</span> w ==baseValue]<span class="comment"># 由所有大于基准值的元素组成的子数组</span></span><br><span class="line">		greater = [n <span class="keyword">for</span> n <span class="keyword">in</span> array[<span class="number">1</span>:] <span class="keyword">if</span> n &gt; baseValue]</span><br><span class="line">	<span class="keyword">return</span> quickSort(less) + equal + quickSort(greater)</span><br></pre></td></tr></table></figure>
<h1 id="快速排序vs堆排序"><a href="#快速排序vs堆排序" class="headerlink" title="快速排序vs堆排序"></a>快速排序vs堆排序</h1><p>我们讨论的排序都是基于比较的，不基于比较的排序：计数排序(O(n)，内存够用的情况下)，基数排序（O(m*n)），桶排序(O(n)，输入数据分布均匀的情况下)</p>
<p>大数排序中，快排比堆排序好。</p>
<ol>
<li>堆排序需要用数组下标来回访问元素，对缓存不友好，但是快速排序是顺序访问，就可以顺着cpu的缓存进行遍历(内存访问（跳跃式还是连续方式）)</li>
<li>堆排序做数据的交换要比快速排序交换的次数多，因为在建堆的过程，数据被打乱. 所以，虽然都是o(nlogn)但是堆排序前面的常数项是一般大于快速排序的</li>
</ol>
<p>排序的上限为什么是o(nlogn)？<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200311232711.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<h1 id="堆"><a href="#堆" class="headerlink" title="堆"></a>堆</h1><p>堆排序就高端一点，用了根堆(heap)的结构。<br>巧妙的是，通过利用完全二叉树的结构，通过数组的位置，就实现了这个根堆的过程。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def heapSort(nums):</span><br><span class="line">    def heapify(nums,n,i):</span><br><span class="line">        large = i</span><br><span class="line">        left = 2*i+1</span><br><span class="line">        right = 2*i+2</span><br><span class="line">        if left&lt;n and nums[left]&gt;nums[large]: large = left</span><br><span class="line">        if right&lt;n and nums[right]&gt;nums[large]: large = right</span><br><span class="line">        if large!=i:</span><br><span class="line">            nums[i],nums[large]=nums[large],nums[i]</span><br><span class="line">            heapify(nums,n,large)</span><br><span class="line">            </span><br><span class="line">    n = len(nums)</span><br><span class="line">    for i in range(n/2,-1,-1):</span><br><span class="line">        print(i)</span><br><span class="line">        heapify(nums,n,i)</span><br><span class="line">    for i in range(n-1,-1,-1):</span><br><span class="line">        print(i)</span><br><span class="line">        nums[i], nums[0] = nums[0], nums[i]</span><br><span class="line">        heapify(nums, i, 0)</span><br><span class="line">    return nums</span><br></pre></td></tr></table></figure>
<h2 id="复习树🌲的知识："><a href="#复习树🌲的知识：" class="headerlink" title="复习树🌲的知识："></a>复习树🌲的知识：</h2><ul>
<li>二叉树：每一个节点最多两个孩子</li>
<li>满二叉树Full binary tree：每个子节点都有两个元素</li>
<li>完美二叉树Perfect binary tree：每一层都填满了</li>
<li>完全二叉树Complete binary tree：除了最后一层其他每一层都是完全填满的，而最后一层从左往右依次排列</li>
</ul>
<h2 id="堆排序的过程"><a href="#堆排序的过程" class="headerlink" title="堆排序的过程"></a>堆排序的过程</h2><ul>
<li>def: 小(大)根堆：完全二叉树 + 每个节点小于(大于)他的子节点。<blockquote>
<p>先把数组构造成最小根堆(最大或者最小都行)<br>while 根堆还有元素:<br>——-弹出顶部最大值<br>——-重新构造最小根堆</p>
</blockquote>
</li>
</ul>
<p>所以堆排序的过程主要是构造(初始化)根堆，和弹出最小值之后再构建根堆(重新维持稳定)根堆。初始化等于一个一个元素插入，重新维持相当于从堆中删除元素。<br>所以，主要是两个步骤：插入和删除。</p>
<h3 id="插入节点："><a href="#插入节点：" class="headerlink" title="插入节点："></a>插入节点：</h3><blockquote>
<p>插入到完全二叉树的最后<br>如果有父节点&amp;&amp;父节点比自己小：<br>——-两个节点交换位置</p>
</blockquote>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200226151338.png"><br>移动次数=层数 所以插入的时间复杂度O(log n)</p>
<h3 id="删除节点："><a href="#删除节点：" class="headerlink" title="删除节点："></a>删除节点：</h3><blockquote>
<p>删除根节点，让末尾最大的值成为新的根节点<br>如果有子节点&amp;&amp;子节点比自己小：<br>——-选择子节点中小的那个，两个节点交换位置</p>
</blockquote>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200226151835.png"></p>
<p>移动次数=层数 所以删除的时间复杂度O(log n)</p>
<h3 id="完全二叉树和数值的索引对应关系"><a href="#完全二叉树和数值的索引对应关系" class="headerlink" title="完全二叉树和数值的索引对应关系"></a>完全二叉树和数值的索引对应关系</h3><p>父节点 i 找子节点：2i+1 , 2i+2<br>子节点找父节点： [(i-1)/2]   向下取整</p>
<h1 id="二叉搜索树-BST博客"><a href="#二叉搜索树-BST博客" class="headerlink" title="二叉搜索树 BST博客"></a>二叉搜索树 <a href="https://blog.csdn.net/csdn0123zl/article/details/81253648" target="_blank" rel="noopener">BST博客</a></h1><ul>
<li>Def: 任何一个节点，小于右子节点，大于左子节点<br>条件不够苛刻，二叉搜索树不唯一。</li>
</ul>
<h2 id="节点的后继："><a href="#节点的后继：" class="headerlink" title="节点的后继："></a>节点的后继：</h2><p>大于这个节点的最小的值。<br>分两种情况，如果这个节点x有右子树，那么这个继承者就是右子树的最小值。<br>如果没有右子树，那么就是这个节点一直往上，第一个向右走的父节点。<br>如图。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200226160114.png"><br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200226160138.png"></p>
<h2 id="插入"><a href="#插入" class="headerlink" title="插入"></a>插入</h2><p>插入很简单，就和查找一样，找到一个位置塞进去就好了。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200226160354.png"></p>
<h2 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h2><p>删除分情况</p>
<ol>
<li>如果0个孩子，直接删</li>
<li>如果1个孩子，用孩子代替这个位置</li>
<li>如果2个孩子，删除孩子的后继，用后继补充这个位置</li>
</ol>
]]></content>
      <categories>
        <category>CSIT5500</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>Q音算法实习复盘</title>
    <url>/2020/Q%E9%9F%B3%E7%AE%97%E6%B3%95%E5%AE%9E%E4%B9%A0%E5%A4%8D%E7%9B%98/</url>
    <content><![CDATA[<p>在11月底面试通过（面试参考之前的<a href="https://leeee.top/2019/%E5%87%86%E5%A4%87Q%E9%9F%B3%E6%8E%A8%E8%8D%90%E7%9A%84%E7%AC%94%E8%AE%B0/">准备Q音推荐实习面试的笔记</a>），开始到腾讯音乐推荐组实习，到上周离职，总共历时2个月3周，排除过年放假的两周，工作9周，50天左右。对于我来说，这是第一次技术岗的实习，虽然大二的时候去YY也做过技术岗，不过那个时候就是写SQL，而且也写得不好😂，算不上技术岗。</p><a id="more"></a>
<p>实习结束整体感受良好，感受到了自己的技术薄弱，熟悉了推荐的相关逻辑，有导师每日交流指点，收获还是很大的。“说说技术上的困难吧，其实还是没经验、熟练度低，一个很简单的事情自己可能要想很久做很久，有时可能还会有疏漏，可能前辈一个小时干的事情，我要几个小时甚至好几天，虽然前辈在给我分配任务的时候可能考虑到这个问题，但其实在我看来感觉还是差的太远，非常愧疚，离职返校后现在还在补充基础知识，c++，还有一些建模熟练度的练习，都有坚持在弄。”</p>
<h1 id="氛围-amp-办公环境"><a href="#氛围-amp-办公环境" class="headerlink" title="氛围&amp;办公环境"></a>氛围&amp;办公环境</h1><p>刚去实习的时候，发现每天需要开晨会，每周需要开周会，周会是投屏展示，感觉压力贼大，加上刚入职的几天啥权限都没有，晨会的时候听着正式员工做了balabala，自己没做出来什么，就很尴尬。不过到后来就好了，可能是因为脸厚了🤫。<br>整体的节奏比较快，团队目标明确，一个季度会有一次OKR的会议(类似与KPI)，每周都会review OKR的完成度，好处是我觉得压力大成长快，不好的地方在于，大家都太忙了，专注于自己的okr，团队之间的闲聊较少，遇到各种小问题就不好问，还好有几个实习生同学，大家可以一起讨论细节问题。</p>
<p>办公环境不咋地，尤其是对比WXG。第一次去的时候没有工位，是一张临时的桌子。到后来，搬了工位，有了稍微大一点的空间，还好点。但是地理位置处于腾大旁边，周围都是写字楼，没有生活气息；再加上深圳，尤其是南山区给我的印象就是到处修修建建，感觉噪音比较大，对于环境不太满意。不过之后去了一趟附近的公园，就感觉心灵有了一片栖息地，有所改观。对比在广州的时候，我感觉珠江一直是我的栖息地，夜跑上班都是走珠江边，会心旷神怡。</p>
<h1 id="实习内容"><a href="#实习内容" class="headerlink" title="实习内容"></a>实习内容</h1><p>实习的任务是实现某推荐点位(脱敏)的留存增长，前期主要熟悉现有逻辑，后期上线三个实现，由于逻辑简单，实验也都获得了正向的反馈。🥰<br>（其实“留存增长”对于算法来说，不好直接优化，不是模型输出的直接指标，更没办法写出来loss function，要做的就是完善推荐策略或者模型就好）</p>
<ul>
<li>实验一：对于召回降级池的年龄划分<br>降级池也叫兜底池，其实用户量不大，但是这一块之前没有做细，就留下了空间，我简单的通过年龄的分层就实现了20%的时长增长。年龄分层就可以理解为一层决策树，所以完全可以用树模型训练一版召回，可能是这里用户量不大，前辈也不想做了。<br>涉及工具：主要是SQL定时任务，计算一个新的榜单，线上的rpc服务用之前写好的。</li>
<li>实验二：增加某个召回策略A的比例<br>前期发现某个召回策略的最终表现较好，但是投放量不大。(🤣我第一反应是只采用这一个召回策略，实际上忽略了太多客观因素) 但是前辈解释策略之后，其实就还有增加召回数量的空间。就简单调整了一下策略，开始做C++服务的改进。<br>涉及工具：C++，git（博文<a href="https://leeee.top/2020/Git%E5%86%8D%E5%85%A5%E9%97%A8/">Git再入门</a>），linux（博文<a href="https://leeee.top/2020/linux%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%86%8D%E5%85%A5%E9%97%A8/">linux从入门到再入门</a>）。大一学过C，但是学的也不深；虽然开发逻辑很简单，还是花了不少时间。</li>
<li>实验三：增加排序的图像特征<br>我只做了离线的验证图像特征有效性。图像特征当然不是我自己跑的啦，准备好数据集，发送给对应做CV的同学，然后用训练好的模型返回数据。拼接到现有的数据集上，跑了xgboost和RankNet两个模型，最后还真的有效果，auc有客观的提升。不错不错。🤤<br>涉及工具：python，拼接特征，然后大概看了看模型的结构。</li>
</ul>
<p>整体来说熟悉开发环境，申请各种权限，了解现有逻辑，熟悉别人代码，占据了主要的时间。😢</p>
<h1 id="杂乱的感悟"><a href="#杂乱的感悟" class="headerlink" title="杂乱的感悟"></a>杂乱的感悟</h1><p>由于思考的过程都很琐碎，就不刻意串起来了，简单罗列。</p>
<p>算法方面：</p>
<ul>
<li>模型、特征的可解释性决定了算法的天花板。如果模型对于我们来说是一个黑匣子，那就只能当”炼丹师“，盲目尝试。这也需要对模型有更深刻的理解。</li>
<li>召回中，策略相对于模型来说，有更好的解释性，也有更好的投放空间，但是个性化推荐不上模型效果往往不佳；建议外层框架用策略，具体召回必须上模型；</li>
<li>排序中，一般来说，加入的特征越多，效果越好；比如专辑封面图都会影响用户对于歌曲的喜好；</li>
<li>对于排序召回的组合推荐算法来说：排序保证了下限，召回决定上限；</li>
</ul>
<p>分析方面：</p>
<ul>
<li>分析数据的时候，每进行下一步操作之前，尽量先给出假设，“如果出现这种情形，我有什么对策”，不然会陷入无意义的数据中，数据不会开口说话告诉你答案。</li>
<li>badcase，要分清楚是个人需求还是群体需求，从而决定优先级；</li>
<li>大部分的算法岗都是结合业务的算法应用，真正硬核的发论文的不多，不要太畏惧。所以懂业务逻辑就很重要，不理解业务就很难洞察到能继续优化的点；eg：转发行为如何区分正负态度；如何衡量不同指标的关系，如完播率和收藏率之间；抖音神曲适不适合适不适合做推荐？不同点位之间的差异（激进还是保守？多样还是资产？）</li>
<li>一旦洞察到优化的点之后，往往简单的逻辑就能造成很好的改善，不一定是很fancy的模型；eg：如果发现用户对于资产的新旧敏感，缩短召回的时间窗口就可以带来很好的效果；</li>
</ul>
<p>其他：</p>
<ul>
<li>每个人有不同的代码风格，但是一定要确保规范：缩进一致、变量命名有意义、备注好解释（防止日后自己都看不懂）；</li>
<li>老板不需要知道怎么使用工具，但是需要懂什么工具能解决什么问题(我遇到的老板知识面很广)；</li>
<li>导师对你严厉很有可能是故意，大概是防止你什么细节都直接过问吧😂，一般大家为人都很好；</li>
</ul>
<p>最后感谢实习期间的导师，让我受益匪浅。</p>
<p>如果你觉得读完有一丢丢用处，就在下面留个言吧👀</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>实习</tag>
        <tag>推荐算法</tag>
      </tags>
  </entry>
  <entry>
    <title>CS224n-3 回顾神经网络，文本分类介绍</title>
    <url>/2020/CS224n-3/</url>
    <content><![CDATA[<p>本节课主要是：<br>分类器回顾，神经网络回顾，NER  Named Entity Recognition，窗口词分类，矩阵计算回顾。总体是回顾旧知识，以及nlp任务的举例，快速过一下。</p><h1 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h1><p>分类问题很常见了，对于NLP来说：</p><a id="more"></a>

<ul>
<li>x ： 单词，句子，文章</li>
<li>y ：情感，是否NER，决策判别，是否人话</li>
</ul>
<h2 id="回顾softmax："><a href="#回顾softmax：" class="headerlink" title="回顾softmax："></a>回顾softmax：</h2><script type="math/tex; mode=display">
p(y | x)=\frac{\exp \left(W_{y} \cdot x\right)}{\sum_{c=1}^{C} \exp \left(W_{c} \cdot x\right)}</script><p>分子：输入向量和矩阵的一行相乘<br>分母：所有相乘，归一化</p>
<p>训练可以直接最大化概率，或者最小化负log概率。</p>
<script type="math/tex; mode=display">p(y_j = 1|x) = \frac{\exp(W_{j\cdot}x)}{\sum_{c=1}^C\exp(W_{c\cdot}x)}</script><p>但是，巧合的是，最小化负log概率对于softmax等同于cross entropy。</p>
<blockquote>
<p> 回顾cross entropy：<br>交叉熵来源于信息论，对于对于c情况真实概率p，模型计算的概率q，那么交叉熵计算为：$H(p, q)=-\sum_{c=1}^{C} p(c) \log q(c)$</p>
</blockquote>
<p>对于softmax的交叉熵来说：</p>
<script type="math/tex; mode=display">
\begin{aligned} H(\hat{y}, y) &=-\sum_{j=1}^{|V|} y_{j} \log \left(\hat{y}_{j}\right) \\ &=-\sum_{j=1}^{C} y_{j} \log \left(p\left(y_{j}=1 | x\right)\right) \\ &=-\sum_{j=1}^{C} y_{j} \log \left(\frac{\exp \left(W_{j}, x\right)}{\sum_{c=1}^{C} \exp \left(W_{c} \cdot x\right)}\right) \\ &=-y_{i} \log \left(\hat{y}_{i}\right) \end{aligned}</script><p>最后一个等号的求和去掉是因为，只有当$y_i$预测对了，才会累加，否则都是0.</p>
<p>所以，交叉熵和负对数概率是等价的。</p>
<p>对于有N个样本的数据集，整体的损失就是：</p>
<script type="math/tex; mode=display">
-\sum_{i=1}^{N} \log \left(\frac{\exp \left(W_{k(i)} \cdot x^{(i)}\right)}{\sum_{c=1}^{C} \exp \left(W_{c} \cdot x^{(i)}\right)}\right)</script><blockquote>
<p>括号里就是对于每一个样本x的预测值概率大小，所有都猜对的话，概率是1，整体损失就是0；当没猜对，概率在0-1，-log(0. xxx)就是很小，损失就多。</p>
</blockquote>
<p>一般的ML问题中，参数由权值矩阵的列组成维度不会太大。而在词向量或其他深度学习中，需要同时学习权值矩阵和词向量。参数一多，就容易过拟合：<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200222013518.png"></p>
<h1 id="神经元的本质"><a href="#神经元的本质" class="headerlink" title="神经元的本质"></a>神经元的本质</h1><p>如果损失函数用sigmoid，单个神经元就是逻辑回归：<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200222014539.png"></p>
<p>而神经网络，就是多个逻辑回归同时计算，如图：<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200222014651.png"><br>上图就是四个逻辑回归(经过4次激活函数)</p>
<h1 id="Named-Entity-Recognition-NER"><a href="#Named-Entity-Recognition-NER" class="headerlink" title="Named Entity Recognition (NER)"></a>Named Entity Recognition (NER)</h1><p>实体识别就是把句子里的实物名字找出来，并且进行分类，比如说组织单位，个人名字，电器名字，软件名字，地点之类的。<br>用途：</p>
<ul>
<li>定位前文的主语</li>
<li>问答系统需要实体</li>
<li>信息一般都与实体相关</li>
<li>slot-filling 填空问题</li>
</ul>
<p>由于自然语言中，大部分实体模糊不清，代词也会干扰，所以不简单。</p>
<blockquote>
<p>实体识别就是把句子里是实物找出来</p>
</blockquote>
<h1 id="窗口单词分类Binary-word-window-classification"><a href="#窗口单词分类Binary-word-window-classification" class="headerlink" title="窗口单词分类Binary word window classification"></a>窗口单词分类Binary word window classification</h1><p>单独对于一个单词分类很难，所以简单思路就是取前后的四五个单词窗口，取平均（或者把向量串起来），然后再进行分类。</p>
<p>但是有一个问题，平均会丢失单词在窗口里的位置。</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200222214054.png"></p>
<p>对于位置问题，可以通过打分来解决（回归）。让位置在中间的样本y高，不在中间的样本（打乱顺序）对应的yscore低。如图。</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200222214634.png"></p>
<h1 id="间隔最大化目标函数"><a href="#间隔最大化目标函数" class="headerlink" title="间隔最大化目标函数"></a>间隔最大化目标函数</h1><p>这里上课老师跳过了，没看懂先挖个坑<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200222215915.png"></p>
<h1 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h1><p>求导，链式法则，老生常谈了。</p>
<p>关注一下矩阵的求导：</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200222220647.png"></p>
<p>对于一个m输出，n输入的函数，求导就是对于m行，每行求对应位置输入x_j的导数。</p>
<p>n个输入n个输出：<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200222221411.png"><br>所以，可以得到一个只有对角线元素上有导数，其他位置为0的矩阵。</p>
<p>所以，最后可以得到s（最后的分数）对b(线性计算加的那个偏置)的导数：<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200222222311.png"></p>
<p>上图中，如果同时对w和b求导可以发现：<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200222222558.png"></p>
<p>观察出，b的导数就是信号的损失</p>
<p>上图第一行，z对w的求导就是x。所以可以得到s对于w的导数，其实就是delt损失和x相乘。</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200222223106.png"></p>
<p>所以导数也是n*m的。</p>
<blockquote>
<p>这里没讲完就下课了…，主要是想展示计算过程吧。</p>
</blockquote>
]]></content>
      <categories>
        <category>CS224n</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>CS224n-2 word2vec, word Senses</title>
    <url>/2020/CS224n-2/</url>
    <content><![CDATA[<h1 id="CS224n-2-word2vec-word-Senses"><a href="#CS224n-2-word2vec-word-Senses" class="headerlink" title="CS224n-2 word2vec, word Senses"></a>CS224n-2 word2vec, word Senses</h1><p>这节课我不按课堂讲的，引用一篇<a href="https://www.jianshu.com/p/a6bc14323d77" target="_blank" rel="noopener">博客</a></p><h1 id="word-vectors-and-word2vec"><a href="#word-vectors-and-word2vec" class="headerlink" title="word vectors and word2vec"></a>word vectors and word2vec</h1><h2 id="代表技术之一-word2vec"><a href="#代表技术之一-word2vec" class="headerlink" title="代表技术之一 word2vec"></a>代表技术之一 word2vec</h2><p>2013年，Google团队发表了word2vec工具 [1]。word2vec工具主要包含两个模型：跳字模型（skip-gram）和连续词袋模型（continuous bag of words，简称CBOW），以及两种近似训练法：负采样（negative sampling）和层序softmax（hierarchical softmax）。值得一提的是，word2vec的词向量可以较好地表达不同词之间的相似和类比关系。</p><a id="more"></a>

<p>word2vec自提出后被广泛应用在自然语言处理任务中。它的模型和训练方法也启发了很多后续的词嵌入模型。本节将重点介绍word2vec的模型和训练方法。</p>
<h2 id="Skip-gram模型（跳字模型）："><a href="#Skip-gram模型（跳字模型）：" class="headerlink" title="Skip-gram模型（跳字模型）："></a>Skip-gram模型（跳字模型）：</h2><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208213903.png"><br>Skip-gram</p>
<p>在跳字模型中，我们用一个词来预测它在文本序列周围的词。</p>
<p>举个例子，假设文本序列是：</p>
<blockquote>
<p>“I love you very much”</p>
</blockquote>
<p>跳字模型所关心的是，给定“<strong>you</strong>”生成邻近词“I”、“love”、“very”和“much”的条件概率。</p>
<p>在这个例子中，“you”叫中心词，“I”、“love”、“very”和“much”叫背景词。</p>
<p>由于“you”只生成与它距离不超过2的背景词，该<strong>时间窗口的大小为2</strong>[与N-gram类似]。</p>
<p>我们来描述一下跳字模型[用最大似然估计的思想]：</p>
<p>假设词典索引集V的大小为|V|，且{0,1,…,|V|−1}。给定一个长度为T的文本序列中，文本序列中第t的词为w(t)。当时间窗口大小为m时，跳字模型需要<strong>最大化给定任一中心词生成所有背景词的概率：</strong></p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208213949.png"></p>
<p>上式的<strong>最大似然估计</strong>与<strong>最小化以下损失函数</strong>等价：</p>
<p><img alt data-src="https://upload-images.jianshu.io/upload_images/1803066-6089ead7ce1ea503.png?imageMogr2/auto-orient/strip|imageView2/2/w/720/format/webp"></p>
<p>我们可以用<strong>v</strong>和<strong>u</strong>分别表示 <strong>中心词</strong> 和 <strong>背景词</strong> 的向量。</p>
<p>换言之，对于词典中索引为i的词，它在作为中心词和背景词时的向量表示分别是vi和ui。而词典中所有词的这两种向量正是跳字模型所要学习的模型参数。为了将模型参数植入损失函数，我们需要使用模型参数表达损失函数中的给定中心词生成背景词的条件概率。给定中心词，假设生成各个背景词是相互独立的。设中心词wc在词典中索引为c，背景词wo在词典中索引为o，损失函数中的给定中心词生成背景词的<strong>条件概率</strong>可以通过softmax函数定义为：</p>
<p><img alt data-src="https://upload-images.jianshu.io/upload_images/1803066-69d819ac1e385080.png?imageMogr2/auto-orient/strip|imageView2/2/w/662/format/webp"></p>
<blockquote>
<p>上式：给定任何一个中心词Wc，产生背景词Wo的概率</p>
<p>每一个词，在模型中有两个词向量，一个是作为中心词时的词向量，一个是作为背景词时的词向量</p>
</blockquote>
<p><strong>利用随机梯度下降求解：</strong></p>
<p>当序列长度T较大时，我们通常在每次迭代时随机采样一个较短的子序列来计算有关该子序列的损失。然后，根据该损失计算词向量的梯度并迭代词向量。具体算法可以参考<a href="https://links.jianshu.com/go?to=http%3A%2F%2Fzh.gluon.ai%2Fchapter_optimization%2Fgd-sgd-scratch.html" target="_blank" rel="noopener">“梯度下降和随机梯度下降——从零开始”</a>一节。 作为一个具体的例子，下面我们看看如何计算随机采样的子序列的损失有关中心词向量的梯度。和上面提到的长度为T的文本序列的损失函数类似，随机采样的子序列的损失实际上是对子序列中给定中心词生成背景词的条件概率的对数求平均。通过微分，我们可以得到上式中条件概率的对数有关中心词向量vc的<strong>梯度：</strong>  </p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208215618.png"></p>
<p><strong>该式也可改写作：</strong></p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208215642.png"></p>
<blockquote>
<p>上面的迭代更新计算开销太大！！每次都需要遍历整个字典，对应的解决方案在后面（这也是word2vec为啥这么牛逼的原因…厉害的不是这个工具本身，而是一种思想的应用）</p>
</blockquote>
<p>随机采样的子序列有关其他词向量的梯度同理可得。训练模型时，每一次迭代实际上是用这些梯度来迭代子序列中出现过的中心词和背景词的向量。训练结束后，对于词典中的任一索引为i的词，我们均得到该词作为中心词和背景词的两组词向量vi和ui。在自然语言处理应用中，我们会使用跳字模型的中心词向量。</p>
<h4 id="求梯度过程"><a href="#求梯度过程" class="headerlink" title="求梯度过程"></a>求梯度过程</h4><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208220835.png"></p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208220909.png"><br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208220919.png"><br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208220926.png"></p>
<hr>
<h3 id="CBOW-连续词袋模型"><a href="#CBOW-连续词袋模型" class="headerlink" title="CBOW(连续词袋模型)"></a>CBOW(连续词袋模型)</h3><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208215727.png"></p>
<p>CBOW</p>
<p>连续词袋模型与跳字模型类似,与跳字模型最大的不同是：</p>
<p>连续词袋模型用一个中心词在文本序列周围的词来预测该中心词。</p>
<p>举个例子，假设文本序列为：</p>
<blockquote>
<p>“I love you very much”</p>
</blockquote>
<p>连续词袋模型所关心的是，邻近词“I”、“love”、“very”和“much”一起生成中心词“you”的概率。</p>
<p>假设词典索引集的大小为V，且V={0,1,…,|V|−1}&lt;/nobr&gt;。给定一个长度为T的文本序列中，文本序列中第t个词为wu(t)。当时间窗口大小为m时，连续词袋模型需要最大化由背景词生成任一中心词的概率</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208215738.png"></p>
<p>上式的最大似然估计与最小化以下损失函数等价：</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208215749.png"></p>
<p>我们可以用<strong>v</strong>和<strong>u</strong>分别表示背景词和中心词的向量（注意符号和跳字模型中的不同）。换言之，对于词典中索引为i的词，它在作为背景词和中心词时的向量表示分别是vi和ui。而词典中所有词的这两种向量正是连续词袋模型所要学习的模型参数。为了将模型参数植入损失函数，我们需要使用模型参数表达损失函数中的给定背景词生成中心词的概率。设中心词wc在词典中索引为c，背景词wo1、wo2、…wo2m在词典中索引为o1、o2、….o2m-1、o2m，损失函数中的给定背景词生成中心词的概率可以通过softmax函数定义为</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208215805.png"></p>
<p>和跳字模型一样，当序列长度T较大时，我们通常在每次迭代时随机采样一个较短的子序列来计算有关该子序列的损失。然后，根据该损失计算词向量的梯度并迭代词向量。 通过微分，我们可以计算出上式中条件概率的对数有关任一背景词向量voi(i=1,2,….2m)的梯度为：<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208221019.png"></p>
<p>该式也可写作</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208221029.png"></p>
<p>随机采样的子序列有关其他词向量的梯度同理可得。和跳字模型一样，训练结束后，对于词典中的任一索引为i的词，我们均得到该词作为背景词和中心词的两组词向量vi和ui。<br>在自然语言处理应用中，我们会使用连续词袋模型的背景词向量。</p>
<hr>
<h1 id="近似训练法"><a href="#近似训练法" class="headerlink" title="近似训练法"></a>近似训练法</h1><p>我们可以看到，无论是skip-gram(跳字模型)还是CBOW(连续词袋模型)，每一步梯度计算的开销与词典V的大小相关。</p>
<blockquote>
<p>因为计算softmax的时考虑了字典上的所有可能性</p>
</blockquote>
<p>当词典较大时，例如几十万到上百万，这种训练方法的计算开销会较大。因此，我们将使用近似的方法来计算这些梯度，从而减小计算开销。常用的近似训练法包括负采样和层序softmax。</p>
<h2 id="1-负采样（Negative-Sample）"><a href="#1-负采样（Negative-Sample）" class="headerlink" title="(1)负采样（Negative Sample）"></a>(1)负采样（Negative Sample）</h2><p>我们以跳字模型为例讨论负采样。</p>
<p>实际上，词典V的大小之所以会在损失中出现，是因为给定中心词$w_c$生成背景词wo的条件概率$P(w_0∣w_c)$</p>
<blockquote>
<p>使用了softmax运算，而softmax运算正是<strong>考虑了背景词可能是词典中的任一词（使用了全部词）</strong>，并体现在分母上。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208224459.png"></p>
</blockquote>
<p>下面，我们可以使用σ(x)=1/(1+exp(−x))函数来表达中心词wc和背景词wo同时出现在该训练数据窗口的概率。</p>
<blockquote>
<p>σ(x)属于[0,1]<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208224516.png"></p>
</blockquote>
<p>那么，给定中心词wc生成背景词wo的条件概率的对数可以近似为:<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208224525.png"></p>
<p>[上式的含义：中心词wc与背景词wo同时出(D=1)现概率，且中心词wc与噪音词wk不同时出现(D=0)的概率。]</p>
<p>假设噪声词wk在词典中的索引为ik，上式可改写为:</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208224609.png"></p>
<p>因此，有关给定中心词wc生成背景词wo的损失是:</p>
<p>假设词典V很大，每次迭代的计算开销由O(|V|)变为O(|K|)。当我们把K取较小值时，负采样每次迭代的计算开销将较小。</p>
<p>当然，我们也可以对连续词袋模型进行负采样。有关给定背景词<br>wt-m、wt-m+1、…、wt+m生成中心词wc的损失:<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208224615.png"></p>
<p>在负采样中可以近似为:</p>
<p>  <img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208224627.png"></p>
<p>同样，当我们把K取较小值时，负采样每次迭代的计算开销将较小。</p>
<h2 id="2-层序softmax"><a href="#2-层序softmax" class="headerlink" title="(2)层序softmax[]"></a>(2)层序softmax[]</h2><p>层序softmax是另一种常用的近似训练法。它利用了二叉树这一数据结构。树的每个叶子节点代表着词典V中的每个词。  </p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208224641.png"></p>
<p>假设L(w)为从二叉树的根节点到词w&lt;的叶子节点的路径（包括根和叶子节点）上的节点数。设n(w,j)为该路径上第j个节点，并设该节点的向量为un(w,j)。以上图为例：L(w3)=4。设词典中的词wi的词向量为vi。那么，跳字模型和连续词袋模型所需要计算的给定词wi生成词w的条件概率为：<img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208224651.png"><br>其中σ(x)=1/(1+exp(−x))，leftChild(n)是节点n的左孩子节点，如果判断x为真，[x]=1；反之[x]=−1。由于σ(x)+σ(−x)=1，给定词wi生成词典V中任一词的条件概率之和为1这一条件也将满足：<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208224729.png"></p>
<p>让我们计算给定词wi生成词w3的条件概率。我们需要将wi的词向量vi和根节点到w3路径上的非叶子节点向量一一求内积。由于在二叉树中由根节点到叶子节点w3的路径上需要向左、向右、再向左地遍历，我们得到:<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208224736.png"></p>
<blockquote>
<p><strong>整个遍历的路径已经通过Huffman编码唯一的确定了</strong></p>
</blockquote>
<p>在使用softmax的跳字模型和连续词袋模型中，词向量和二叉树中非叶子节点向量是需要学习的模型参数。</p>
<p>假设词典V很大，每次迭代的计算开销由O(|V|)下降至O(log2|V|)。</p>
<p>推荐资料：<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Fx-hacker%2FWordEmbedding" target="_blank" rel="noopener">学习word2vec的经典资料</a></p>
<h1 id="SVD"><a href="#SVD" class="headerlink" title="SVD"></a>SVD</h1><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208225228.png"></p>
<p>分解矩阵，就可以得到embedding，和推荐系统的思路一样。SVD也存在维数问题，以及矩阵分解的困难。</p>
<h1 id="GloVe算法-基于局部和全局"><a href="#GloVe算法-基于局部和全局" class="headerlink" title="GloVe算法-基于局部和全局"></a>GloVe算法-基于局部和全局</h1><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208225801.png"><br>比较SVD这种count based模型与Word2Vec这种direct prediction模型，它们各有优缺点：Count based模型优点是训练快速，并且有效的利用了统计信息，缺点是对于高频词汇较为偏向，并且仅能概括词组的相关性，而且有的时候产生的word vector对于解释词的含义如word analogy等任务效果不好；Direct Prediction优点是可以概括比相关性更为复杂的信息，进行word analogy等任务时效果较好，缺点是对统计信息利用的不够充分。所以Manning教授他们想采取一种方法可以结合两者的优势，并将这种算法命名为GloVe（Global Vectors的缩写），表示他们可以有效的利用全局的统计信息。</p>
<p>那么如何有效的利用word-word co-occurrence count并能学习到词语背后的含义呢？首先为表述问题简洁需要，先定义一些符号：对于矩阵X，$X_{ij}$代表了单词 i 出现在单词 j 上下文中的次数，则$X_i=\sum_k X_{ij}$<br> 即代表所有出现在单词 i 的上下文中的单词次数。我们用$P_{i j}=P(j | i)=\frac{X_{i j}}{X_{i}}$来代表单词 j 出现在单词 i 上下文中的概率。</p>
<p>我们用一个小例子来解释如何利用co-occurrence probability来表示词汇含义：<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208225816.png"><br>例如我们想区分热力学上两种不同状态ice冰与蒸汽steam，它们之间的关系可通过与不同的单词 [公式] 的co-occurrence probability 的比值来描述，例如对于solid固态，虽然 $P(solidice)$ 与 $P(solid∣steam)$本身很小，不能透露有效的信息，但是它们的比值$\frac{P(solid|ice)} {P(solid|steam)}$ 却较大，因为solid更常用来描述ice的状态而不是steam的状态，所以在ice的上下文中出现几率较大，对于gas则恰恰相反，而对于water这种描述ice与steam均可或者fashion这种与两者都没什么联系的单词，则比值接近于1。所以相较于单纯的co-occurrence probability，实际上co-occurrence probability的相对比值更有意义。</p>
<p>通过定义如下的损失函数：<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208230330.png"></p>
<p>优点是训练快，小数据集表现好。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208233632.png"></p>
]]></content>
      <categories>
        <category>CS224n</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>CS224n-1 初步探索，背景介绍  </title>
    <url>/2020/CS224n-1/</url>
    <content><![CDATA[<p>NLP持续升温，作为入门课程，224n声名远扬。<br>听了10节课之后，果然感觉不愧是斯坦福。<br>这门课逻辑很清晰（遇到什么问题，产生什么思路，做了什么探索模型，怎么解决问题），而不是直接的扔出来一个模型，之前遇到很多老师这样，让人摸不到头脑；这门课会讲如何做一个研究以及如何写一篇paper。这些虽然不是NLP必备，是一些普世的知识，但是课堂上不讲，学生也很难完全了解到，基本上都、是自己摸索。</p><a id="more"></a>
<p>总的来说，觉得相见恨晚，虽然有点难，但是学的很舒服！现在开始整理每节课的笔记。</p>
<hr>
<p>Lecture 1: Introduction and Word Vectors 第一节课主要是介绍背景</p>
<h1 id="The-course-10-mins"><a href="#The-course-10-mins" class="headerlink" title="The course (10 mins)"></a>The course (10 mins)</h1><h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p><strong>自然语言处理（NLP）</strong>是计算科学、AI、语言学的交叉学科，其目的是为了让机器能够处理或者是“理解”自然语言，比如可以通过说话让机器为我们定会议、买东西。机器完全理解是不大可能的，完全理解基本等同于AI完全实现了。</p>
<h2 id="如何表示词义？"><a href="#如何表示词义？" class="headerlink" title="如何表示词义？"></a>如何表示词义？</h2><ul>
<li><p>Def：meaning：就是人写的，说的，短语句子符号来表达的想法</p>
<h2 id="如何用计算机表达词义？"><a href="#如何用计算机表达词义？" class="headerlink" title="如何用计算机表达词义？"></a>如何用计算机表达词义？</h2><h3 id="WordNet："><a href="#WordNet：" class="headerlink" title="WordNet："></a>WordNet：</h3><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208165156.png"></p>
<p>WordNet是人为的收录了近义词和相似词。<br>存在的问题是：没办法统计到细微差别；没有新词；需要人为的统计输入；不能计算相似度；依赖生成词库的主观。</p>
</li>
</ul>
<h3 id="把词当做离散变量one-hot"><a href="#把词当做离散变量one-hot" class="headerlink" title="把词当做离散变量one-hot"></a>把词当做离散变量one-hot</h3><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208165732.png"></p>
<p> 存在的问题是：词库长度太大；不能计算相似度；</p>
<h3 id="通过上下文表示"><a href="#通过上下文表示" class="headerlink" title="通过上下文表示"></a>通过上下文表示</h3><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208170015.png"><br>通过上下文的思路，可以引出主流方法Word vectors（word embeddings or word representations）。<br>每一个词对应一个N维度的向量，N一般几百维。</p>
<h1 id="Word2vec"><a href="#Word2vec" class="headerlink" title="Word2vec"></a>Word2vec</h1><p>从2013年开始有了Word2vec，如何生成向量的方法逐渐出现。</p>
<p>思路：</p>
<ul>
<li>有一个大的语料库</li>
<li>每个词都表示成向量</li>
<li>遍历每个词，中间的词当做c，周围的几个当做o</li>
<li>通过计算每个词向量和周围词向量出现的概率</li>
<li>调整词向量，让概率最大</li>
</ul>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208171649.png"></p>
<p>目标函数：</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208171826.png"></p>
<p>理解：这里就是对于语料(Data)的每个词t，对应前后j位置的词，是词a和词b的概率P，都乘起来。（这里还是很有统计色彩的)</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208172914.png"><br>注意：这里需要维护两套向量，一套是中间的，一套是周围的。</p>
<p>其他的都是一些微积分和优化的知识，不做记录了。</p>
]]></content>
      <categories>
        <category>CS224n</category>
      </categories>
      <tags>
        <tag>NLP</tag>
      </tags>
  </entry>
  <entry>
    <title>FM,FFM,DeepFM </title>
    <url>/2020/FM-FFM%E4%B8%8E%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<p>最近过年在家因为疫情不能外出，随手抓了本推荐系统开始看。模型部分从传统的邻域（协同过滤）到隐语义模型（LFM）到矩阵分解模型（SVD，SVD++），FM和FFM等遇到颇多问题，在此梳理一下。</p><h1 id="FM"><a href="#FM" class="headerlink" title="FM"></a>FM</h1><p>FM的paper地址如下：<a href="https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf" target="_blank" rel="noopener">https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf</a><br>FM主要目标是：解决数据稀疏的情况下，特征怎样组合的问题<br>根据paper的描述，FM有一下三个优点：</p><a id="more"></a>

<ol>
<li>处理稀疏数据</li>
<li>FM模型的时间复杂度是线性的</li>
<li>FM是一个通用模型，它可以用于任何特征为实值的情况</li>
</ol>
<ul>
<li>一般的线性模型：<br>$y=w_{0}+\sum_{i=1}^{n} w_{i} x_{i}$</li>
</ul>
<p>从上面的式子中看出，一般的线性模型没有考虑特征之间的关联。</p>
<ul>
<li>为了简化，采用最简单的<strong>二阶组合+多项式相乘</strong>作为关联特征的例子。<br>$y=w_{0}+\sum_{i=1}^{n} w_{i} x_{i}+\sum_{i=1}^{n} \sum_{j=i+1}^{n} w_{i j} x_{i} x_{j}$</li>
</ul>
<p>该多项是模型与线性模型相比，多了特征组合的部分，特征组合部分的参数有$\frac{n(n-1)}{2}$个($w_{i j}$是对称的)。如果特征非常稀疏且维度很高的话，时间复杂度O(N^2)。<br>所以，通过引入辅助向量lantent vector $V_{i}=\left[v_{i 1}, v_{i 2}, \dots, v_{i k}\right]^{T}$来表示$\frac{n(n-1)}{2}$个参数。（这里借用了FunkSVD(LFM，Latent Factor Model)的思想）    </p>
<ul>
<li>FM<script type="math/tex; mode=display">y=w_{0}+\sum_{i=1}^{n} w_{i} x_{i}+\sum_{i=1}^{n} \sum_{j=i+1}^{n}<V_{i}, V_{j}>x_{i} x_{j}</script></li>
</ul>
<p>这里，辅助向量V的长度K一般是远远小于n的，所以参数量从$\frac{n(n-1)}{2}$个变成了$nk$，参数量降低，而且每一个向量V也表示了x的一个维度，有更好的解释性，<strong>本质上是在对特征进行embedding</strong>。且时间复杂度降为O(kN).</p>
<p>时间复杂度化简后方可看出：<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200129213611.png"></p>
<h1 id="FFM-Field-aware-Factorization-Machines"><a href="#FFM-Field-aware-Factorization-Machines" class="headerlink" title="FFM(Field-aware Factorization Machines)"></a>FFM(Field-aware Factorization Machines)</h1><p>FFM是FM的升级版模型，引入了field的概念。FFM把相同性质的特征归于同一个field。在FFM中，每一维特征$x_i$，针对每一种field $f_j$，都会学习到一个隐向量$V_{i,f_j}$，因此，隐向量不仅与特征相关，也与field相关。</p>
<p>设样本一共有n个特征, f 个field，那么FFM的二次项有nf个隐向量。而在FM模型中，每一维特征的隐向量只有一个。FM可以看做FFM的特例，即把所有特征都归属到同一个field中。</p>
<script type="math/tex; mode=display">y = w_0 + \Sigma_{i=1}^{n}w_{i} x_{i} + \Sigma_{i=1}^{n}\Sigma_{j=i+1}^{n}<V_{i,f_{j}}, V_{j,f_{i}}>x_{i}x_{j}</script><p>如果隐向量的长度为k，那么FFM的二次项参数数量为nfk，远多于FM模型。此外由于隐向量与field相关，FFM二次项并不能够化简，时间复杂度为$O(kn^2)$。需要注意的是由于FFM中的latent vector只需要学习特定的field，所以通常$K_{FFM} &lt;&lt; K_{FM}$。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200130123459.png"></p>
<h1 id="DeepFM"><a href="#DeepFM" class="headerlink" title="DeepFM"></a>DeepFM</h1><p>当理解了FM，deepfm的思路也就很好懂了。</p>
<p>fm是低阶特征，dnn是高阶特征，把低阶和高阶特征并行就是deepFM<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200130132900.png"><br>我们先来看一下DeepFM的模型结构：</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200130135729.png"><br>FM部分是一个因子分解机。关于因子分解机可以参阅文章[Rendle, 2010] Steffen Rendle. Factorization machines. In ICDM, 2010.。因为引入了隐变量的原因，对于几乎不出现或者很少出现的隐变量，FM也可以很好的学习。<br><strong>深度部分</strong><br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200130135817.png"></p>
<p>深度部分是一个前馈神经网络。与图像或者语音这类输入不同，图像语音的输入一般是连续而且密集的，然而用于CTR的输入一般是及其稀疏的。因此需要重新设计网络结构。具体实现中为，在第一层隐含层之前，引入一个嵌入层来完成将输入向量压缩到低维稠密向量。</p>
<p>  <img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200130135833.png"><br>  嵌入层(embedding layer)的结构如上图所示。当前网络结构有两个有趣的特性，1）尽管不同field的输入长度不同，但是embedding之后向量的长度均为K。2)在FM里得到的隐变量Vik现在作为了嵌入层网络的权重。</p>
<p>这里的第二点如何理解呢，假设我们的k=5，首先，对于输入的一条记录，同一个field 只有一个位置是1，那么在由输入得到dense vector的过程中，输入层只有一个神经元起作用，得到的dense vector其实就是输入层到embedding层该神经元相连的五条线的权重，即vi1，vi2，vi3，vi4，vi5。这五个值组合起来就是我们在FM中所提到的Vi。在FM部分和DNN部分，这一块是共享权重的，对同一个特征来说，得到的Vi是相同的。</p>
<p>代码地址：<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2FChenglongChen%2Ftensorflow-DeepFM" target="_blank" rel="noopener">https://github.com/ChenglongChen/tensorflow-DeepFM</a></p>
<p>梳理FM发展历史：<a href="https://zhuanlan.zhihu.com/p/52877868" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/52877868</a><br>参考FM：<a href="https://blog.csdn.net/John_xyz/article/details/78933253" target="_blank" rel="noopener">https://blog.csdn.net/John_xyz/article/details/78933253</a><br>带举例的解释：<a href="https://blog.csdn.net/baymax_007/article/details/83931698" target="_blank" rel="noopener">https://blog.csdn.net/baymax_007/article/details/83931698</a><br>推荐系统遇上深度学习系列1-3：<a href="https://www.jianshu.com/p/6f1c2643d31b" target="_blank" rel="noopener">https://www.jianshu.com/p/6f1c2643d31b</a></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>推荐系统</tag>
      </tags>
  </entry>
  <entry>
    <title>2020香港马拉松备赛</title>
    <url>/2020/2020%E9%A6%99%E6%B8%AF%E9%A9%AC%E6%8B%89%E6%9D%BE%E5%A4%87%E8%B5%9B/</url>
    <content><![CDATA[<p>2020香港马拉松倒计时：</p><hr><p>备赛日记</p><h1 id="1月26日"><a href="#1月26日" class="headerlink" title="1月26日"></a>1月26日</h1><p>因为肺炎，大赛取消。 渣马有缘再见。<br><img width="50%" data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200126115659.png"></p><h1 id="1月14日"><a href="#1月14日" class="headerlink" title="1月14日"></a>1月14日</h1><p>早上跑了5公里，公园高低起伏，上坡下坡很不舒服。速度也提不上来，就当是第一次热身了。</p><h1 id="1月13日"><a href="#1月13日" class="headerlink" title="1月13日"></a>1月13日</h1><p>周一开完组会已经11点了，放弃了。</p><a id="more"></a>





<h1 id="1月12日-发现场地，初步热身，开始备赛"><a href="#1月12日-发现场地，初步热身，开始备赛" class="headerlink" title="1月12日 发现场地，初步热身，开始备赛"></a>1月12日 发现场地，初步热身，开始备赛</h1><p>我是大二的时候开始热爱运动的，当时也奇怪，总想热爱点什么。没想到跑步坚持了一年多，才放弃。当时不知道哪来的热情，六七点起床去跑珠江边，一跑就是十来公里，上头的时候早上8点的课，我也要6点去跑步。现在真的没有那么兴奋了233333。当时的想法就是参加一次马拉松证明一下自己。本科四年，报名了三次广州马拉松的半马，结果三次都没有中签。害，现在跑个步都要排队的吗？到之后兴趣也就慢慢减弱了。</p>
<p>而打败跑步的是另一个热爱，健身。连续去了健身房两年，一周三次以上，让我学习了几乎所有b站建设up主的教程，在学校的英东健身房也算是“有头有脸”的人。认识了许多小老弟。</p>
<p>害，扯远了。上学期在香港，看到香港马拉松的报名，毫不犹豫的直接报名了。时间是2月8号，也就是开学后一天。离现在也只有不到一个月的时间，近几个月我好吃懒做，加班严重，公司附近也没有很好的健身房(其实是没有去找)。反正就是心肺都下降了很多，力量也弱，六七个引体都做不了(去年还能一次30个呢，哼)。</p>
<p>所以，接下来三周，我要进入疯狂备赛阶段，今晚去公司对面的公园，发现环境还不错，面积挺大，一圈又两公里左右。有很多跑步的人和健身老头。所以我可以接下来一周(11-19号)就在公园锻炼，然后过年回家十来天，在家的体育场，年后(2月1号-7号)再来一周公园锻炼，就要去跑马拉松啦。</p>
<pre><code>&lt;div style=&quot;width:100%; height:50px;border:none;text-align:center&quot;&gt;
&lt;center&gt;&lt;iframe allowtransparency=&quot;yes&quot; frameborder=&quot;0&quot; src=&quot;/time.html&quot;/&gt;&lt;/center&gt;
&lt;/div&gt;
</code></pre>]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>运动</tag>
      </tags>
  </entry>
  <entry>
    <title>Git再入门</title>
    <url>/2020/Git%E5%86%8D%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<h1 id="认识多年，但我还是不懂你—GIT"><a href="#认识多年，但我还是不懂你—GIT" class="headerlink" title="认识多年，但我还是不懂你—GIT"></a>认识多年，但我还是不懂你—GIT</h1><p>虽然用github已经很多年了，但是git的各种命令没怎么接触过，能用的也只是简单的clone和pull，也没用真正的理解git的内涵。作为多人合作和版本控制的工具，git强大的一面我还没有接触到。</p><a id="more"></a>
<p>最近实习的时候需要编写cpp服务，写好了就需要git push 到新的分支去，等待导师code review，然后merge到master，中间遇到很多坑，在此就一篇文章整理完所有git方面的知识。</p>
<p>刚开始接触git会遇到很多命令，记不住没关系，先花两个小时理解git的概念，之后遇到问题再查。<br>详细教程可以看：<a href="https://www.runoob.com/git/git-tutorial.html" target="_blank" rel="noopener">https://www.runoob.com/git/git-tutorial.html</a></p>
<h1 id="版本控制"><a href="#版本控制" class="headerlink" title="版本控制"></a>版本控制</h1><p>版本控制（Revision control）是一种在开发的过程中用于管理我们对文件、目录或工程等内容的修改历史，方便查看更改历史记录，备份以便恢复以前的版本的软件工程技术。</p>
<ul>
<li>实现跨区域多人协同开发</li>
<li>追踪和记载一个或者多个文件的历史记录</li>
<li>组织和保护你的源代码和文档</li>
<li>统计工作量</li>
<li>并行开发、提高开发效率</li>
<li>跟踪记录整个软件的开发过程</li>
<li>减轻开发人员的负担，节省时间，同时降低人为错误</li>
</ul>
<p><strong>简单说就是用于管理多人协同开发项目的技术。</strong></p>
<h1 id="git的基本概念"><a href="#git的基本概念" class="headerlink" title="git的基本概念"></a>git的基本概念</h1><h2 id="工作区"><a href="#工作区" class="headerlink" title="工作区"></a>工作区</h2><p>Git本地有四个工作区域：工作目录（Working Directory）、暂存区(Stage/Index)、资源库(Repository或Git Directory)、git仓库(Remote Directory)。文件在这四个区域之间的转换关系如下：<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200111202138.png"><br><strong>Workspace</strong>： 工作区，就是你平时存放项目代码的地方<br><strong>Index / Stage</strong>： 暂存区，用于临时存放你的改动，事实上它只是一个文件，保存即将提交到文件列表信息<br><strong>Repository</strong>： 仓库区（或版本库），就是安全存放数据的位置，这里面有你提交到所有版本的数据。其中HEAD指向最新放入仓库的版本<br><strong>Remote</strong>： 远程仓库，托管代码的服务器，可以简单的认为是你项目组中的一台电脑用于远程数据交换</p>
<h1 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h1><ol>
<li>clone项目或者创建项目Repository</li>
<li>写代码</li>
<li>git add 修改了的有价值的代码到index</li>
<li>index commit提交到本地的项目Repository</li>
<li>本地改好了就上传到服务器上remote</li>
</ol>
<h1 id="文件的四种状态"><a href="#文件的四种状态" class="headerlink" title="文件的四种状态"></a>文件的四种状态</h1><p>版本控制就是对文件的版本控制，要对文件进行修改、提交等操作，首先要知道文件当前在什么状态，不然可能会提交了现在还不想提交的文件，或者要提交的文件没提交上。</p>
<p>GIT不关心文件两个版本之间的具体差别，而是关心文件的整体是否有改变，若文件被改变，在添加提交时就生成文件新版本的快照，而判断文件整体是否改变的方法就是用SHA-1算法计算文件的校验和。</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200111202617.png"><br><strong>Untracked:</strong> 未跟踪, 此文件在文件夹中, 但并没有加入到git库, 不参与版本控制. 通过git add 状态变为Staged.</p>
<p><strong>Unmodify:</strong> 文件已经入库, 未修改, 即版本库中的文件快照内容与文件夹中完全一致. 这种类型的文件有两种去处, 如果它被修改, 而变为Modified. 如果使用git rm移出版本库, 则成为Untracked文件</p>
<p><strong>Modified:</strong>  文件已修改, 仅仅是修改, 并没有进行其他的操作. 这个文件也有两个去处, 通过git add可进入暂存staged状态, 使用git checkout 则丢弃修改过,返回到unmodify状态, 这个git checkout即从库中取出文件, 覆盖当前修改</p>
<p><strong>Staged:</strong> 暂存状态. 执行git commit则将修改同步到库中, 这时库中的文件和本地文件又变为一致, 文件为Unmodify状态. 执行git reset HEAD filename取消暂存,文件状态为Modified</p>
<p>下面的图很好的解释了这四种状态的转变：</p>
<p><img alt data-src="https://img2018.cnblogs.com/blog/1090617/201810/1090617-20181008212245877-52530897.png"></p>
<h1 id="四个区域之间的命令"><a href="#四个区域之间的命令" class="headerlink" title="四个区域之间的命令"></a>四个区域之间的命令</h1><h4 id="1、新建代码库"><a href="#1、新建代码库" class="headerlink" title="1、新建代码库"></a>1、新建代码库</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 在当前目录新建一个Git代码库</span><br><span class="line">git init # 新建一个目录，将其初始化为Git代码库</span><br><span class="line">git init [project-name] # 下载一个项目和它的整个代码历史</span><br><span class="line">git clone [url]</span><br></pre></td></tr></table></figure>
<h4 id="2、查看文件状态"><a href="#2、查看文件状态" class="headerlink" title="2、查看文件状态"></a>2、查看文件状态</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#查看指定文件状态</span><br><span class="line">git status [filename] #查看所有文件状态</span><br><span class="line">git status</span><br></pre></td></tr></table></figure>
<h4 id="3、工作区-lt-—-gt-暂存区"><a href="#3、工作区-lt-—-gt-暂存区" class="headerlink" title="3、工作区&lt;—&gt;暂存区"></a>3、工作区&lt;—&gt;暂存区</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 添加指定文件到暂存区</span><br><span class="line">git add [file1] [file2] ... # 添加指定目录到暂存区，包括子目录</span><br><span class="line">git add [dir] # 添加当前目录的所有文件到暂存区</span><br><span class="line">git add . #当我们需要删除暂存区或分支上的文件, 同时工作区也不需要这个文件了, 可以使用（⚠️）</span><br><span class="line">git rm file_path #当我们需要删除暂存区或分支上的文件, 但本地又需要使用, 这个时候直接push那边这个文件就没有，如果push之前重新add那么还是会有。</span><br><span class="line">git rm --cached file_path #直接加文件名   从暂存区将文件恢复到工作区，如果工作区已经有该文件，则会选择覆盖 #加了【分支名】 +文件名  则表示从分支名为所写的分支名中拉取文件 并覆盖工作区里的文件</span><br><span class="line">git checkout</span><br></pre></td></tr></table></figure>
<h4 id="4、工作区-lt-—-gt-资源库（版本库）"><a href="#4、工作区-lt-—-gt-资源库（版本库）" class="headerlink" title="4、工作区&lt;—&gt;资源库（版本库）"></a>4、工作区&lt;—&gt;资源库（版本库）</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#将暂存区--&gt;资源库（版本库）</span><br><span class="line">git commit -m &apos;该次提交说明&apos;</span><br><span class="line">#如果出现:将不必要的文件commit 或者 上次提交觉得是错的  或者 不想改变暂存区内容，只是想调整提交的信息</span><br><span class="line">#移除不必要的添加到暂存区的文件</span><br><span class="line">git reset HEAD 文件名 #去掉上一次的提交（会直接变成add之前状态） </span><br><span class="line">git reset HEAD^ </span><br><span class="line">#去掉上一次的提交（变成add之后，commit之前状态） </span><br><span class="line">git reset --soft  HEAD^</span><br></pre></td></tr></table></figure>
<h4 id="5、远程操作"><a href="#5、远程操作" class="headerlink" title="5、远程操作"></a>5、远程操作</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 取回远程仓库的变化，并与本地分支合并</span><br><span class="line">git pull # 上传本地指定分支到远程仓库</span><br><span class="line">git push</span><br></pre></td></tr></table></figure>
<h4 id="6、其它常用命令"><a href="#6、其它常用命令" class="headerlink" title="6、其它常用命令"></a>6、其它常用命令</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 显示当前的Git配置</span><br><span class="line">git config --list # 编辑Git配置文件</span><br><span class="line">git config -e [--global] #初次commit之前，需要配置用户邮箱及用户名，使用以下命令：</span><br><span class="line">git config --global user.email &quot;you@example.com&quot;</span><br><span class="line">git config --global user.name &quot;Your Name&quot;</span><br><span class="line">#调出Git的帮助文档</span><br><span class="line">git --help #查看某个具体命令的帮助文档</span><br><span class="line">git +命令 --help #查看git的版本</span><br><span class="line">git --version</span><br></pre></td></tr></table></figure>
<p>参考：<a href="https://www.cnblogs.com/qdhxhz/p/9757390.html" target="_blank" rel="noopener">https://www.cnblogs.com/qdhxhz/p/9757390.html</a></p>
]]></content>
      <categories>
        <category>工程</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>linux从入门到再入门</title>
    <url>/2020/linux%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%86%8D%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<h1 id="Linux-工程必备"><a href="#Linux-工程必备" class="headerlink" title="Linux-工程必备"></a>Linux-工程必备</h1><p>一直以来，没有系统的学习过linux，每次遇到工程问题，总是靠着百度和谷歌，效率很低。<br>最近需要部署C++服务，所以需要LINUX环境，在此立帖，持续更新，直到熟练使用linux。</p><h1 id="用户管理"><a href="#用户管理" class="headerlink" title="用户管理"></a>用户管理</h1><a id="more"></a>
<ul>
<li>查看当前用户<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">$ cat /etc/passwd</span><br></pre></td></tr></table></figure></li>
<li>添加新用户<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ adduser 选项 username</span><br><span class="line">·</span><br><span class="line">选项可以有：</span><br><span class="line">-c 		comment 指定一段注释性描述。</span><br><span class="line">-d(常用）  目录 指定用户主目录，如果此目录不存在，则同时使用-m选项，可以创建主目录。</span><br><span class="line">-g(常用）  用户组 指定用户所属的用户组。</span><br><span class="line">-G 		用户组，用户组 指定用户所属的附加组。</span><br><span class="line">-s 		Shell文件 指定用户的登录Shell。</span><br><span class="line">-u 		用户号 指定用户的用户号，如果同时有-o选项，则可以重复使用其他用户的标识号。</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>例1：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">useradd –d /usr/sam</span><br></pre></td></tr></table></figure><br>此命令创建了一个用户sam，其中-d选项用来为登录名sam产生一个主目录/usr/sam（/usr为默认的用户主目录所在的父目录）。</p>
<p>例2：<br>代码:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">useradd -s /bin/sh -g group –G adm,root gem</span><br></pre></td></tr></table></figure><br>此命令新建了一个用户gem，该用户的登录Shell是/bin/sh，它属于group用户组，同时又属于adm和root用户组，其中group用户组是其主组。</p>
<ul>
<li>给新用户加密码<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ passwd 选项(不选最简单) 用户名</span><br><span class="line">·</span><br><span class="line">-l 锁定口令，即禁用账号。</span><br><span class="line">-u 口令解锁。</span><br><span class="line">-d 使账号无口令。</span><br><span class="line">-f 强迫用户下次登录时修改口令。</span><br><span class="line">如果默认用户名，则修改当前用户的口令。</span><br><span class="line">然后输入两次密码就行了。</span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li>删除账号<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ userdel 选项(建议-r） 账户名</span><br><span class="line">-r 可以把主目录一起删除</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h1 id="文件权限与访问控制"><a href="#文件权限与访问控制" class="headerlink" title="文件权限与访问控制"></a>文件权限与访问控制</h1><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200107231346.png"><br>Linux文件系统权限：</p>
<p><img alt data-src="https://img-blog.csdn.net/20180711160810276?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjQ0MjcxMw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"></p>
<h1 id="文件操作"><a href="#文件操作" class="headerlink" title="文件操作"></a>文件操作</h1><p><strong>一、Linux系统的结构</strong></p>
<p>　　1、Linux是一个倒树型结构，最大的目录名称为“/”（根目录）</p>
<p>　　2、Linux系统的二级目录</p>
<p>　　/bin　　 ##binary二进制可执行文件，系统常规命令<br>　　/boot 　　 ##启动目录，存放系统自动启动文件，内核，初始化程序<br>　　/dev ##系统设备管理文件<br>　　/etc　　 ##大多数系统配置文件存放路径<br>　　/home 　 ##普通用户家目录（/home/student）<br>　　/media 　 ##临时的挂载点<br>　　/lib　　 ##函数库<br>　　/lib64 　　 ##64位函数库（含有.bll）<br>　　/mnt 　　 ##临时挂载点<br>　　/run　　 ##自动临时设备挂载点（u盘）<br>　　/opt　　 ##第三方软件安装的位置<br>　　/sbin 　　 ##系统管理命令，通常只有root可以执行<br>　　/proc 　　 ##系统硬件信息和系统进程信息~~~~<br>　　/srv 　　 ##系统数据目录<br>　　/var 　　 ##系统数据目录<br>　　/sys　　 ##内核相关数据<br>　　/usr 　　　 ##用户相关信息数据<br>　　/tmp 　　 ##临时文件产生目录<br>　　/root　　 ##超级用户家目录</p>
<p>　　<strong><em>使用mount命令来更改临时设备的挂载点</em></strong></p>
<p><strong>二、文件管理命令</strong></p>
<p>　　1、文件的建立</p>
<p>　　命令：touch　filename　　## 通常用来创建文件，也可以修改文件的时间戳</p>
<p>　　注释：时间戳分为atime、mtime、ctime</p>
<p>　　　　atime　：文件内容被访问的时间标识</p>
<p>　　　　mtime　：文件内容被修改的时间标识</p>
<p>　　　　ctime　 ：文件属性或文件内容被修改的时间标识</p>
<p>　　实例：使用<strong><em> touch file </em></strong> 建立一个名为file的文件，并使用stat命令进行查看</p>
<p>　　<img alt data-src="https://images2018.cnblogs.com/blog/1438668/201807/1438668-20180716191242211-1069722524.png"></p>
<ul>
<li>　若进行文件的查看后，则访问时间将会被改变，结果如下：</li>
</ul>
<p>　　<img alt data-src="https://images2018.cnblogs.com/blog/1438668/201807/1438668-20180716191629214-2046658304.png"></p>
<ul>
<li>　若文件进行编辑后，则访问时间、修改时间和文件改变时间三者均会变化，结果如下：</li>
</ul>
<p>　　<img alt data-src="https://images2018.cnblogs.com/blog/1438668/201807/1438668-20180716192012796-193555712.png"></p>
<p>　　注意：使用<strong><em> touch —help </em></strong>进行其他参数的查看</p>
<p>　　2、目录的建立</p>
<p>　　命令：mkdir　directory　　　　　　　　## 用来建立名为directory的目录</p>
<p>　　　　 mkdir　-p　test/redcat/linux　　 ## -p 进行多级目录的创建</p>
<p>　　注释：也可使用 mkdir —help命令进行参数的查看</p>
<p>　　实例：使用<strong><em> mkdir niu </em></strong>创建一个目录名为niu，结果如下：</p>
<p>　　<img alt data-src="https://images2018.cnblogs.com/blog/1438668/201807/1438668-20180716192938835-574407116.png"></p>
<ul>
<li>　多级目录创建结果如下：</li>
</ul>
<p>　　<img alt data-src="https://images2018.cnblogs.com/blog/1438668/201807/1438668-20180716193136101-657056986.png"></p>
<p>　　3、文件的删除</p>
<p>　　命令：rm 　file　　　　 ## 进行文件的删除</p>
<p>　　　　 rm 　-f 　test　　## -f 为强行删除文件</p>
<p>　　实例：使用<strong><em> ls file </em></strong>命令删除文件file，结果如下：</p>
<p>　　<img alt data-src="https://images2018.cnblogs.com/blog/1438668/201807/1438668-20180716193719450-1436996021.png"></p>
<p>　　4、目录的删除</p>
<p>　　命令：rm 　-r 　directory　　## -r表示递归删除所有内容</p>
<p>　　　　 rm　 -r　-f 　dir　　　## 删除目录不再提示</p>
<p>　　　　 rm 　-rf　　dir　　　 ## j结果与上一个相同，且有 -a -b -c= - abc = - cba　</p>
<p>　　实例：使用<strong><em> rm -rf test</em></strong> 删除test目录以及test目录下的所有内容，结果如下：</p>
<p>　　<img alt data-src="https://images2018.cnblogs.com/blog/1438668/201807/1438668-20180716194551519-1288801399.png"></p>
<p>　　5、文件编辑</p>
<ul>
<li>　gedit 编辑器</li>
</ul>
<p>　　　　　命令：gedit　　file　　## 必须有图形界面，进行file文件的编辑</p>
<ul>
<li>　vim 编辑器</li>
</ul>
<p>　　　　　命令：vim　file ———&gt; 按 i 进入insert 模式 ———&gt; 书写内容 ———&gt; esc退出insert模式 - ——-&gt; wq退出并保存</p>
<p>　　 实例：gedit使用（使用以下命令即可打开file文件，并进行编辑）</p>
<p>　　<img alt data-src="https://images2018.cnblogs.com/blog/1438668/201807/1438668-20180716195422572-1655897153.png"></p>
<ul>
<li>　使用vim.tiny实例应用如下：（vim 和vim.tiny功能类似）</li>
</ul>
<p>　　<img alt data-src="https://images2018.cnblogs.com/blog/1438668/201807/1438668-20180716195752419-614443396.png"></p>
<p>　　###### 使用vim 会出现异常情况 ######</p>
<p>　　当vim异常退出时，会生成.file.swp文件（原因是修改文件未保存）</p>
<p>　　当helloc未保存后再次打开时，会出现以下情况：（下面文字接着图的more）<br>　 <img alt data-src="https://images2018.cnblogs.com/blog/1438668/201807/1438668-20180716200340278-2049532639.png"></p>
<p>　　Swap file “.hello.swp” already exists!</p>
<p>　　[O]pen Read-Only, (E)dit anyway, (R)ecover, (D)elete it,　　 (Q)uit, (A)bort:<br>　　　　只读打开 　　　 继续编辑 　 恢复数据 　 删除swap文件 退出<br>　　分析：无论按【o】【e】【r】【q】【a】任何一个都不会删除.swp文件，再次打开还会</p>
<p>　　　　　有这样的这个问题，直到按【D】后，.swp被删除，vim恢复正常。  </p>
<p>　　6、文件的复制（复制目录的时候用- r）</p>
<p>　　命令：cp 　sourcefile　objectfile　　　　　　　　　## 表示把远文件复制到目标文件　</p>
<p>　　　　　cp 　-r　源目录　目的地目录　　</p>
<p>　　　　　cp 　源文件1　源文件2　目的地目录　　 　　## 目的地目录必须存在</p>
<p>　　　　　cp 　-r 　源目录1　源目录2　目的地目录　　 ## 目的地目录必须存在</p>
<p>　　实例：把file文件中的内容复制到file1中，结果如下：</p>
<p>　　<img alt data-src="https://images2018.cnblogs.com/blog/1438668/201807/1438668-20180716202413095-1447577145.png"></p>
<ul>
<li>　使用 <strong><em> cp -r test　test1 </em></strong>命令把test目录下内容复制到test1目录中，结果如下：</li>
</ul>
<p>　　<img alt data-src="https://images2018.cnblogs.com/blog/1438668/201807/1438668-20180716203157814-1198844011.png"></p>
<ul>
<li>　使用 <strong><em> cp file1 file2 dir </em></strong>命令，把file1和file2文件复制到目录dir下，结果如下：</li>
</ul>
<p>　　<img alt data-src="https://images2018.cnblogs.com/blog/1438668/201807/1438668-20180716203804044-2015492922.png"></p>
<ul>
<li>　使用<strong><em> cp -r dir dir1 dir2 </em></strong>把目录dir1和dir2复制到目录dir3下，结果如下：</li>
</ul>
<p>　　<img alt data-src="https://images2018.cnblogs.com/blog/1438668/201807/1438668-20180716204213938-2053126740.png"></p>
<p>　　7、文件的移动</p>
<p>　　命令：mv 　源文件　　目的地文件　　　　## 重命名</p>
<p>　　　　　mv　 源目录　　目的地目录</p>
<p>　　实例：使用<strong><em> mv file file1</em></strong>命令，把file重命名为file1，结果如下：</p>
<p>　　<img alt data-src="https://images2018.cnblogs.com/blog/1438668/201807/1438668-20180716204620780-1893321132.png"></p>
<p>　　使用<strong><em> mv niu/file test/ </em></strong>把niu目录下的file文件移动到test目录中，结果如下：</p>
<p>　　<img alt data-src="https://images2018.cnblogs.com/blog/1438668/201807/1438668-20180716204956300-1776343291.png"></p>
<p>　　（.代表当前目录）例：把test目录下的file1复制到当前目录下，命令如下：</p>
<p>　　<img alt data-src="https://images2018.cnblogs.com/blog/1438668/201807/1438668-20180716205318027-1553458611.png"></p>
<p>　　注意：相同磁盘的文件移动是重命名的过程，不用磁盘的移动是复制删除的过程。</p>
<p>　　8、文件的查看</p>
<p>　　命令：cat　filename　　　　## 表示查看文件的全部内容</p>
<p>　　　　　cat 　-b 　filename　 ## 查看内容并显示行号</p>
<p>　　　　　less　filename　　　 ## 分页浏览(以下命令在less命令之后的操作)</p>
<p>　　　　　上|下　　　　　　　　## 逐行移动</p>
<p>　　　　　pageu|pagedn　　　 ## 逐页移动</p>
<p>　　　　　/关键字　　　　　　　## 高亮显示关键字，n向下匹配，N向上匹配</p>
<p>　　　　　v　　　　　　　　　　## 进入vim模式，然后按i进行编辑，返回vim模式按esc</p>
<p>　　　　　q　　　　　　　　　　##退出vim模式</p>
<p>　　实例：使用<strong><em> cat file1</em></strong>命令查看file1中的内容，结果入下：</p>
<p>　　<img alt data-src="https://images2018.cnblogs.com/blog/1438668/201807/1438668-20180716212743634-353476679.png"></p>
<ul>
<li>　查看内容并显示行号，结果如下：</li>
</ul>
<p>　　<img alt data-src="https://images2018.cnblogs.com/blog/1438668/201807/1438668-20180716212922248-1273385407.png"></p>
<ul>
<li>　less 命令既修改文件中的内容，也可以使用快捷键进行查找，在此就不放截图了。</li>
</ul>
<p>　　9、文件的寻址</p>
<p>　　相对路径：</p>
<p>　　　　　　相对与当前系统所在的目录的一个文件名称的简写；</p>
<p>　　　　　　此名称省略了系统当前所在目录的名称；</p>
<p>　　　　　　此名称不以“/”开头；</p>
<p>　　　　　　此名称在命令执行时会自动在操作对象前加入”pwd”所显示的值。</p>
<p>　　绝对路径：</p>
<p>　　　　　　绝对路径是文件在系统中的真实位置；</p>
<p>　　　　　　此命令以“/”开头；</p>
<p>　　　　　　此命令在执行时不会考虑现在的位置的信息。</p>
<p>　　注意：当操作对象是　　对象1　空格　对象2 时，这两个对象没有任何关系</p>
<p>　　　　　亲　　　　## 动作时被系统执行，不能作为名称出现</p>
<p>　　　　　“亲”　　　 ## 引号的作用是把动作变成名称字符，这种方法叫引用</p>
<p>　　　　　pwd　　　## 显示当前工作目录</p>
<p>　　10、自动补齐</p>
<p>　　《tab》</p>
<p>　　　　　系统中的《tab》键可以实现命令的自动补齐；</p>
<p>　　　　　可以补齐系统中存在的命令，文件名称，和部分命令的参数；</p>
<p>　　　　　当一次《tab》补齐不了时，代表以此关键字开头的内容不唯一；</p>
<p>　　　　　可以使用《tab》两次来列出所有一次关键字开头的内容散</p>
<h1 id="脚本交互-except工具"><a href="#脚本交互-except工具" class="headerlink" title="脚本交互-except工具"></a>脚本交互-except工具</h1><p>主要用户自动操作，比如说：自动输入密码(最常见)<br>在使用expect时，基本上都是和以下四个命令打交道：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">send	用于向进程发送字符串</span><br><span class="line">expect	从进程接收字符串</span><br><span class="line">spawn	启动新的进程</span><br><span class="line">interact	允许用户交互</span><br></pre></td></tr></table></figure>
<p>send命令接收一个字符串参数，并将该参数发送到进程。</p>
<p>expect命令和send命令相反，expect通常用来等待一个进程的反馈，我们根据进程的反馈，再发送对应的交互命令。</p>
<p>spawn命令用来启动新的进程，spawn后的send和expect命令都是和使用spawn打开的进程进行交互。</p>
<p>interact命令用的其实不是很多，一般情况下使用spawn、send和expect命令就可以很好的完成我们的任务；但在一些特殊场合下还是需要使用interact命令的，interact命令主要用于退出自动化，进入人工交互。</p>
<ul>
<li>例子：链接shh</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!/usr/tcl/bin/expect</span><br><span class="line"></span><br><span class="line">set timeout 30</span><br><span class="line">set host &quot;101.200.241.109&quot;</span><br><span class="line">set username &quot;root&quot;</span><br><span class="line">set password &quot;123456&quot;</span><br><span class="line"></span><br><span class="line">spawn ssh $username@$host</span><br><span class="line">expect &quot;*password*&quot; &#123;send &quot;$password\r&quot;&#125;</span><br><span class="line">interact</span><br></pre></td></tr></table></figure>
<ul>
<li>例子：自动切换到sudo 并启动hexo<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!/usr/bin/expect</span><br><span class="line">set timeout 30</span><br><span class="line">spawn sudo -s</span><br><span class="line">expect &quot;Password:&quot;</span><br><span class="line">send &quot;123456\r&quot;</span><br><span class="line">expect &quot;*#&quot;</span><br><span class="line">send &quot;cd hexoblog\r&quot;</span><br><span class="line">expect &quot;*#&quot;</span><br><span class="line">send &quot;hexo s\r&quot;</span><br><span class="line">interact</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>参考：<a href="https://blog.csdn.net/weixin_42442713/article/details/81001753" target="_blank" rel="noopener">https://blog.csdn.net/weixin_42442713/article/details/81001753</a><br><a href="https://www.cnblogs.com/uthnb/p/9320582.html" target="_blank" rel="noopener">https://www.cnblogs.com/uthnb/p/9320582.html</a></p>
]]></content>
      <categories>
        <category>工程</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title>5003总结3 Graphs</title>
    <url>/2020/5003%E6%80%BB%E7%BB%933-Graphs/</url>
    <content><![CDATA[<p>graphframes是处理图的一个API <a href="https://graphframes.github.io/graphframes/docs/_site/index.html" target="_blank" rel="noopener">graphframes官方文档</a><br>可以和RDD结合，和pyspark结合使用。<br>在Python环境使用需要以下步骤：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">**GraphFrames:**</span><br><span class="line">-   For pre-installed Spark version ubuntu, to use GraphFrames:</span><br><span class="line">    1.  get the jar file:  </span><br><span class="line">        wget http://dl.bintray.com/spark-packages/maven/graphframes/graphframes/0.7.0-spark2.4-s_2.11/graphframes-0.7.0-spark2.4-s_2.11.jar</span><br><span class="line">    2.  Load the jar file in the Jupyter notebook  </span><br><span class="line">        sc.addPyFile(&apos;path_to_the_jar_file&apos;)</span><br><span class="line">    You can also refer to &quot;~/Untitled.ipynb&quot;.</span><br><span class="line">-   Using the pyspark shell directly with GraphFrames:</span><br><span class="line">    -   ./bin/pyspark --packages graphframes:graphframes:0.7.0-spark2.4-s_2.11</span><br><span class="line">-   Using Jupyter locally:</span><br><span class="line">    1.  Set the environment variable:  </span><br><span class="line">        export SPARK_OPTS=&quot;--packages graphframes:graphframes:0.7.0-spark2.4-s_2.11&quot;</span><br><span class="line">    2.  get the jar file:  </span><br><span class="line">        wget http://dl.bintray.com/spark-packages/maven/graphframes/graphframes/0.7.0-spark2.4-s_2.11/graphframes-0.7.0-spark2.4-s_2.11.jar</span><br><span class="line">    3.  Load the jar file in the Jupyter notebook  </span><br><span class="line">        sc.addPyFile(&apos;path_to_the_jar_file&apos;)</span><br><span class="line">-   In Azure Databricks Service:</span><br><span class="line">    1.  Start the cluster</span><br><span class="line">    2.  Search for &quot;graphframes&apos; and install the library</span><br></pre></td></tr></table></figure></p><a id="more"></a>
<p>在jupyter里面使用需要引用压缩包，例如：<br><code>sc.addPyFile(&quot;/usr/local/Cellar/apache-spark/2.4.4/libexec/jars/graphframes-0.7.0-spark2.4-s_2.11.jar&quot;)</code></p>
<hr>
<h1 id="生成图"><a href="#生成图" class="headerlink" title="生成图"></a>生成图</h1><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">v = spark.createDataFrame([</span><br><span class="line">  (<span class="string">"a"</span>, <span class="string">"Alice"</span>, <span class="number">34</span>),</span><br><span class="line">  (<span class="string">"b"</span>, <span class="string">"Bob"</span>, <span class="number">36</span>),</span><br><span class="line">  (<span class="string">"c"</span>, <span class="string">"Charlie"</span>, <span class="number">37</span>),</span><br><span class="line">  (<span class="string">"d"</span>, <span class="string">"David"</span>, <span class="number">29</span>),</span><br><span class="line">  (<span class="string">"e"</span>, <span class="string">"Esther"</span>, <span class="number">32</span>),</span><br><span class="line">  (<span class="string">"f"</span>, <span class="string">"Fanny"</span>, <span class="number">38</span>),</span><br><span class="line">  (<span class="string">"g"</span>, <span class="string">"Gabby"</span>, <span class="number">60</span>)</span><br><span class="line">], [<span class="string">"id"</span>, <span class="string">"name"</span>, <span class="string">"age"</span>])</span><br><span class="line"><span class="comment"># Edges DataFrame</span></span><br><span class="line">e = spark.createDataFrame([</span><br><span class="line">  (<span class="string">"a"</span>, <span class="string">"b"</span>, <span class="string">"friend"</span>),</span><br><span class="line">  (<span class="string">"b"</span>, <span class="string">"c"</span>, <span class="string">"follow"</span>),</span><br><span class="line">  (<span class="string">"c"</span>, <span class="string">"b"</span>, <span class="string">"follow"</span>),</span><br><span class="line">  (<span class="string">"f"</span>, <span class="string">"c"</span>, <span class="string">"follow"</span>),</span><br><span class="line">  (<span class="string">"e"</span>, <span class="string">"f"</span>, <span class="string">"follow"</span>),</span><br><span class="line">  (<span class="string">"e"</span>, <span class="string">"d"</span>, <span class="string">"friend"</span>),</span><br><span class="line">  (<span class="string">"d"</span>, <span class="string">"a"</span>, <span class="string">"friend"</span>),</span><br><span class="line">  (<span class="string">"a"</span>, <span class="string">"e"</span>, <span class="string">"friend"</span>),</span><br><span class="line">  (<span class="string">"g"</span>, <span class="string">"e"</span>, <span class="string">"follow"</span>)</span><br><span class="line">], [<span class="string">"src"</span>, <span class="string">"dst"</span>, <span class="string">"relationship"</span>])</span><br><span class="line"><span class="comment"># Create a GraphFrame</span></span><br><span class="line">g = GraphFrame(v, e)</span><br><span class="line"></span><br><span class="line">g.vertices.show()</span><br><span class="line">g.edges.show()</span><br></pre></td></tr></table></figure>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191123161350.png"><br>建立两个dataframe：</p>
<ul>
<li>一个储存节点vertices的id+[data]</li>
<li>另一个储存关系edges的[“src”, “dst”, “relationship”]</li>
</ul>
<p>这个图就建立好了。</p>
<h1 id="图的基本属性"><a href="#图的基本属性" class="headerlink" title="图的基本属性"></a>图的基本属性</h1><p>g.vertices和g.edges是输入的两个v，e 可以使用dataframe的方法筛选过滤统计。</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191123140805.png"></p>
<p>g.outDegrees或者g.inDegrees可以返回一个dataframe-[id,degree]，自动计算每个节点的出度和入度。</p>
<ul>
<li>cache也可用到图上<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191123141021.png"><br>整个图cache 运用：<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191123144609.png"><h1 id="Motif-finding"><a href="#Motif-finding" class="headerlink" title="Motif finding"></a>Motif finding</h1></li>
</ul>
<p>Motif finding refers to searching for structural patterns in a graph.<br>例如：寻找互相关注，寻找三角形关注<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191123145700.png"><br>寻找单向关注，寻找无人关注<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191123145801.png"></p>
<p>另一种方法寻找无人关注的点：</p>
<ul>
<li><p>左连接or求差集（先求id的差集，再直接join整张表）<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191123150855.png"></p>
<blockquote>
<p>如果不是左连接，那一行会被删掉</p>
</blockquote>
</li>
<li><p>例子：<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191123151645.png"></p>
</li>
</ul>
<p>先找单向的四人关系，map 相互为friend=1，筛选有2个friend以上的关系链。</p>
<h1 id="Subgraphs-生成子图"><a href="#Subgraphs-生成子图" class="headerlink" title="Subgraphs 生成子图"></a>Subgraphs 生成子图</h1><ul>
<li>选择子节点和子边</li>
<li><p>生成新图<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191123152823.png"></p>
</li>
<li><p>过滤掉多余的部分<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191123153344.png"><br>这里的leftsemi的join方式：<a href="https://blog.csdn.net/zhaoxz128/article/details/80784188" target="_blank" rel="noopener">leftsemi讲解</a></p>
<blockquote>
<p>Hive 当前<strong>没有</strong>实现 IN/EXISTS 子查询，所以你可以用 <strong>LEFT SEMI JOIN 重写你的子查询语句</strong>。LEFT SEMI JOIN 的限制是， JOIN 子句中右边的表只能在  ON 子句中设置过滤条件，在 WHERE 子句、SELECT 子句或其他地方过滤都不行。</p>
<h1 id="例子：找到最少被两个人关注的人"><a href="#例子：找到最少被两个人关注的人" class="headerlink" title="例子：找到最少被两个人关注的人"></a>例子：找到最少被两个人关注的人</h1><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">g.find(<span class="string">"( )-[e]-&gt;(b)"</span>).filter(<span class="string">"e.relationship='follow'"</span>).</span><br><span class="line">groupby(<span class="string">'b'</span>).count().filter(<span class="string">"count&gt;=2"</span>).select(<span class="string">'b.name'</span>).show()</span><br></pre></td></tr></table></figure>
</blockquote>
</li>
</ul>
<h1 id="应用：BFS广度有限搜索"><a href="#应用：BFS广度有限搜索" class="headerlink" title="应用：BFS广度有限搜索"></a>应用：BFS广度有限搜索</h1><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191123161040.png"><br>API自带的接口：<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191123161117.png"></p>
<h1 id="例子-list-rank"><a href="#例子-list-rank" class="headerlink" title="例子 list rank"></a>例子 list rank</h1><p>对于一个链表排序（按照距离尾部节点的距离排序）：<br>暴力算法：遍历n次，每次找到尾部节点，记录并删除 O(n)<br>方法2：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Initialize u.d = 0 if u.next = null, else u.d = 1</span><br><span class="line">Run the following for each node u until all next pointers are null:</span><br><span class="line">	if u.next is not null: </span><br><span class="line">		u.d += u.next.d </span><br><span class="line">		u.next = u.next.next</span><br></pre></td></tr></table></figure><br>算法原理如图：<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191123170545.png"><br>复杂度O(logn)，每一轮遍历非尾节点都会参与，减少循环次数<br> 实现：<br> <img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191123170704.png"><br> <img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191123170718.png"></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文总结了pyspark的graph模块基本语法和操作，关于5003的三篇总结到此结束。</p>
]]></content>
      <categories>
        <category>MSBD5003</category>
      </categories>
      <tags>
        <tag>复习</tag>
        <tag>spark</tag>
        <tag>5003</tag>
        <tag>并行计算</tag>
      </tags>
  </entry>
  <entry>
    <title>5003总结2 stream&amp;并行计算-例子</title>
    <url>/2019/5003%E6%80%BB%E7%BB%932-stream-%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97-%E4%BE%8B%E5%AD%90-1/</url>
    <content><![CDATA[<p>Streaming是处理数据流的API。<br>下面直接通过例子，感受streaming的机制。</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191123213735.png"><br><a id="more"></a></p>
<h1 id="例1-从键盘输入文本，统计词频"><a href="#例1-从键盘输入文本，统计词频" class="headerlink" title="例1 从键盘输入文本，统计词频"></a>例1 从键盘输入文本，统计词频</h1><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191123220112.png"></p>
<h1 id="例2-1-从文件输入，统计词频"><a href="#例2-1-从文件输入，统计词频" class="headerlink" title="例2.1 从文件输入，统计词频"></a>例2.1 从文件输入，统计词频</h1><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191123222512.png"></p>
<h1 id="例2-2-对词的感情值排序"><a href="#例2-2-对词的感情值排序" class="headerlink" title="例2.2 对词的感情值排序"></a>例2.2 对词的感情值排序</h1><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191123230557.png"></p>
<h1 id="例2-3-stage，统计所有词频"><a href="#例2-3-stage，统计所有词频" class="headerlink" title="例2.3 stage，统计所有词频"></a>例2.3 stage，统计所有词频</h1><p>上面的例子2.1 仅仅是统计每一个输入部分的词频，意义不大<br>通过<code>updateStateByKey()</code>可以实现对所有数据的统计。</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191123231336.png"></p>
<p><code>updateStateByKey()</code>需要定义一个函数，函数的输入是上次的和这次的rdd，这里的streaming的精髓，需要好好理解。</p>
<hr>
<h1 id="算法应用1：蓄水池抽样Reservoir-Sampling"><a href="#算法应用1：蓄水池抽样Reservoir-Sampling" class="headerlink" title="算法应用1：蓄水池抽样Reservoir Sampling"></a>算法应用1：蓄水池抽样Reservoir Sampling</h1><h2 id="算法过程"><a href="#算法过程" class="headerlink" title="算法过程"></a>算法过程</h2><p>蓄水池采样算法（Reservoir Sampling）了。先说一下算法的过程：</p>
<ul>
<li>假设数据序列的规模为  𝑛，需要采样的数量的为  𝑘。</li>
<li>首先构建一个可容纳  𝑘  个元素的数组，将序列的前  𝑘  个元素放入数组中。</li>
<li>然后从第  𝑘+1  个元素开始，以  𝑘/𝑛  的概率来决定该元素是否被替换到数组中（数组中的元素被替换的概率是相同的）。 当遍历完所有元素之后，数组中剩下的元素即为所需采取的样本。<blockquote>
<p>这样就可以对任意长度的数据抽样，可以实现streaming. 不需要考虑文件长度。</p>
</blockquote>
</li>
</ul>
<p>简单证明：<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191124085220.png"></p>
<p>完整证明需要用到FIsher-Yates shuffle。</p>
<h1 id="算法应用2：O-n-时间，O-1-空间，寻找Majority的元素-n-gt-N-2"><a href="#算法应用2：O-n-时间，O-1-空间，寻找Majority的元素-n-gt-N-2" class="headerlink" title="算法应用2：O(n)时间，O(1)空间，寻找Majority的元素(n&gt;N/2)"></a>算法应用2：O(n)时间，O(1)空间，寻找Majority的元素(n&gt;N/2)</h1><p>算法描述：<br>只用空间复杂度O(1)，去寻找数组内有没有出现次数大于一半的元素。</p>
<p>算法过程：</p>
<blockquote>
<p>遍历所有元素：记录新出现元素的次数，如果下一个与记录相同，就＋1，不同就-1，遍历完成，会保留一个候选项<br>遍历所有元素：统计刚才候选项出现的次数n以及N，验证n&gt;N/2则验证成功，如果n&lt;=N/2，则无Majority</p>
</blockquote>
<h1 id="算法应用3：GM算法-Heavy-hitters"><a href="#算法应用3：GM算法-Heavy-hitters" class="headerlink" title="算法应用3：GM算法 Heavy hitters"></a>算法应用3：GM算法 Heavy hitters</h1><p>Misra-Gries (MG) algorithm finds up to k items that occur more than 1/k fraction of the time in a stream.<br>找到频率超过1/k的元素.<br>算法：</p>
<blockquote>
<p>初始化k个候选项，对之后的每个元素：</p>
<ul>
<li>如果元素已经被记录了，count++</li>
<li>如果没有记录，如果候选项&lt;k，那就记录他</li>
<li>如果没有记录，如果候选项=k，那就对每个候选项count—</li>
</ul>
<p>遍历完成，返回候选项</p>
</blockquote>
<h1 id="算法应用4：并行计算TOPn-时间复杂度满足O-n-p-log-k"><a href="#算法应用4：并行计算TOPn-时间复杂度满足O-n-p-log-k" class="headerlink" title="算法应用4：并行计算TOPn, 时间复杂度满足O(n/p*log k)"></a>算法应用4：并行计算TOPn, 时间复杂度满足O(n/p*log k)</h1><p>原题：</p>
<blockquote>
<p>Given an RDD storing a list of n integers (unordered), design a divide-and-conquer algorithm to find the k largest integers in the RDD. All workers must run in parallel. For full marks, each worker should run in time O(n/p * log k) time, where p is the number of workers.<br>Hint: Use a priority queue at each worker for maximum efficiency.</p>
</blockquote>
<p>当看到log K和priority queue就知道要使用堆排序了。<br>分成p个worker，每个worker有O(n/p)的值，每一个work维护一个最大K堆，时间复杂度是O(log k). </p>
<p>老师给的答案：</p>
<blockquote>
<p>Partition the integers evenly so that each worker receives O(n/p) values. On each worker, maintain a min-heap of size k. Inserting an element to the heap costs O(log k) time.<br>For each value, insert it to the heap if it is larger than the current min of the heap. Pop the minimum item if there are more than k items in the heap. By making one pass over all the values in each worker, we get the k largest integers out of the values of this worker. This can be done in O(n/p log k) time.<br>Then we merge the results by sending the top k of each partition to the same worker, which is at most kp values. The worker finds the largest k integers among these kp values and report it.</p>
</blockquote>
<p>代码<br><figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> heapq  <span class="comment"># 引入最大堆的包</span></span><br><span class="line">  </span><br><span class="line">rdd = sc.parallelize(xrange(<span class="number">0</span>,<span class="number">1000</span>,<span class="number">2</span>))   <span class="comment">#生成rdd</span></span><br><span class="line">k = <span class="number">10</span>  </span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">topk</span><span class="params">(it)</span>:</span>        <span class="comment">#对于每一个分区的n/p个值</span></span><br><span class="line">    h = []  </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> it:     <span class="comment">#遍历每一个值</span></span><br><span class="line">        <span class="comment"># check if we should insert i  </span></span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">not</span> h) <span class="keyword">or</span> (i &gt; h[<span class="number">0</span>]):   <span class="comment">#如果h为空或者新来的大于h里面最大的</span></span><br><span class="line">            heapq.heappush(h,i)     <span class="comment">#把这个元素插入到h</span></span><br><span class="line">            <span class="keyword">if</span> len(h) &gt; k:          <span class="comment">#长度大于k</span></span><br><span class="line">                heapq.heappop(h)    <span class="comment">#弹出h中最小的</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> xrange(len(h)):        <span class="comment">#遍历每一个值</span></span><br><span class="line">        <span class="keyword">yield</span> heapq.heappop(h)      <span class="comment">#从小到大依次弹出返回到上一层</span></span><br><span class="line">        </span><br><span class="line">print(list(topk(rdd.mapPartitions(topk).collect()))) <span class="comment">#对于分区使用，再整体使用</span></span><br></pre></td></tr></table></figure></p>
<hr>
<p>用实例总结了几个steaming和并行计算的基础知识点，路漫漫兮。</p>
]]></content>
      <categories>
        <category>MSBD5003</category>
      </categories>
      <tags>
        <tag>复习</tag>
        <tag>spark</tag>
        <tag>5003</tag>
        <tag>并行计算</tag>
      </tags>
  </entry>
  <entry>
    <title>5003总结1 RDD, Spark Internals</title>
    <url>/2019/5003%E6%80%BB%E7%BB%931-RDD-Spark-Internals/</url>
    <content><![CDATA[<h1 id="5003总结1-RDD-Spark-Internals"><a href="#5003总结1-RDD-Spark-Internals" class="headerlink" title="5003总结1 RDD, Spark Internals"></a>5003总结1 RDD, Spark Internals</h1><p>学习了5003之后，对于RDD和spark两章总结复习，梳理出有关函数的作用。</p><h2 id="RDD"><a href="#RDD" class="headerlink" title="RDD"></a>RDD</h2><p>resilient Distributed Datasets: 弹性分布式数据库，rdd是spark的基本运行单位<br>使用者作用于RDD，RDD自动进行分区，在不同partitions进行操作<br><img alt="RDD的操作" data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191030092656.png"></p><a id="more"></a>

<h2 id="rdd是“懒惰的”Lazy，如果只进行Transfomations-，RDD不会进行实际运算，会等待actions操作才会实际运算。（理解起来就是，如果每Transfomations一次就要运算，就需要操作一下等一次；而且Transfomations之间可能有优化的空间；所以如果没有Actions就意味着不需要输出，就先记住步骤不执行）"><a href="#rdd是“懒惰的”Lazy，如果只进行Transfomations-，RDD不会进行实际运算，会等待actions操作才会实际运算。（理解起来就是，如果每Transfomations一次就要运算，就需要操作一下等一次；而且Transfomations之间可能有优化的空间；所以如果没有Actions就意味着不需要输出，就先记住步骤不执行）" class="headerlink" title="* rdd是“懒惰的”Lazy，如果只进行Transfomations ，RDD不会进行实际运算，会等待actions操作才会实际运算。（理解起来就是，如果每Transfomations一次就要运算，就需要操作一下等一次；而且Transfomations之间可能有优化的空间；所以如果没有Actions就意味着不需要输出，就先记住步骤不执行）"></a>* rdd是“懒惰的”Lazy，如果只进行Transfomations ，RDD不会进行实际运算，会等待actions操作才会实际运算。（理解起来就是，如果每Transfomations一次就要运算，就需要操作一下等一次；而且Transfomations之间可能有优化的空间；所以如果没有Actions就意味着不需要输出，就先记住步骤不执行）</h2><p><a href="https://haofly.net/spark/" target="_blank" rel="noopener">引用博文 https://haofly.net/spark/</a></p>
<ul>
<li><strong>RDD(Resilient Distributed Dataset弹性分布式数据集)</strong>：这是spark的主要数据概念。有多种来源，容错机制，并且能缓存、并行计算。RDD在整个计算流程中会经过不同方式的变换，这种变换关系就是一个有向无环图。</li>
<li>需要注意的是，所有的方法在定义执行之前都是异步的，所以不能简单地在下面的方法外部添加<code>try...catch...</code>进行异常捕获，最好是在传入的函数里面进行异常的捕获(如果是lambda，请确认lambda不会报错，否则如果lambda报错整个程序都会报错并终止允许)</li>
<li>Spark应用程序可以使用大多数主流语言编写，这里使用的是python，只<code>pip install pyspark</code>即可</li>
<li><strong>Stage(调度阶段)</strong>: 每个Job会根据RDD大小切分城多个Stage，每个Stage包含一个TaskSet</li>
<li><strong>TaskSet(任务集)</strong>: 一组关联的Task集合，不过是没有依赖的</li>
<li><strong>Task(任务)</strong>: RDD中的一个分区对应一个Task。</li>
<li><strong>Narrow Dependency(窄依赖)</strong>: 比较简单的一对一依赖和多对一依赖(如union)</li>
<li><strong>Shuffle Dependency(宽依赖)</strong>: 父RDD的分区被多个子RDD分区所使用，这时父RDD的数据会被再次分割发送给子RDD</li>
<li><strong>Spark 内存分配</strong>: 分为这三块:<ul>
<li><strong>execution</strong>: 执行内存，基本的算子都是在这里面执行的，这块内存满了就写入磁盘。</li>
<li><strong>storage</strong>: 用于存储broadcast, cache, persist</li>
<li><strong>other</strong>: 程序预留给自己的内存，这个可以不用考虑</li>
</ul>
</li>
<li><strong>Duration</strong><ul>
<li><strong>batchDuration</strong>: 批次时间</li>
<li><strong>windowDuration</strong>: 窗口时间，要统计多长时间内的数据，必须是<code>batchDuration</code>的整数倍</li>
<li><strong>slideDuration</strong>: 滑动时间，窗口多长时间滑动一次，必须是<code>batchDuration</code>的整数倍，一般是跟<code>batchDuration</code>时间相同<h3 id="生成RDD"><a href="#生成RDD" class="headerlink" title="生成RDD"></a>生成RDD</h3>sc.parallelize(xrange(10))<br>sc.textFile(‘../data/fruits.txt’)</li>
</ul>
</li>
</ul>
<h3 id="基本运算"><a href="#基本运算" class="headerlink" title="基本运算"></a><a href="https://haofly.net/spark/#%E5%9F%BA%E6%9C%AC%E8%BF%90%E7%AE%97" target="_blank" rel="noopener" title="基本运算"></a>基本运算</h3><ul>
<li>下面是所有运算方法的集合，其中有些方法仅用于键值对，有些方法仅用于数据流</li>
</ul>
<h4 id="Transformation-转换"><a href="#Transformation-转换" class="headerlink" title="Transformation(转换)"></a><a href="https://haofly.net/spark/#Transformation-%E8%BD%AC%E6%8D%A2" target="_blank" rel="noopener" title="Transformation(转换)"></a>Transformation(转换)</h4><p>这类方法仅仅是定义逻辑，并不会立即执行，即lazy特性。目的是将一个RDD转为新的RDD。</p>
<ul>
<li>map(func): 返回一个新的RDD，func会作用于每个map的key，func的返回值即是新的数据。为了便于后面的计算，这一步一般在数据处理的最前面将数据转换为(K, V)的形式，例如计数的过程中首先要<code>datas.map(lambda a, (a, 1))</code>将数据转换成(a, 1)的形式以便后面累加</li>
<li><p>flatmap： 提取出每个list的所有元素，压成一层</p>
</li>
<li><p>mappartitions(func, partition): 和map不同的地方在于map的func应用于每个元素，而这里的<strong>func会应用于每个分区</strong>，能够有效减少调用开销，减少func初始化次数。减少了初始化的内存开销。但是map如果数据量过大，计算后面的时候可以将已经计算过的内存销毁掉，但是mappartitions中如果一个分区太大，一次计算的话可能直接导致内存溢出。</p>
</li>
<li>filter(func): 返回一个新的RDD，func会作用于每个map的key，返回的仅仅是返回True的数据组成的集合，返回None或者False或者不返回都表示被过滤掉</li>
<li>filtMap(func): 返回一个新的RDD，func可以一次返回多个元素，最后形成的是所有返回的元素组成的新的数据集</li>
<li>mapValues(func): 返回一个新的RDD，对RDD中的每一个value应用函数func。</li>
<li>distinct(): 去除重复的元素</li>
<li>subtractByKey(other): 删除在RDD1中的RDD2中key相同的值</li>
<li>groupByKey(numPartitions=None): 将(K, V)数据集上所有Key相同的数据聚合到一起，得到的结果是(K, (V1, V2…))</li>
<li>reduceByKey(func, numPartitions=None): 将(K, V)数据集上所有Key相同的数据聚合到一起，func的参数即是每两个K-V中的V。可以使用这个函数来进行计数，例如reduceByKey(lambda a,b:a+b)就是将key相同数据的Value进行相加。</li>
<li>reduceByKeyAndWindow(func, invFunc, windowdurartion, slideDuration=None, numPartitions=None, filterFunc=None): 与reduceByKey类似，不过它是在一个时间窗口上进行计算，由于时间窗口的移动，有增加也有减少，所以必须提供一个逻辑和func相反的函数invFunc，例如func为(lambda a, b: a+b)，那么invFunc一般为(lambda a, b: a-b)，其中a和b都是key相同的元素的value。另外需要注意的是，程序默认会缓存一个时间窗口内所有的数据以便后续能进行inv操作，所以如果窗口太长，内存占用可能会非常高</li>
<li>join(other, numPartitions=None): 将(K, V)和(K, W)类型的数据进行类似于SQL的JOIN操作，得到的结果是这样(K, (V, W))</li>
<li>union(other): 并集运算，简单合并两个RDD</li>
<li>intersection(other): 交集运算，保留在两个RDD中都有的元素</li>
<li>leftOuterJoin(other): 左外连接</li>
<li>rightOuterJoin(other): 右外连接</li>
</ul>
<h4 id="Action-执行"><a href="#Action-执行" class="headerlink" title="Action(执行)"></a><a href="https://haofly.net/spark/#Action-%E6%89%A7%E8%A1%8C" target="_blank" rel="noopener" title="Action(执行)"></a>Action(执行)</h4><p>不会产生新的RDD，而是直接运行，得到我们想要的结果。</p>
<ul>
<li>collect(): 以数组的形式，返回数据集中所有的元素</li>
<li>count(): 返回数据集中元素的个数</li>
<li>take(n): 返回数据集的前N个元素</li>
<li>takeOrdered(n): 升序排列，取出前N个元素</li>
<li>takeOrdered(n, lambda x: -x): 降序排列，取出前N个元素</li>
<li>first(): 返回数据集的第一个元素</li>
<li>min(): 取出最小值</li>
<li>max(): 取出最大值</li>
<li>stdev(): 计算标准差</li>
<li>sum(): 求和</li>
<li>mean(): 平均值</li>
<li>countByKey(): 统计各个key值对应的数据的条数</li>
<li>lookup(key): 根据传入的key值来查找对应的Value值</li>
<li>foreach(func): 对集合中每个元素应用func</li>
</ul>
<h4 id="Persistence-持久化"><a href="#Persistence-持久化" class="headerlink" title="Persistence(持久化)"></a><a href="https://haofly.net/spark/#Persistence-%E6%8C%81%E4%B9%85%E5%8C%96" target="_blank" rel="noopener" title="Persistence(持久化)"></a>Persistence(持久化)</h4><ul>
<li>cache()：保存，固定</li>
<li>persist(): 将数据按默认的方式进行持久化</li>
<li>unpersist(): 取消持久化</li>
<li>saveAsTextFile(path): 将数据集保存至文件</li>
</ul>
<hr>
<h2 id="RDD的操作-pyspark"><a href="#RDD的操作-pyspark" class="headerlink" title="RDD的操作 pyspark"></a>RDD的操作 pyspark</h2><figure class="highlight py"><table><tr><td class="code"><pre><span class="line">fruits = sc.textFile(<span class="string">'../data/fruits.txt'</span>) </span><br><span class="line">fruits.collect()</span><br><span class="line"><span class="comment">#读文本，全部显示</span></span><br></pre></td></tr></table></figure>
<p>累加器的使用：<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191030104539.png"></p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">rdd = sc.parallelize(xrange(<span class="number">10</span>))</span><br><span class="line">accum = sc.accumulator(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">g</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> accum</span><br><span class="line">    accum += x</span><br><span class="line">    <span class="keyword">return</span> x * x</span><br><span class="line"></span><br><span class="line">a = rdd.map(g)</span><br><span class="line"><span class="keyword">print</span> <span class="string">"---------"</span></span><br><span class="line"><span class="keyword">print</span> accum.value</span><br><span class="line"><span class="keyword">print</span> rdd.reduce(<span class="keyword">lambda</span> x, y: x+y)</span><br><span class="line"><span class="keyword">print</span> <span class="string">"---------"</span></span><br><span class="line"><span class="comment">#a.cache()</span></span><br><span class="line">tmp = a.count()</span><br><span class="line"><span class="keyword">print</span> accum.value</span><br><span class="line"><span class="keyword">print</span> rdd.reduce(<span class="keyword">lambda</span> x, y: x+y)</span><br><span class="line"><span class="keyword">print</span> <span class="string">"---------"</span></span><br><span class="line">tmp = a.count()</span><br><span class="line"><span class="keyword">print</span> accum.value</span><br><span class="line"><span class="keyword">print</span> rdd.reduce(<span class="keyword">lambda</span> x, y: x+y)</span><br><span class="line"><span class="comment">#reduce 始终不变，但是如果没有cache accumulator就会反复累加</span></span><br></pre></td></tr></table></figure>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">---------</span><br><span class="line"><span class="number">0</span></span><br><span class="line"><span class="number">45</span></span><br><span class="line">---------</span><br><span class="line"><span class="number">45</span></span><br><span class="line"><span class="number">45</span></span><br><span class="line">---------</span><br><span class="line"><span class="number">90</span></span><br><span class="line"><span class="number">45</span></span><br></pre></td></tr></table></figure>
<p>展示分区glom（）<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191030105120.png"><br>mapParttitions 在分区内部执行函数f<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191030110438.png"></p>
<p>这里的index就是为了改变每次生成的随机数不一样，否则每个分区算出来是一样的<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191030110351.png"></p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191030111556.png"><br>对key相同的值进行操作</p>
<h4 id="kmeans"><a href="#kmeans" class="headerlink" title="kmeans"></a>kmeans</h4><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191030113309.png"></p>
<h4 id="pagerank"><a href="#pagerank" class="headerlink" title="pagerank"></a>pagerank</h4><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191031205443.png"></p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191030113538.png"></p>
<h1 id="Internal-of-Spark"><a href="#Internal-of-Spark" class="headerlink" title="Internal of Spark"></a>Internal of Spark</h1><h2 id="web端监控Spark运行情况"><a href="#web端监控Spark运行情况" class="headerlink" title="web端监控Spark运行情况"></a>web端监控Spark运行情况</h2><p>查看Spark 可视化进程： localhost:4040 4041 4042 …</p>
<h2 id="partitions-分区"><a href="#partitions-分区" class="headerlink" title="partitions 分区"></a>partitions 分区</h2><p>RDD是储存在不同的partition里的，生成时每个partition平衡的（数量差不多），用于并行计算，但是有可能操作之后，就不平衡了。</p>
<p>这时候，需要 .repartition(n)</p>
<h1 id="Hash-vs-Range-partitioning"><a href="#Hash-vs-Range-partitioning" class="headerlink" title="Hash  vs Range partitioning"></a>Hash  vs Range partitioning</h1><ul>
<li>Hash partitioning<br>通过%N，这样的将相同<strong>余数</strong>放到一个分区。<br>缺点：可能由于原数据余数不平衡，可能分区不平衡</li>
<li>Range partitioning<br>计算每个分区大小，将连续的数放到一个分区<br>缺点：数值大小不平衡</li>
</ul>
<p>例子如下：<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191031200235.png"></p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191031201853.png"><br>RDD本来没有partitions，当有了shuffle 或者主动生成一个partitions才会有。<br>(这样的好处是，shuffle本身是需要多个partitions一起参与的，如果是线性图（key没有变化），那就只需要在自己的分区内计算，实现并行)</p>
<p>会继承partitions的3个Operations(key不会改变):</p>
<ul>
<li>mapValues  （但是map就不行）<ul>
<li>flatMapValues </li>
<li>filter  </li>
</ul>
</li>
</ul>
<p>其他的Operations都会改变key？ （这里需要考察一下）<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191031202823.png"></p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191031211821.png"></p>
<p>Spark 的 各级目录</p>
<blockquote>
<p>application 一个内核&gt;job一次运行 &gt;stage指令下的一个状态&gt;task一个状态的任务</p>
</blockquote>
<p>Spark的内存管理</p>
<ul>
<li>Two types of memory usages for applications:<br>– Execution memory: for computation in shuffles, joins, sorts and aggregations<br>– Storage memory: for caching and propagating internal data across the cluster</li>
</ul>
]]></content>
      <categories>
        <category>MSBD5003</category>
      </categories>
      <tags>
        <tag>复习</tag>
        <tag>spark</tag>
        <tag>5003</tag>
      </tags>
  </entry>
  <entry>
    <title>准备Q音推荐实习面试的笔记</title>
    <url>/2019/%E5%87%86%E5%A4%87Q%E9%9F%B3%E6%8E%A8%E8%8D%90%E7%9A%84%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>11月30更新，面试通过。后续更新实习心得。</p><hr><p>学姐有发消息招腾讯音乐的日常实习，我当天投递简历，当晚组长联系第二天面试。<br>推荐部门，我约的第二天下午三点面试，感觉下午会清醒一点。<br>现在记录一下准备过程。<br>本文没有逻辑，看到哪记到哪。</p><a id="more"></a>


<hr>
<h1 id="qq音乐推荐现状"><a href="#qq音乐推荐现状" class="headerlink" title="qq音乐推荐现状"></a>qq音乐推荐现状</h1><p>用户登录之后，默认进入喜好选择页面。<br>Page1：选择喜好的音乐流派，可多选，候选项为常见的流派<br>Page2：选择喜好的歌手，候选项为基于流派里的出名歌星<br>然后在推荐页，有电台，当天推荐30首，每周新歌推荐；<br>下面可以一直往下拉，有专辑和短视频推荐，短视频自动播放</p>
<p>喜好选择可以解决能启动。<br>解决冷启动还能通过：</p>
<blockquote>
<p>导入用户在社交网络上的好友信息和公开发布的信息<br>基本信息：（性别、职业、年龄段、地理位置（方言，城市等级，天气）、手机型号，传感器：行为判断运动？散步？休息）<br>关系链：相似好友推荐<br>朋友圈、QQ空间获取初步的用户画像：</p>
<ul>
<li>自己：个性签名，朋友圈动态-nlp，cv情感分析</li>
<li>交互：好友分享，点赞，评论</li>
</ul>
</blockquote>
<hr>
<h1 id="相似度矩阵思考问题"><a href="#相似度矩阵思考问题" class="headerlink" title="相似度矩阵思考问题"></a>相似度矩阵思考问题</h1><p>链接：<a href="https://link.jianshu.com/?t=https://www.zhihu.com/question/26743347/answer/34542247" target="_blank" rel="noopener">知乎沙克</a>  </p>
<p>完整的推荐系统体系包括 官方团队推荐（Editorial）、UGC（User-Generated Content）和热门推荐（Top Seller/Trending）的协作。</p>
<ul>
<li><strong>相似度矩阵（Similarity Matrix）：</strong><br>大家提的各种算法里面，几乎都是基于相似度的吧 — 无论是CF还是Content based产生的相似度，前者需要用户的行为数据，后者需要歌曲的元数据（metadata），比如旋律、Tag等等。<br>需要避免过多推荐单一歌手，避免过多热门。<br>找到冷门优秀的歌曲。<br>类似与tf-idf，在歌曲对个人的重要性在总榜里的热度乘反比，在个人的喜好程度乘正比。</li>
</ul>
<hr>
<h1 id="userCF算法和itemCF算法的层面"><a href="#userCF算法和itemCF算法的层面" class="headerlink" title="userCF算法和itemCF算法的层面"></a>userCF算法和itemCF算法的层面</h1><blockquote>
<p>链接：<a href="https://link.jianshu.com?t=https://www.zhihu.com/question/26743347/answer/65777210" target="_blank" rel="noopener">作者：郑昊</a><br>来源：知乎著作权归作者所有，转载请联系作者获得授权。<br>在本文中我们将提到两种方法来实现这个目的，基于用户的协作型过滤和基于物品的协作型过滤。</p>
</blockquote>
<h2 id="基于用户的协作型过滤"><a href="#基于用户的协作型过滤" class="headerlink" title="基于用户的协作型过滤"></a>基于用户的协作型过滤</h2><p> 音乐用户甲-&gt;偏好相近用户-&gt;相关歌曲-&gt;推荐列表</p>
<p>流程至少包括以下四个步骤：<br>建立评价规则<br>搜集用户偏好<br>寻找相近的用户<br>推荐歌曲</p>
<blockquote>
<p><strong>1.建立评价规则</strong><br>下图是我随意做的一个评价规则。评价规则应该根据明确的用户行为来建立。</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191119203521.png"></p>
<p>评价规则-随意做的</p>
<p><strong>2.搜集用户偏好</strong><br>根据评价规则，我们可以得到每个用户和该用户相关的每首歌的一个得分。 下图也是我随意造的数据。</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191119203536.png"></p>
<p>用户偏好</p>
<p><strong>3.寻找相近的用户</strong><br>常用的计算相似度评价值的体系有两种：欧几里得距离和皮尔逊相关度。</p>
<p><strong>4.推荐歌曲</strong><br>接下来系统要做的就是，为用户郑昊提供歌曲推荐。我们当然可以查找与郑昊品味最相近的人，从他所喜欢的歌曲中找出一首郑昊可能还未接触过的歌曲。不过，这样的做法未免太随意了。<br>目前最通用的做法是，通过一个经过加权的评价值来为歌曲打分，评分结果即排名结果。为此，我们需要取得所有其他用户的分数，借此得到相关系数后，再乘以他们与相关歌曲的分数，求和之后再除以对应的相关系数总计，便能获得一个我们需要的评价值。在下表中我们给出了具体的做法。</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191119203705.png"></p>
<p>「相关系数」一列来自于皮尔逊相关度评价。「歌名」对应各用户的得分来自评价规则处理后的结果。将前两者一一对应相乘，便是「歌N*相关系数」的值。如此一来，相比于与我们不相近的人，那些与我们相近的人将会对整体评价值拥有更多的贡献。总计一行给出了所有加权评价值的总和。</p>
<p>我们可以用总计值来计算歌曲排名，但是我们还需要考虑到，这样人数会对一首歌的得分产生正相关影响。为了避免这一问题，我们需要将总计除以相关系数总计。相关系数总计等于所有对这首歌曲有影响的用户的相关系数之和。表中最后一行就是我们所需要的结果。</p>
</blockquote>
<h2 id="基于物品的协作型过滤"><a href="#基于物品的协作型过滤" class="headerlink" title="基于物品的协作型过滤"></a>基于物品的协作型过滤</h2><p>1.歌曲A-&gt;相关用户-&gt;相关歌曲-&gt;推荐列表；<br>2.网易云音乐用户甲-&gt;偏好歌曲-&gt;推荐列表。</p>
<p>1是主要计算过程，2是推荐过程。</p>
<hr>
<h1 id="从产品角度思考数据"><a href="#从产品角度思考数据" class="headerlink" title="从产品角度思考数据"></a>从产品角度思考数据</h1><p><a href="http://www.chanpin100.com/article/100147" target="_blank" rel="noopener">链接</a><br>行业分析、市场分析、用户群的划分和分析之外，还考虑未来的发展方向</p>
<hr>
<h1 id="实习经历描述"><a href="#实习经历描述" class="headerlink" title="实习经历描述"></a>实习经历描述</h1><p>腾讯 微信事业群 数据分析实习生 用户拉起方向 2019.04-2019.08 l 运用聚类算法对用户来源、拉起特征、活跃企业等属性完成了用户聚类，梳理出用户画像，找到用户拉起的增长点;通过通过漏斗分析，寻找出注册页瓶颈，找到改进措施。</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191119221035.png"></p>
<p>产品岗，做的杂：捞数据，做报表，策划，数据分析。<br>分析：互通现状。<br>任务：分析现状，梳理出下一步的方向。<br>What：现状是什么？用户增长放缓，发消息加深。<br>思路：用户群的划分→得到比例和画像→比例与市场比较，寻找空间；画像对比我们的目标企业查看问题</p>
<ul>
<li><p>用户群怎么划分？<br>1 活跃 62%<br>2 基于产品性质，协同12%，服务50%<br>3 服务类的 基于使用情况，公司规模 大企业10% 小企业40%</p>
</li>
<li><p>画像，使用情况：<br>分词去寻找岗位，树状结构去找级别，流失时间点，是否体验了</p>
</li>
</ul>
<p>解决：<br>when：使用互通次日<br>who：IT，零售，物流<br>why：需要客户联系，管理消费者资源<br>how：<br>1 大企业，推联系方式给BD联系主动沟通，拉起使用<br>2 中小企业，非管理员体验，push引导管理员开通客户联系；  管理员体验，企业号推送行业案例，激发兴趣<br>3 未进入的企业，寻找“优质用户”包，在朋友圈广告定向推送互通行业案例<br>4 增加通道：微信个人资料增加企业微信icon，增加曝光</p>
<hr>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>实习</tag>
        <tag>推荐算法</tag>
      </tags>
  </entry>
  <entry>
    <title>What is GAN basicly?</title>
    <url>/2019/What-is-GAN-basicly/</url>
    <content><![CDATA[<p><strong>MSBD5012 Term Paper</strong></p><p>Due Date: 7 December 2019</p><p>Via Canvas</p><p>As announced by the university administration, there won’t be any proctored examinations this semester and alternative assessment arrangements are to be made by the course instructors. For CSIT6000G/MSBD5012, you are asked to write a term paper in lieu of the final exam.</p><a id="more"></a>



<p>You need to choose one topic from the following list, and explain it informally:</p>
<p>· Adversarial attack</p>
<p>· Variational autoencoders</p>
<p>· Generative adversarial networks</p>
<p>· Deep reinforcement learning</p>
<p>The targeted readers of the paper are computer science students who are about to take the course. In other words,  <strong>you are asked to explain the chosen topic to the past you</strong> at 1 September 2019.  Obviously, there isn’t enough space for you to include all the details. However, you need to cover the<br>key concepts and key ideas.<br> You can follow the outlines of the relevant lectures, and might need to include contents before those lectures as background.</p>
<p>You can include diagrams and mathematical formulae. However, avoid mathematical formulae as much as possible because  <strong>the purpose is to give informal explanations, not formal proofs.</strong></p>
<p>The term paper should be no more than 4 pages in length, and the font size of the main text should be 12pt. You are encouraged to use latex  <a href="https://github.com/ICLR/Master-Template/blob/master/archive/iclr2020.zip" target="_blank" rel="noopener">latex template</a> of <a href="https://iclr.cc/Conferences/2020/CallForPapers" target="_blank" rel="noopener">ICLR 2020</a>. Generate a pdf file for submission via Canvas and name your file  “ [Last Name]_ [First Name]_[Student ID].pdf”. Discussions among students are encouraged. However, you need to write up your paper independently.  A plagiarism checker will be run on all submitted reports.</p>
<p>The term paper will be graded using the following scheme:</p>
<p>· Overall understanding of the topic:  50%</p>
<p>· Clarity of explanations:  30%</p>
<p>· Effort (how polished the report is):  20%</p>
<p>The term paper is  <strong>due by 23:59 on 7 December</strong>, the scheduled final exam date.  <strong>No late submissions will be accepted</strong>.</p>
<hr>
<h1 id="Generative-Adversarial-Networks-is-so-Easy"><a href="#Generative-Adversarial-Networks-is-so-Easy" class="headerlink" title="Generative Adversarial Networks is so Easy"></a>Generative Adversarial Networks is so Easy</h1><p>In machine learning course, we learn how to teach our program to learn the information among the data. There are a lot’s kinds of work can be down, just like classification, regression and generate new data as same as nature. Generating new data is pretty interesting job. Thinking about what if you can teach your program to learn the plot by Picasso’s. The plots by Picasso’s  is very famous and expensive. The most painting by Picasso is _Les femmes d’Alger_  which worth  $179 million.  If we can teach our program to plot a image similar with his style easily. That’s will be a amazing job. But now we can made it by the algorithm GANs.</p>
<h2 id="Basic-idea"><a href="#Basic-idea" class="headerlink" title="Basic idea"></a>Basic idea</h2><p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191130001221.png"></p>
<p>GANs are the algorithms represented for Generative Adversarial Networks.  It is the process of two complex algorithms (neural networks) competing against each other. One algorithms is called <strong>Generator,</strong> the other algorithm is called <strong>Discriminator</strong>.</p>
<p>The generative model and the discriminant model play a game with each other and learn to produce quite good output. Taking pictures as an example, the main task of the generator is to learn the real picture set, so that the pictures generated by yourself are closer to the real pictures, and the “disguise” discriminator. The main task of the discriminator is to find out the picture generated by the generator, distinguish it from the real picture, and perform true and false discrimination. Throughout the iteration process, the generator continuously strives to make the generated image more and more real, and the discriminator continuously strives to identify the authenticity of the picture. This is similar to the game between the generator and the discriminator. After repeated iterations, the two finally reached a balance: the picture generated by the generator is very close to the real picture, and it is difficult for the discriminator to distinguish the difference between the real and fake pictures. Its performance is that for true and false pictures, the probability output of the discriminator is close to 0.5.</p>
<p>Let’s still assume an I wants to replicate the style of Picasso. After I have watch all the detail of Picasso’s paintings, I think I have learned a lot. So I find a a collector to help me improve my level. The collector has rich experience and sharp eyes, and the paintings on the market that imitate Picasso cannot escape his eyes. The collector told me a word: when will your painting deceive me, you will be successful.</p>
<p>Then I give hime this one:<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191130110753.png"><br>The collector glanced lightly and was very angry. “0 points! This is also called painting? Too much difference!” After listening to the collector’s words, I began to reflect on myself and did not hesitate to draw, even it is a black image. So I drew another picture:<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191130110852.png"></p>
<p>The collector saw : 1 point ! Repaint! As soon as I thought it was still impossible, the painting was too bad, so I went back to study Picasso’s painting style, and continued to improve and re-create, until one day I showed the new painting to the collector:<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191130001221.png"><br>This time, the collector was wearing glasses and carefully analyzing. After a long time, the collector patted my shoulder and said that the painting was very good. Haha, I was so happy to be praised and affirmed by the collector.</p>
<p>This example is actually a GAN training process. I am a generator, the purpose is to output a picture that can fool collectors, making it difficult for collectors to distinguish between true and false! The collector is the discriminator, the purpose is to identify my painting and judge it to be false! The whole process is a game of “generation-confrontation”. In the end, I (the generator) outputs a picture of “truths and false truths”, and even collectors (the discriminator) can hardly distinguish.</p>
<h2 id="What’s-GAN-model"><a href="#What’s-GAN-model" class="headerlink" title="What’s GAN model?"></a>What’s GAN model?</h2><p>After we talk about the basic ideal, then let’s see what is the Generative Adversarial Networks(GANs) mathematically.  Generally, GANs are a model architecture for training a generative model, and it is most common to use deep learning models in this architecture.</p>
<p>The GAN architecture was first described in the 2014 paper by  Ian Goodfellow, et al. titled “Generative Adversarial Networks.” After this paper appeared, there are plenty related paper followed. A standardized approach called Deep Convolutional Generative Adversarial Networks, or DCGAN, that led to more stable models was later formalized by  Alec Radford, et al. in the 2015 paper titled Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks.</p>
<p>The GAN model architecture involves two sub-models: a  _generator model_  for generating new examples and a  _discriminator model_  for classifying whether generated examples are real, from the domain, or fake, generated by the generator model.</p>
<ul>
<li><strong>Generator</strong>. Model that is used to generate new plausible examples from the problem domain.</li>
<li><strong>Discriminator</strong>. Model that is used to classify examples as real (_from the domain_) or fake (_generated_).</li>
</ul>
<blockquote>
<p>Generative adversarial networks are based on a game theoretic scenario in which the generator network must compete against an adversary. The generator network directly produces samples. Its adversary, the discriminator network, attempts to distinguish between samples drawn from the training data and samples drawn from the generator.</p>
</blockquote>
<h3 id="Generator-Model"><a href="#Generator-Model" class="headerlink" title="Generator Model"></a>Generator Model</h3><p>The generator model takes a fixed-length random vector as input and generates a sample in the domain. The vector is drawn from randomly from a Gaussian distribution, and the vector is used to seed the generative process. After training, points in this multidimensional vector space will correspond to points in the problem domain, forming a compressed representation of the data distribution.</p>
<p>This vector space is referred to as a latent space, or a vector space comprised of  <a href="https://en.wikipedia.org/wiki/Latent_variable" target="_blank" rel="noopener">latent variables</a>. Latent variables, or hidden variables, are those variables that are important for a domain but are not directly observable.</p>
<p>We often refer to latent variables, or a latent space, as a projection or compression of a data distribution. That is, a latent space provides a compression or high-level concepts of the observed raw data such as the input data distribution. In the case of GANs, the generator model applies meaning to points in a chosen latent space, such that new points drawn from the latent space can be provided to the generator model as input and used to generate new and different output examples.</p>
<p>After training, the generator model is kept and used to generate new samples.</p>
<p><img alt="Example of the GAN Generator Model" data-src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/04/Example-of-the-GAN-Generator-Model.png"></p>
<p>Example of the GAN Generator Model</p>
<h3 id="The-Discriminator-Model"><a href="#The-Discriminator-Model" class="headerlink" title="The Discriminator Model"></a>The Discriminator Model</h3><p>The discriminator model takes an example from the domain as input (real or generated) and predicts a binary class label of real or fake (generated).</p>
<p>The real example comes from the training dataset. The generated examples are output by the generator model.</p>
<p>The discriminator is a normal (and well understood) classification model.</p>
<p>After the training process, the discriminator model is discarded as we are interested in the generator.</p>
<p>Sometimes, the generator can be repurposed as it has learned to effectively extract features from examples in the problem domain. Some or all of the feature extraction layers can be used in transfer learning applications using the same or similar input data.</p>
<p><img alt="Example of the GAN Discriminator Model" data-src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/04/Example-of-the-GAN-Discriminator-Model.png"></p>
<h1 id="Combine-two-parts"><a href="#Combine-two-parts" class="headerlink" title="Combine two parts"></a>Combine two parts</h1><p>Generative modeling is an unsupervised learning problem, as we discussed in the previous section, although a clever property of the GAN architecture is that the training of the generative model is framed as a supervised learning problem. The two models, the generator and discriminator, are trained together. The generator generates a batch of samples, and these, along with real examples from the domain, are provided to the discriminator and classified as real or fake. The discriminator is then updated to get better at discriminating real and fake samples in the next round, and importantly, the generator is updated based on how well, or not, the generated samples fooled the discriminator.</p>
<p>In this way, the two models are competing against each other, they are adversarial in the game theory sense, and are playing a  zero-sum game. In this case, zero-sum means that when the discriminator successfully identifies real and fake samples, it is rewarded or no change is needed to the model parameters, whereas the generator is penalized with large updates to model parameters. Alternately, when the generator fools the discriminator, it is rewarded, or no change is needed to the model parameters, but the discriminator is penalized and its model parameters are updated.</p>
<p>At a limit, the generator generates perfect replicas from the input domain every time, and the discriminator cannot tell the difference and predicts “unsure” (e.g. 50% for real and fake) in every case. This is just an example of an idealized case; we do not need to get to this point to arrive at a useful generator model.</p>
<p><img alt="Example of the Generative Adversarial Network Model Architecture" data-src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/04/Example-of-the-Generative-Adversarial-Network-Model-Architecture.png"></p>
<p>Example of the Generative Adversarial Network Model Architecture</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>集成学习GDBT,XGBOOST,RF</title>
    <url>/2019/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%91%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0GDBT-XGBOOST-RF/</url>
    <content><![CDATA[<p>集成学习（Ensemble Learning），集成学习的目的是通过结合多个基学习器的预测结果来改善单个学习器的泛化能力和鲁棒性。</p><p>集成学习致分为两大类：</p><ul>
<li>Boosting:即个体学习器之间存在强依赖关系、必须串行生成的序列化方法，Adaboost, GDBT, Xgboost.</li>
<li>Bagging以及个体学习器间不存在强依赖关系、可同时生成的并行化方法，“随机森林”（Random Forest）。</li>
</ul><a id="more"></a>


<h1 id="1-Bagging"><a href="#1-Bagging" class="headerlink" title="1. Bagging"></a>1. Bagging</h1><p>Bagging：简单放回抽样，多数表决（分类）或简单平均（回归）,同时Bagging的基学习器之间属于并列生成，无依赖关系。</p>
<h2 id="1-1-随机森林"><a href="#1-1-随机森林" class="headerlink" title="1.1 随机森林"></a>1.1 随机森林</h2><p>Random Forest（随机森林）：Bagging的扩展变体，它在以决策树为基学习器构建Bagging集成的基础上，进一步在决策树的训练过程中引入了随机特征选择，因此可以概括RF包括四个部分：<br>1、随机选择 样本（放回抽样）；<br>2、随机选择 特征；<br>3、构建分类器；如：ID3、C4.5、CART、SVM、Logistic regression等<br>4、投票（平均）</p>
<p>随机性偏差会有微增（相比于单棵不随机树），‘平均’会使得方差减小更多</p>
<ul>
<li>随机森林的优点<br>1、速度快，精度不会很差<br>2、能够处理高维数据，不用特征选择，训练完后，可给出特征重要性；<br>3、可并行化  </li>
<li>随机森林的缺点：在噪声较大的分类或者回归问题上回过拟合。</li>
</ul>
<h1 id="2-Boosting"><a href="#2-Boosting" class="headerlink" title="2. Boosting"></a>2. Boosting</h1><h2 id="2-1-基于调整权重-Adaboost"><a href="#2-1-基于调整权重-Adaboost" class="headerlink" title="2.1 基于调整权重 Adaboost"></a>2.1 基于调整权重 Adaboost</h2><p>每生成一棵树之后，计算两个权重</p>
<blockquote>
<p>1 计算这个树的误差率，误差率越高，权重越低<br>2 计算每个样本的错分率，错分的样本，权重越高，之后更容易分对</p>
</blockquote>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191116091802.png"><br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191116091915.png"></p>
<h2 id="2-2-基于残差：GB-GBTD-Xgboost"><a href="#2-2-基于残差：GB-GBTD-Xgboost" class="headerlink" title="2.2 基于残差：GB(GBTD,Xgboost)"></a>2.2 基于残差：GB(GBTD,Xgboost)</h2><h3 id="2-2-1-GBTD"><a href="#2-2-1-GBTD" class="headerlink" title="2.2.1 GBTD"></a>2.2.1 GBTD</h3><p>GBDT只能由回归树组成.</p>
<ul>
<li>基本思想：<br>在GradientBoost中，每个新的模型的建立是为了使得之前的模型的残差往梯度下降的方法。</li>
</ul>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191116110339.png"></p>
<ul>
<li>如果是分类树，损失函数是指数损失函数：<br>𝐿(𝑦,𝑓(𝑥))=𝑒𝑥𝑝(−𝑦𝑓(𝑥))</li>
<li>如果是回归树，损失函数是均方损失（CART）：<br>𝐿(𝑦,𝑓(𝑥))=(𝑦−𝑓(𝑥))^2</li>
<li>如何防止过拟合？<blockquote>
<ol>
<li>步长v(0-1)，权重衰减 𝑓𝑘(𝑥)=𝑓𝑘−1(𝑥)+𝑣 ℎ𝑘(𝑥)，降低新来的分类器的影响力</li>
<li>子采样比例</li>
<li>用弱学习器</li>
</ol>
</blockquote>
</li>
</ul>
<h3 id="2-2-2-xgboost"><a href="#2-2-2-xgboost" class="headerlink" title="2.2.2 xgboost"></a>2.2.2 xgboost</h3><p>当已经生成了一棵树的时候，如何去选择新子树：</p>
<ul>
<li><p>1 目标函数：</p>
<script type="math/tex; mode=display">Obj=\sum_{i=1}^{n} l\left(y_{i}, \hat{y}_{i}\right)+\sum_{k} \Omega\left(f_{k}\right), f_{k} \in \mathcal{F}</script></li>
<li><p>1.1 第t轮的时候：</p>
<script type="math/tex; mode=display">\begin{aligned} O b j^{(t)} 
&=\sum_{i=1}^{n} l\left(y_{i}, \hat{y}_{i}^{(t)}\right)+\sum_{i=1}^{t} \Omega\left(f_{i}\right) 
\\ & \equiv \sum_{i=1}^{n} l\left(y_{i}, \hat{y}_{i}^{(t-1)}+f_{t}\left(x_{i}\right)\right)+\Omega\left(f_{t}\right)+c\end{aligned}</script></li>
<li>这时候需要寻找f_t来让目标函数最小</li>
</ul>
<blockquote>
<p>a. 式子左边，对目标函数在$f_t(x)$上泰勒展开，去二阶，求得近似解：<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191116120113.png"></p>
<p>b. 式子右边，定义复杂度 $\Omega\left(f_{t}\right)$<br>每颗树，都是由枝干(分类节点)和叶子(树的末端)组成的。<br>定义复杂度为：叶子个个数T, 加上每个叶子的值w平方和（各有系数）。<br>树越复杂，T ↑，w平方和 ↑，复杂度 ↑，惩罚 ↑。<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191116121238.png"></p>
</blockquote>
<ul>
<li>更新目标函数：<script type="math/tex; mode=display">
\begin{aligned} O b j^{(t)} & \simeq \sum_{i=1}^{n}\left[g_{i} f_{t}\left(x_{i}\right)+\frac{1}{2} h_{i} f_{t}^{2}\left(x_{i}\right)\right]+\Omega\left(f_{t}\right) +c\\ &=\sum_{i=1}^{n}\left[g_{i} w_{q\left(x_{i}\right)}+\frac{1}{2} h_{i} w_{q\left(x_{i}\right)}^{2}\right]+\left(\gamma T+\lambda \frac{1}{2} \sum_{j=1}^{T} w_{j}^{2}\right)+c
\\ &=\sum_{j=1}^{T}\left[\left(\sum_{i \in I_{j}} g_{i}\right) w_{j}+\frac{1}{2}\left(\sum_{i \in I_{j}} h_{i}+\lambda\right) w_{j}^{2}\right]+\gamma T +c \end{aligned}</script></li>
</ul>
<blockquote>
<ul>
<li>其中$f_{t}(x)=w_{q(x)}, w \in \mathbf{R}^{T}, q: \mathbf{R}^{d} \rightarrow\{1,2, \cdots, T\}$，表示x→叶节点→对应的值w。目的是统一用$w_{j}$表示树$f_t$。</li>
<li>第三行的理解，对于示性函数$I_{j}=\left\{i | q\left(x_{i}\right)=j\right\}$，$I_j$表示一个集合在j的叶子节点中。用示性函数求和代替1-n的求和，然后交换求和顺序。</li>
</ul>
</blockquote>
<ul>
<li>这里发现目标函数是关于$w_{j}$的二次函数，二次函数在对称轴上取极值。<br>简化表达：$G_{j}=\sum_{i \in I_{j}} g_{i} \quad H_{j}=\sum_{i \in I_{j}} h_{i}$得到：<script type="math/tex; mode=display">
\begin{aligned} O b j^{(t)} =\sum_{j=1}^{T}\left[G_{j} w_{j}+\frac{1}{2}\left(H_{j}+\lambda\right) w_{j}^{2}\right]+\gamma T \end{aligned}</script>二次函数求极值得到：<script type="math/tex; mode=display">
\begin{array}{c}{w_{j}^{*}=-\frac{G_{j}}{H_{j}+\lambda}} \\ {} \\ {O b j=-\frac{1}{2} \sum_{j=1}^{T} \frac{G_{j}^{2}}{H_{j}+\lambda}+\gamma T}\end{array}</script>w是每一个叶节点值，Obj是这个树的分数，分数越低越好。<br>这样，就可以直接计算出树的分数，可以对于候选进行评比。</li>
</ul>
<hr>
<p>如何生成候选树？</p>
<ul>
<li>Enumerate 枚举可能的结构</li>
<li>通过刚才的式子计算最优分数</li>
<li>但是问题是有无限的可能性。</li>
</ul>
<hr>
<ul>
<li>所以通过贪婪学习：（不详细讲）<br>每一次尝试对已有的叶子结点加入一个分割，选择具有最佳增益的分割对结点进行分裂。对于一个具体的分割方案，我们可以获得的增益可以由如下公式计算：<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191116142330.png"></li>
</ul>
<blockquote>
<p>也就是通过信息增益去寻找最优分割点。<br>这里有个好处就是如果惩罚大于增益，gain就会为负数，自动停止。</p>
</blockquote>
<h1 id="3-模型对比"><a href="#3-模型对比" class="headerlink" title="3 模型对比"></a>3 模型对比</h1><h2 id="3-1-随机森林vsGDBT"><a href="#3-1-随机森林vsGDBT" class="headerlink" title="3.1 随机森林vsGDBT"></a>3.1 随机森林vsGDBT</h2><ul>
<li>决策树类型：组成随机森林的树可以是分类树，也可以是回归树；而GBDT只能由回归树组成；  </li>
<li>结果预测：对于最终的输出结果而言，随机森林采用多数投票、简单平均等；而GBDT则是将所有结果累加起来，或者加权累加起来；  </li>
<li>并行/串行：组成随机森林的树可以并行生成；而GBDT只能是串行生成；  </li>
<li>异常值：随机森林对异常值不敏感；GBDT对异常值非常敏感；</li>
<li>方差/偏差：随机森林减少方差；GBDT是通过减少偏差。</li>
</ul>
<h2 id="3-2-GDBT-vs-XGboost"><a href="#3-2-GDBT-vs-XGboost" class="headerlink" title="3.2 GDBT vs XGboost"></a>3.2 GDBT vs XGboost</h2><ul>
<li>GDBT只支持CATR树，xgboost还支持线性分类器</li>
<li>GDBT只用了一阶，xgboost泰勒展开，用了二阶</li>
<li>xgboost有正则项，而且会自动停止生成(依赖参数gamma)。</li>
<li>xgboost可以列抽样，借鉴了随机森林的做法</li>
<li>XGBOOST可以自动学习出缺失值的分裂方向</li>
<li>XGBOOST实现了并行化：每个特征并行计算，每个特征划分也并行计算</li>
</ul>
<p>后期实现中，xgboost还有优化，所以很快：</p>
<ul>
<li>在寻找分割点，枚举贪心法效率低，xgboost实现近似的算法。大致的思想是根据百分位法列举几个成为分割点的候选者，然后再进一步计算。</li>
<li>xgboost考虑了训练数据为稀疏值的情况（我也不懂T^T）</li>
<li>特征列排序后以块的形式存储在内存中，在迭代中可以重复使用；虽然boosting算法迭代必须串行，但是在处理每个特征列时可以做到并行。</li>
<li>Shrinkage（缩减），相当于学习速率（xgboost中的eta）。xgboost在进行完一次迭代后，会将叶子节点的权重乘上该系数，主要是为了削弱每棵树的影响，让后面有更大的学习空间。实际应用中，一般把eta设置得小一点，然后迭代次数设置得大一点。（补充：传统GBDT的实现也有学习速率）</li>
</ul>
<p>总结，一个简单的idel不断优化，借鉴别的想法，优化到了极致，导致xgboost能这么强。</p>
<p>参考资料：xgboost原文<br><a href="https://blog.csdn.net/weixin_42158523/article/details/81737370" target="_blank" rel="noopener">https://blog.csdn.net/weixin_42158523/article/details/81737370</a><br><a href="https://www.cnblogs.com/aixiao07/p/11375168.html" target="_blank" rel="noopener">https://www.cnblogs.com/aixiao07/p/11375168.html</a></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>港校msc 互联网找工作时间轴</title>
    <url>/2019/Blog2-%E6%B8%AF%E6%A0%A1msc-%E4%BA%92%E8%81%94%E7%BD%91%E6%89%BE%E5%B7%A5%E4%BD%9C%E6%97%B6%E9%97%B4%E8%BD%B4/</url>
    <content><![CDATA[<h1 id="港校msc-互联网找工作时间轴"><a href="#港校msc-互联网找工作时间轴" class="headerlink" title="港校msc 互联网找工作时间轴"></a>港校msc 互联网找工作时间轴</h1><p><strong>入学前的（大四） 暑期实习</strong> 建议参加<br>3-5月 实习岗位网申开启<br>5-7月 进行网申、面试，发放Offer<br>7-9月 进入公司实习</p><p><strong>入学前的 秋季校招</strong> 建议参加<br>7-8月 互联网大厂的提前批、正式校招开放；<br>9月意向书，10月底谈薪</p><a id="more"></a>

<hr>
<h2 id="入学"><a href="#入学" class="headerlink" title="入学"></a>入学</h2><p><strong>入学后的</strong> 春季校招 招人较少<br>2-4月 进行网申<br>3-5月 开始笔试、面试<br>5-6月 发Offer入职</p>
<p><strong>暑假实习</strong> 必参加<br>3-5月 各大行业实习岗位网申开启<br>5-7月 进行网申、面试，发放Offer<br>7-9月 进入公司实习</p>
<p><strong>秋季校招</strong> 即使拿到实习return也建议参加，有利于argue涨价<br>7-8月 互联网大厂的提前批、正式校招开放；<br>9月意向书，10月底谈薪</p>
<p>11月毕业-&gt;入职</p>
<hr>
<h2 id="成为社畜"><a href="#成为社畜" class="headerlink" title="成为社畜"></a>成为社畜</h2><p>我的个人准备笔试面试时间轴：<br><!-- Table --><br>| 月份| 校内|找工作准备|<br>|—|—|—|<br>| 11月| 各种ddl | 算法基础+数据结构<br>|12月|考试+寒假|剑指offer<br>|1月|寒假| 剑指offer+NLP+整理机器学习+特征工程<br>|2月|开学不忙|leetcode mid+NLP实战+整理深度学习<br>|3月|开始准备期中| leetcode hard+笔试概率题、智商题</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>timeline</tag>
        <tag>实习</tag>
      </tags>
  </entry>
  <entry>
    <title>Build by Hexo</title>
    <url>/2019/Blog1-Build%20by%20Hexo/</url>
    <content><![CDATA[<p>本次搭建blog，完全学习于：<a href="https://www.bilibili.com/video/av44544186?from=search&amp;seid=6748505739751413370" target="_blank" rel="noopener">b站up主codesheep视频</a></p><p>下面进入流程：</p><ol>
<li>sudo su 进入管理员</li>
<li>安装Node.js，搜索，下载，安装<br>安装之后会有两个工具： node和npm<br>也可以用国内的cnpm</li>
<li>通过npm安装hexo 博客静态框架<blockquote>
<p>npm install -g hexo-cli </p>
</blockquote>
</li>
<li>建立一个专有的文件夹，方便管理</li>
<li>文件夹下运行hexo<blockquote>
<p>sudo hexo init</p>
</blockquote>
</li>
</ol><a id="more"></a>


<p>初始化文件，主要的有_config.yml 配置文件，source内容的文件夹，themes主题文件夹。</p>
<blockquote>
<p>hexo s #start 开始<br>hexo n “文章名” #生成文章<br>hexo clean #清理之前的</p>
<ol>
<li>部署到github</li>
</ol>
</blockquote>
<p>生成 xxx.github.io（ xxx必须为github的用户名）的项目</p>
<blockquote>
<p>npm install —save hexo-deployer-git</p>
</blockquote>
<p>下载插件，连接到git</p>
<p>设置_config.yml最下面</p>
<blockquote>
<p>type: git<br>repo: <a href="https://github.com/xxxx/xxxx.github.io" target="_blank" rel="noopener">https://github.com/xxxx/xxxx.github.io</a></p>
</blockquote>
<p>推送到远端</p>
<blockquote>
<p>hexo clean &amp;&amp; hexo g &amp;&amp; hexo d</p>
</blockquote>
<p>访问 xxxx.github.io，就可以看到自己的博客啦。</p>
<hr>
<p><a href="https://hexo.io/zh-cn/docs/commands.html" target="_blank" rel="noopener">hexo官网</a></p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello Blog</title>
    <url>/2019/Hello-Blog/</url>
    <content><![CDATA[<h1 id="Hello-Blog"><a href="#Hello-Blog" class="headerlink" title="Hello Blog."></a>Hello Blog.</h1><p>之前经常会发现大佬有自己的技术博客，之前也尝试着去做一个，但是由于自己的技术水平有限，也没有决定好走技术路线，所以就一直没有开始写技术博客。</p><p>最近比较了算法和产品的待遇，真的差别好大。暂且不说之后的发展会怎样，程序员/技术岗本身是智力和努力的比拼，是硬功夫。有更清晰的发展方向。再加上种种原因，我决定做技术了。</p><a id="more"></a>

<ul>
<li>所以为什么要写博客呢？<br>（鉴于自己的理解和b站up主<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2Fav56930990%2F%3Fspm_id_from%3D333.788.videocard.2" target="_blank" rel="noopener">codesheep</a> 的介绍，总结如下） <ol>
<li>博客=输出=实践<br>写博客也是一个技术输出的过程，而当你想输出的时候，你就已经需要整合自己的学习成果，不断的理解技术细节，比如说：神经网络的梯度传到过程，虽然接触很多遍，不动手就很难掌握。</li>
<li>博客=输出=表达<br>理科出身的我经常给自己找借口，原理我懂就行，表达不清楚就慢慢表达，但实际上，表达不清楚会导致别人不愿意和你交流，从而丧失很多机会。<br>有了输出的过程，就需要去磨炼自己表达的精炼程度，以及练习如何让别人明白，就更容易理解。</li>
<li>博客=简历=社交<br>有了个人主页，别人就知道你的技术水平，你会什么，你学过什么，一应俱全。是找工作，或者是技术交流的好平台。</li>
</ol>
</li>
<li>担心自己的博客没有技术含量？<br>你觉得没有技术含量的可能会对别人有用，只要可复现，都是有价值的。</li>
<li>现在写的会晚吗？<br>我知道很多cs的同学大一就开始搭建自己的知识体系，构建专栏，值得敬佩和羡慕。不过人生漫长，任何时候开始干一件事都不晚。</li>
<li>写什么内容？<ol>
<li>学习笔记、心得</li>
<li>生活感悟</li>
<li>工程排坑</li>
</ol>
</li>
</ul>
<p>为了混口饭吃，写博客的flag没有任何理由推倒了吧。<br>希望最少保持一个月一篇的频率，正常频率一周一篇。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>blog</tag>
      </tags>
  </entry>
</search>
