<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/icon_ca.jpeg">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/icon_ca.jpeg">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/icon_ca.jpeg">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">
  <meta name="google-site-verification" content="true">
  <meta name="msvalidate.01" content="true">
  <meta name="yandex-verification" content="true">
  <meta name="baidu-site-verification" content="true">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css?family=Lato:300,300italic,400,400italic,700,700italic|Long Cang:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.4.2',
    exturl: false,
    sidebar: {"position":"left","display":"always","offset":12,"onmobile":false},
    copycode: {"enable":true,"show_result":true,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":true},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="CS224n-2 word2vec, word Senses这节课我不按课堂讲的，引用一篇博客word vectors and word2vec代表技术之一 word2vec2013年，Google团队发表了word2vec工具 [1]。word2vec工具主要包含两个模型：跳字模型（skip-gram）和连续词袋模型（continuous bag of words，简称CBOW），以及两种近似训">
<meta name="keywords" content="NLP">
<meta property="og:type" content="article">
<meta property="og:title" content="CS224n-2 word2vec, word Senses">
<meta property="og:url" content="http:&#x2F;&#x2F;leeee.top&#x2F;2020&#x2F;CS224n-2-word2vec-word-Senses&#x2F;index.html">
<meta property="og:site_name" content="元哥的日记">
<meta property="og:description" content="CS224n-2 word2vec, word Senses这节课我不按课堂讲的，引用一篇博客word vectors and word2vec代表技术之一 word2vec2013年，Google团队发表了word2vec工具 [1]。word2vec工具主要包含两个模型：跳字模型（skip-gram）和连续词袋模型（continuous bag of words，简称CBOW），以及两种近似训">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200208213903.png">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200208213949.png">
<meta property="og:image" content="https:&#x2F;&#x2F;upload-images.jianshu.io&#x2F;upload_images&#x2F;1803066-6089ead7ce1ea503.png?imageMogr2&#x2F;auto-orient&#x2F;strip|imageView2&#x2F;2&#x2F;w&#x2F;720&#x2F;format&#x2F;webp">
<meta property="og:image" content="https:&#x2F;&#x2F;upload-images.jianshu.io&#x2F;upload_images&#x2F;1803066-69d819ac1e385080.png?imageMogr2&#x2F;auto-orient&#x2F;strip|imageView2&#x2F;2&#x2F;w&#x2F;662&#x2F;format&#x2F;webp">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200208215618.png">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200208215642.png">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200208220835.png">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200208220909.png">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200208220919.png">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200208220926.png">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200208215727.png">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200208215738.png">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200208215749.png">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200208215805.png">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200208221019.png">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200208221029.png">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200208224459.png">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200208224516.png">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200208224525.png">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200208224609.png">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200208224615.png">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200208224627.png">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200208224641.png">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200208224651.png">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200208224729.png">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200208224736.png">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200208225228.png">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200208225801.png">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200208225816.png">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200208230330.png">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200208233632.png">
<meta property="og:updated_time" content="2020-02-26T08:19:41.710Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200208213903.png">

<link rel="canonical" href="http://leeee.top/2020/CS224n-2-word2vec-word-Senses/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>CS224n-2 word2vec, word Senses | 元哥的日记</title>
  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?567d405f5ec7479a4e2944724d8c336f";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">元哥的日记</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <h1 class="site-subtitle" itemprop="description">终其一生，我们只不过在寻找自己</h1>
      
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/#/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-所有文章">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>所有文章</a>

  </li>
        <li class="menu-item menu-item-标签">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-关于我">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于我</a>

  </li>
        <li class="menu-item menu-item-分类">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        
            
  <li class="menu-item menu-item-更多">

    <a href="/more/" rel="section"><i class="fa fa-fw fa-share"></i>更多</a>

  </li>


      
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://leeee.top/2020/CS224n-2-word2vec-word-Senses/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/pic03.jpg">
      <meta itemprop="name" content="Yuan">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="元哥的日记">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          CS224n-2 word2vec, word Senses
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-02-08 23:37:47" itemprop="dateCreated datePublished" datetime="2020-02-08T23:37:47+08:00">2020-02-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-02-26 16:19:41" itemprop="dateModified" datetime="2020-02-26T16:19:41+08:00">2020-02-26</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CS224n/" itemprop="url" rel="index"><span itemprop="name">CS224n</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>4.6k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>4 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="CS224n-2-word2vec-word-Senses"><a href="#CS224n-2-word2vec-word-Senses" class="headerlink" title="CS224n-2 word2vec, word Senses"></a>CS224n-2 word2vec, word Senses</h1><p>这节课我不按课堂讲的，引用一篇<a href="https://www.jianshu.com/p/a6bc14323d77" target="_blank" rel="noopener">博客</a></p><h1 id="word-vectors-and-word2vec"><a href="#word-vectors-and-word2vec" class="headerlink" title="word vectors and word2vec"></a>word vectors and word2vec</h1><h2 id="代表技术之一-word2vec"><a href="#代表技术之一-word2vec" class="headerlink" title="代表技术之一 word2vec"></a>代表技术之一 word2vec</h2><p>2013年，Google团队发表了word2vec工具 [1]。word2vec工具主要包含两个模型：跳字模型（skip-gram）和连续词袋模型（continuous bag of words，简称CBOW），以及两种近似训练法：负采样（negative sampling）和层序softmax（hierarchical softmax）。值得一提的是，word2vec的词向量可以较好地表达不同词之间的相似和类比关系。</p><a id="more"></a>

<p>word2vec自提出后被广泛应用在自然语言处理任务中。它的模型和训练方法也启发了很多后续的词嵌入模型。本节将重点介绍word2vec的模型和训练方法。</p>
<h2 id="Skip-gram模型（跳字模型）："><a href="#Skip-gram模型（跳字模型）：" class="headerlink" title="Skip-gram模型（跳字模型）："></a>Skip-gram模型（跳字模型）：</h2><p><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208213903.png" alt><br>Skip-gram</p>
<p>在跳字模型中，我们用一个词来预测它在文本序列周围的词。</p>
<p>举个例子，假设文本序列是：</p>
<blockquote>
<p>“I love you very much”</p>
</blockquote>
<p>跳字模型所关心的是，给定“<strong>you</strong>”生成邻近词“I”、“love”、“very”和“much”的条件概率。</p>
<p>在这个例子中，“you”叫中心词，“I”、“love”、“very”和“much”叫背景词。</p>
<p>由于“you”只生成与它距离不超过2的背景词，该<strong>时间窗口的大小为2</strong>[与N-gram类似]。</p>
<p>我们来描述一下跳字模型[用最大似然估计的思想]：</p>
<p>假设词典索引集V的大小为|V|，且{0,1,…,|V|−1}。给定一个长度为T的文本序列中，文本序列中第t的词为w(t)。当时间窗口大小为m时，跳字模型需要<strong>最大化给定任一中心词生成所有背景词的概率：</strong></p>
<p><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208213949.png" alt></p>
<p>上式的<strong>最大似然估计</strong>与<strong>最小化以下损失函数</strong>等价：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/1803066-6089ead7ce1ea503.png?imageMogr2/auto-orient/strip|imageView2/2/w/720/format/webp" alt></p>
<p>我们可以用<strong>v</strong>和<strong>u</strong>分别表示 <strong>中心词</strong> 和 <strong>背景词</strong> 的向量。</p>
<p>换言之，对于词典中索引为i的词，它在作为中心词和背景词时的向量表示分别是vi和ui。而词典中所有词的这两种向量正是跳字模型所要学习的模型参数。为了将模型参数植入损失函数，我们需要使用模型参数表达损失函数中的给定中心词生成背景词的条件概率。给定中心词，假设生成各个背景词是相互独立的。设中心词wc在词典中索引为c，背景词wo在词典中索引为o，损失函数中的给定中心词生成背景词的<strong>条件概率</strong>可以通过softmax函数定义为：</p>
<p><img src="https://upload-images.jianshu.io/upload_images/1803066-69d819ac1e385080.png?imageMogr2/auto-orient/strip|imageView2/2/w/662/format/webp" alt></p>
<blockquote>
<p>上式：给定任何一个中心词Wc，产生背景词Wo的概率</p>
<p>每一个词，在模型中有两个词向量，一个是作为中心词时的词向量，一个是作为背景词时的词向量</p>
</blockquote>
<p><strong>利用随机梯度下降求解：</strong></p>
<p>当序列长度T较大时，我们通常在每次迭代时随机采样一个较短的子序列来计算有关该子序列的损失。然后，根据该损失计算词向量的梯度并迭代词向量。具体算法可以参考<a href="https://links.jianshu.com/go?to=http%3A%2F%2Fzh.gluon.ai%2Fchapter_optimization%2Fgd-sgd-scratch.html" target="_blank" rel="noopener">“梯度下降和随机梯度下降——从零开始”</a>一节。 作为一个具体的例子，下面我们看看如何计算随机采样的子序列的损失有关中心词向量的梯度。和上面提到的长度为T的文本序列的损失函数类似，随机采样的子序列的损失实际上是对子序列中给定中心词生成背景词的条件概率的对数求平均。通过微分，我们可以得到上式中条件概率的对数有关中心词向量vc的<strong>梯度：</strong>  </p>
<p><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208215618.png" alt></p>
<p><strong>该式也可改写作：</strong></p>
<p><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208215642.png" alt></p>
<blockquote>
<p>上面的迭代更新计算开销太大！！每次都需要遍历整个字典，对应的解决方案在后面（这也是word2vec为啥这么牛逼的原因…厉害的不是这个工具本身，而是一种思想的应用）</p>
</blockquote>
<p>随机采样的子序列有关其他词向量的梯度同理可得。训练模型时，每一次迭代实际上是用这些梯度来迭代子序列中出现过的中心词和背景词的向量。训练结束后，对于词典中的任一索引为i的词，我们均得到该词作为中心词和背景词的两组词向量vi和ui。在自然语言处理应用中，我们会使用跳字模型的中心词向量。</p>
<h4 id="求梯度过程"><a href="#求梯度过程" class="headerlink" title="求梯度过程"></a>求梯度过程</h4><p><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208220835.png" alt></p>
<p><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208220909.png" alt><br><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208220919.png" alt><br><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208220926.png" alt></p>
<hr>
<h3 id="CBOW-连续词袋模型"><a href="#CBOW-连续词袋模型" class="headerlink" title="CBOW(连续词袋模型)"></a>CBOW(连续词袋模型)</h3><p><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208215727.png" alt></p>
<p>CBOW</p>
<p>连续词袋模型与跳字模型类似,与跳字模型最大的不同是：</p>
<p>连续词袋模型用一个中心词在文本序列周围的词来预测该中心词。</p>
<p>举个例子，假设文本序列为：</p>
<blockquote>
<p>“I love you very much”</p>
</blockquote>
<p>连续词袋模型所关心的是，邻近词“I”、“love”、“very”和“much”一起生成中心词“you”的概率。</p>
<p>假设词典索引集的大小为V，且V={0,1,…,|V|−1}&lt;/nobr&gt;。给定一个长度为T的文本序列中，文本序列中第t个词为wu(t)。当时间窗口大小为m时，连续词袋模型需要最大化由背景词生成任一中心词的概率</p>
<p><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208215738.png" alt></p>
<p>上式的最大似然估计与最小化以下损失函数等价：</p>
<p><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208215749.png" alt></p>
<p>我们可以用<strong>v</strong>和<strong>u</strong>分别表示背景词和中心词的向量（注意符号和跳字模型中的不同）。换言之，对于词典中索引为i的词，它在作为背景词和中心词时的向量表示分别是vi和ui。而词典中所有词的这两种向量正是连续词袋模型所要学习的模型参数。为了将模型参数植入损失函数，我们需要使用模型参数表达损失函数中的给定背景词生成中心词的概率。设中心词wc在词典中索引为c，背景词wo1、wo2、…wo2m在词典中索引为o1、o2、….o2m-1、o2m，损失函数中的给定背景词生成中心词的概率可以通过softmax函数定义为</p>
<p><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208215805.png" alt></p>
<p>和跳字模型一样，当序列长度T较大时，我们通常在每次迭代时随机采样一个较短的子序列来计算有关该子序列的损失。然后，根据该损失计算词向量的梯度并迭代词向量。 通过微分，我们可以计算出上式中条件概率的对数有关任一背景词向量voi(i=1,2,….2m)的梯度为：<br><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208221019.png" alt></p>
<p>该式也可写作</p>
<p><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208221029.png" alt></p>
<p>随机采样的子序列有关其他词向量的梯度同理可得。和跳字模型一样，训练结束后，对于词典中的任一索引为i的词，我们均得到该词作为背景词和中心词的两组词向量vi和ui。<br>在自然语言处理应用中，我们会使用连续词袋模型的背景词向量。</p>
<hr>
<h1 id="近似训练法"><a href="#近似训练法" class="headerlink" title="近似训练法"></a>近似训练法</h1><p>我们可以看到，无论是skip-gram(跳字模型)还是CBOW(连续词袋模型)，每一步梯度计算的开销与词典V的大小相关。</p>
<blockquote>
<p>因为计算softmax的时考虑了字典上的所有可能性</p>
</blockquote>
<p>当词典较大时，例如几十万到上百万，这种训练方法的计算开销会较大。因此，我们将使用近似的方法来计算这些梯度，从而减小计算开销。常用的近似训练法包括负采样和层序softmax。</p>
<h2 id="1-负采样（Negative-Sample）"><a href="#1-负采样（Negative-Sample）" class="headerlink" title="(1)负采样（Negative Sample）"></a>(1)负采样（Negative Sample）</h2><p>我们以跳字模型为例讨论负采样。</p>
<p>实际上，词典V的大小之所以会在损失中出现，是因为给定中心词$w_c$生成背景词wo的条件概率$P(w_0∣w_c)$</p>
<blockquote>
<p>使用了softmax运算，而softmax运算正是<strong>考虑了背景词可能是词典中的任一词（使用了全部词）</strong>，并体现在分母上。<br><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208224459.png" alt></p>
</blockquote>
<p>下面，我们可以使用σ(x)=1/(1+exp(−x))函数来表达中心词wc和背景词wo同时出现在该训练数据窗口的概率。</p>
<blockquote>
<p>σ(x)属于[0,1]<br><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208224516.png" alt></p>
</blockquote>
<p>那么，给定中心词wc生成背景词wo的条件概率的对数可以近似为:<br><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208224525.png" alt></p>
<p>[上式的含义：中心词wc与背景词wo同时出(D=1)现概率，且中心词wc与噪音词wk不同时出现(D=0)的概率。]</p>
<p>假设噪声词wk在词典中的索引为ik，上式可改写为:</p>
<p><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208224609.png" alt></p>
<p>因此，有关给定中心词wc生成背景词wo的损失是:</p>
<p>假设词典V很大，每次迭代的计算开销由O(|V|)变为O(|K|)。当我们把K取较小值时，负采样每次迭代的计算开销将较小。</p>
<p>当然，我们也可以对连续词袋模型进行负采样。有关给定背景词<br>wt-m、wt-m+1、…、wt+m生成中心词wc的损失:<br><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208224615.png" alt></p>
<p>在负采样中可以近似为:</p>
<p>  <img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208224627.png" alt></p>
<p>同样，当我们把K取较小值时，负采样每次迭代的计算开销将较小。</p>
<h2 id="2-层序softmax"><a href="#2-层序softmax" class="headerlink" title="(2)层序softmax[]"></a>(2)层序softmax[]</h2><p>层序softmax是另一种常用的近似训练法。它利用了二叉树这一数据结构。树的每个叶子节点代表着词典V中的每个词。  </p>
<p><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208224641.png" alt></p>
<p>假设L(w)为从二叉树的根节点到词w&lt;的叶子节点的路径（包括根和叶子节点）上的节点数。设n(w,j)为该路径上第j个节点，并设该节点的向量为un(w,j)。以上图为例：L(w3)=4。设词典中的词wi的词向量为vi。那么，跳字模型和连续词袋模型所需要计算的给定词wi生成词w的条件概率为：<img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208224651.png" alt><br>其中σ(x)=1/(1+exp(−x))，leftChild(n)是节点n的左孩子节点，如果判断x为真，[x]=1；反之[x]=−1。由于σ(x)+σ(−x)=1，给定词wi生成词典V中任一词的条件概率之和为1这一条件也将满足：<br><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208224729.png" alt></p>
<p>让我们计算给定词wi生成词w3的条件概率。我们需要将wi的词向量vi和根节点到w3路径上的非叶子节点向量一一求内积。由于在二叉树中由根节点到叶子节点w3的路径上需要向左、向右、再向左地遍历，我们得到:<br><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208224736.png" alt></p>
<blockquote>
<p><strong>整个遍历的路径已经通过Huffman编码唯一的确定了</strong></p>
</blockquote>
<p>在使用softmax的跳字模型和连续词袋模型中，词向量和二叉树中非叶子节点向量是需要学习的模型参数。</p>
<p>假设词典V很大，每次迭代的计算开销由O(|V|)下降至O(log2|V|)。</p>
<p>推荐资料：<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Fx-hacker%2FWordEmbedding" target="_blank" rel="noopener">学习word2vec的经典资料</a></p>
<h1 id="SVD"><a href="#SVD" class="headerlink" title="SVD"></a>SVD</h1><p><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208225228.png" alt></p>
<p>分解矩阵，就可以得到embedding，和推荐系统的思路一样。SVD也存在维数问题，以及矩阵分解的困难。</p>
<h1 id="GloVe算法-基于局部和全局"><a href="#GloVe算法-基于局部和全局" class="headerlink" title="GloVe算法-基于局部和全局"></a>GloVe算法-基于局部和全局</h1><p><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208225801.png" alt><br>比较SVD这种count based模型与Word2Vec这种direct prediction模型，它们各有优缺点：Count based模型优点是训练快速，并且有效的利用了统计信息，缺点是对于高频词汇较为偏向，并且仅能概括词组的相关性，而且有的时候产生的word vector对于解释词的含义如word analogy等任务效果不好；Direct Prediction优点是可以概括比相关性更为复杂的信息，进行word analogy等任务时效果较好，缺点是对统计信息利用的不够充分。所以Manning教授他们想采取一种方法可以结合两者的优势，并将这种算法命名为GloVe（Global Vectors的缩写），表示他们可以有效的利用全局的统计信息。</p>
<p>那么如何有效的利用word-word co-occurrence count并能学习到词语背后的含义呢？首先为表述问题简洁需要，先定义一些符号：对于矩阵X，$X_{ij}$代表了单词 i 出现在单词 j 上下文中的次数，则$X_i=\sum_k X_{ij}$<br> 即代表所有出现在单词 i 的上下文中的单词次数。我们用$P_{i j}=P(j | i)=\frac{X_{i j}}{X_{i}}$来代表单词 j 出现在单词 i 上下文中的概率。</p>
<p>我们用一个小例子来解释如何利用co-occurrence probability来表示词汇含义：<br><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208225816.png" alt><br>例如我们想区分热力学上两种不同状态ice冰与蒸汽steam，它们之间的关系可通过与不同的单词 [公式] 的co-occurrence probability 的比值来描述，例如对于solid固态，虽然 $P(solidice)$ 与 $P(solid∣steam)$本身很小，不能透露有效的信息，但是它们的比值$\frac{P(solid|ice)} {P(solid|steam)}$ 却较大，因为solid更常用来描述ice的状态而不是steam的状态，所以在ice的上下文中出现几率较大，对于gas则恰恰相反，而对于water这种描述ice与steam均可或者fashion这种与两者都没什么联系的单词，则比值接近于1。所以相较于单纯的co-occurrence probability，实际上co-occurrence probability的相对比值更有意义。</p>
<p>通过定义如下的损失函数：<br><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208230330.png" alt></p>
<p>优点是训练快，小数据集表现好。<br><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200208233632.png" alt></p>

    </div>

    
    
    
      
  <div class="popular-posts-header">相似文章</div>
  <ul class="popular-posts">
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/2020/CS224n-1-初步探索，背景介绍/" rel="bookmark">CS224n-1 初步探索，背景介绍  </a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/2020/CS224n-3/" rel="bookmark">CS224n-3 回顾神经网络，文本分类介绍</a></div>
    </li>
  </ul>


      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/NLP/" rel="tag"><i class="fa fa-tag"></i> NLP</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
                <a href="/2020/CS224n-1-%E5%88%9D%E6%AD%A5%E6%8E%A2%E7%B4%A2%EF%BC%8C%E8%83%8C%E6%99%AF%E4%BB%8B%E7%BB%8D/" rel="next" title="CS224n-1 初步探索，背景介绍  ">
                  <i class="fa fa-chevron-left"></i> CS224n-1 初步探索，背景介绍  
                </a>
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
                <a href="/2020/CS224n-3/" rel="prev" title="CS224n-3 回顾神经网络，文本分类介绍">
                  CS224n-3 回顾神经网络，文本分类介绍 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
      </footer>
    
  </article>

  
  
  

  </div>


          </div>
          
    <div class="comments" id="gitalk-container"></div>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#CS224n-2-word2vec-word-Senses"><span class="nav-number">1.</span> <span class="nav-text">CS224n-2 word2vec, word Senses</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#word-vectors-and-word2vec"><span class="nav-number">2.</span> <span class="nav-text">word vectors and word2vec</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#代表技术之一-word2vec"><span class="nav-number">2.1.</span> <span class="nav-text">代表技术之一 word2vec</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Skip-gram模型（跳字模型）："><span class="nav-number">2.2.</span> <span class="nav-text">Skip-gram模型（跳字模型）：</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#求梯度过程"><span class="nav-number">2.2.0.1.</span> <span class="nav-text">求梯度过程</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CBOW-连续词袋模型"><span class="nav-number">2.2.1.</span> <span class="nav-text">CBOW(连续词袋模型)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#近似训练法"><span class="nav-number">3.</span> <span class="nav-text">近似训练法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-负采样（Negative-Sample）"><span class="nav-number">3.1.</span> <span class="nav-text">(1)负采样（Negative Sample）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-层序softmax"><span class="nav-number">3.2.</span> <span class="nav-text">(2)层序softmax[]</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#SVD"><span class="nav-number">4.</span> <span class="nav-text">SVD</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#GloVe算法-基于局部和全局"><span class="nav-number">5.</span> <span class="nav-text">GloVe算法-基于局部和全局</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="site-author-image" itemprop="image" alt="Yuan"
    src="/images/pic03.jpg">
  <p class="site-author-name" itemprop="name">Yuan</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">20</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/liyuan97" title="GitHub &amp;rarr; https:&#x2F;&#x2F;github.com&#x2F;liyuan97" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:lysysu@qq.com" title="E-Mail &amp;rarr; mailto:lysysu@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title">
      <i class="fa fa-fw fa-link"></i>
      Friends Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="http://www.yelbee.top/" title="http:&#x2F;&#x2F;www.yelbee.top&#x2F;" rel="noopener" target="_blank">Yellow Bee</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://blog.dlzhang.com/" title="https:&#x2F;&#x2F;blog.dlzhang.com" rel="noopener" target="_blank">班班碎碎念</a>
        </li>
    </ul>
  </div>

      </div>
      
      <div style="">
  <canvas id="canvas" style="width:60%;">当前浏览器不支持canvas，请更换浏览器后再试</canvas>
</div>
<script>
(function(){

   var digit=
    [
        [
            [0,0,1,1,1,0,0],
            [0,1,1,0,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,0,1,1,0],
            [0,0,1,1,1,0,0]
        ],//0
        [
            [0,0,0,1,1,0,0],
            [0,1,1,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [1,1,1,1,1,1,1]
        ],//1
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,0,0,0],
            [0,1,1,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,0,0,0,1,1],
            [1,1,1,1,1,1,1]
        ],//2
        [
            [1,1,1,1,1,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,1,1,0],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//3
        [
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,1,0],
            [0,0,1,1,1,1,0],
            [0,1,1,0,1,1,0],
            [1,1,0,0,1,1,0],
            [1,1,1,1,1,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,1,1]
        ],//4
        [
            [1,1,1,1,1,1,1],
            [1,1,0,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,1,1,1,1,0],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//5
        [
            [0,0,0,0,1,1,0],
            [0,0,1,1,0,0,0],
            [0,1,1,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,0,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//6
        [
            [1,1,1,1,1,1,1],
            [1,1,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0]
        ],//7
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//8
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,1,1,0,0,0,0]
        ],//9
        [
            [0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0],
            [0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0]
        ]//:
    ];

var canvas = document.getElementById('canvas');

if(canvas.getContext){
    var cxt = canvas.getContext('2d');
    //声明canvas的宽高
    var H = 100,W = 700;
    canvas.height = H;
    canvas.width = W;
    cxt.fillStyle = '#f00';
    cxt.fillRect(10,10,50,50);

    //存储时间数据
    var data = [];
    //存储运动的小球
    var balls = [];
    //设置粒子半径
    var R = canvas.height/20-1;
    (function(){
        var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
        //存储时间数字，由十位小时、个位小时、冒号、十位分钟、个位分钟、冒号、十位秒钟、个位秒钟这7个数字组成
        data.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
    })();

    /*生成点阵数字*/
    function renderDigit(index,num){
        for(var i = 0; i < digit[num].length; i++){
            for(var j = 0; j < digit[num][i].length; j++){
                if(digit[num][i][j] == 1){
                    cxt.beginPath();
                    cxt.arc(14*(R+2)*index + j*2*(R+1)+(R+1),i*2*(R+1)+(R+1),R,0,2*Math.PI);
                    cxt.closePath();
                    cxt.fill();
                }
            }
        }
    }

    /*更新时钟*/
    function updateDigitTime(){
        var changeNumArray = [];
        var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
        var NewData = [];
        NewData.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
        for(var i = data.length-1; i >=0 ; i--){
            //时间发生变化
            if(NewData[i] !== data[i]){
                //将变化的数字值和在data数组中的索引存储在changeNumArray数组中
                changeNumArray.push(i+'_'+(Number(data[i])+1)%10);
            }
        }
        //增加小球
        for(var i = 0; i< changeNumArray.length; i++){
            addBalls.apply(this,changeNumArray[i].split('_'));
        }
        data = NewData.concat();
    }

    /*更新小球状态*/
    function updateBalls(){
        for(var i = 0; i < balls.length; i++){
            balls[i].stepY += balls[i].disY;
            balls[i].x += balls[i].stepX;
            balls[i].y += balls[i].stepY;
            if(balls[i].x > W + R || balls[i].y > H + R){
                balls.splice(i,1);
                i--;
            }
        }
    }

    /*增加要运动的小球*/
    function addBalls(index,num){
        var numArray = [1,2,3];
        var colorArray =  ["#3BE","#09C","#A6C","#93C","#9C0","#690","#FB3","#F80","#F44","#C00"];
        for(var i = 0; i < digit[num].length; i++){
            for(var j = 0; j < digit[num][i].length; j++){
                if(digit[num][i][j] == 1){
                    var ball = {
                        x:14*(R+2)*index + j*2*(R+1)+(R+1),
                        y:i*2*(R+1)+(R+1),
                        stepX:Math.floor(Math.random() * 4 -2),
                        stepY:-2*numArray[Math.floor(Math.random()*numArray.length)],
                        color:colorArray[Math.floor(Math.random()*colorArray.length)],
                        disY:1
                    };
                    balls.push(ball);
                }
            }
        }
    }

    /*渲染*/
    function render(){
        //重置画布宽度，达到清空画布的效果
        canvas.height = 100;
        //渲染时钟
        for(var i = 0; i < data.length; i++){
            renderDigit(i,data[i]);
        }
        //渲染小球
        for(var i = 0; i < balls.length; i++){
            cxt.beginPath();
            cxt.arc(balls[i].x,balls[i].y,R,0,2*Math.PI);
            cxt.fillStyle = balls[i].color;
            cxt.closePath();
            cxt.fill();
        }
    }

    clearInterval(oTimer);
    var oTimer = setInterval(function(){
        //更新时钟
        updateDigitTime();
        //更新小球状态
        updateBalls();
        //渲染
        render();
    },50);
}

})();
</script>

      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        
<div class="copyright">
  
  &copy; 2019 – 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yuan</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">54k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">50 分钟</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://gemini.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>












        
      </div>
    </footer>
  </div>

  
  
  <script color='255,140,0' opacity='1' zIndex='-1' count='99' src="//cdn.jsdelivr.net/gh/theme-next/theme-next-canvas-nest@latest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/pisces.js"></script>
<script src="/js/next-boot.js"></script>



  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>






  <script src="/js/local-search.js"></script>














  

<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>



  

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css"/>



<script src="//cdn.jsdelivr.net/npm/js-md5@0.7.3/src/md5.min.js"></script>

<script>
  var gitalk = new Gitalk({
    clientID: '6e0e8cda3de0989d1085',
    clientSecret: '3cb5f9a7db98cf1fb0204f8ef83de99e8be2eb66',
    repo: 'liyuan97.github.io',
    owner: 'liyuan97',
    admin: ['liyuan97'],
    id: md5(location.pathname),
    
      language: 'zh-CN',
    
    distractionFreeMode: 'true'
  });
  gitalk.render('gitalk-container');
</script>

  

  
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  

  


  

<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>



  

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css"/>



<script src="//cdn.jsdelivr.net/npm/js-md5@0.7.3/src/md5.min.js"></script>

<script>
  var gitalk = new Gitalk({
    clientID: '6e0e8cda3de0989d1085',
    clientSecret: '3cb5f9a7db98cf1fb0204f8ef83de99e8be2eb66',
    repo: 'liyuan97.github.io',
    owner: 'liyuan97',
    admin: ['liyuan97'],
    id: md5(location.pathname),
    
      language: 'zh-CN',
    
    distractionFreeMode: 'true'
  });
  gitalk.render('gitalk-container');
</script>

<script src="/js/friends.js"></script>

</body>
</html>
