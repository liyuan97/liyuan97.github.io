<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200228121032.png">
  <link rel="icon" type="image/png" sizes="32x32" href="https://s2.ax1x.com/2020/02/28/3B0ldI.md.jpg">
  <link rel="icon" type="image/png" sizes="16x16" href="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200228121032.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">
  <meta name="google-site-verification" content="true">
  <meta name="msvalidate.01" content="true">
  <meta name="yandex-verification" content="true">
  <meta name="baidu-site-verification" content="true">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css?family=Lato:300,300italic,400,400italic,700,700italic|Long Cang:300,300italic,400,400italic,700,700italic|Noto Serif SC:300,300italic,400,400italic,700,700italic|Source Code Pro:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.4.2',
    exturl: false,
    sidebar: {"position":"left","display":"always","offset":12,"onmobile":false},
    copycode: {"enable":true,"show_result":true,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":true},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: true,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="skorch是基于pytorch的外部工具，集成了很多基础功能，使得训练过程变得异常简单。一个net.fit()就能搞定。本次是MSBD5002的第二次作业，作业要求用MLP实现二分类和多分类的任务。多分类其实是对于图片分类，所以我也照着MNIST的CNNdemo改了个CNN的模型，CNN效果会好一点。但是由于数据集本身的原因，准确率没能上90%。">
<meta name="keywords" content="机器学习">
<meta property="og:type" content="article">
<meta property="og:title" content="pytorch再接触">
<meta property="og:url" content="http:&#x2F;&#x2F;leeee.top&#x2F;2020&#x2F;pytorch2&#x2F;index.html">
<meta property="og:site_name" content="元哥的日记">
<meta property="og:description" content="skorch是基于pytorch的外部工具，集成了很多基础功能，使得训练过程变得异常简单。一个net.fit()就能搞定。本次是MSBD5002的第二次作业，作业要求用MLP实现二分类和多分类的任务。多分类其实是对于图片分类，所以我也照着MNIST的CNNdemo改了个CNN的模型，CNN效果会好一点。但是由于数据集本身的原因，准确率没能上90%。">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200415172243.png?x-oss-process=image&#x2F;auto-orient,1&#x2F;quality,q_90&#x2F;format,jpg#center">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200417005311.png?x-oss-process=image&#x2F;auto-orient,1&#x2F;quality,q_90&#x2F;format,jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200416195751.png?x-oss-process=image&#x2F;auto-orient,1&#x2F;quality,q_90&#x2F;format,jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200417202326.png?x-oss-process=image&#x2F;auto-orient,1&#x2F;quality,q_90&#x2F;format,jpg =500x400">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200417014003.png?x-oss-process=image&#x2F;auto-orient,1&#x2F;quality,q_90&#x2F;format,jpg">
<meta property="og:updated_time" content="2020-04-17T13:59:31.616Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200415172243.png?x-oss-process=image&#x2F;auto-orient,1&#x2F;quality,q_90&#x2F;format,jpg#center">

<link rel="canonical" href="http://leeee.top/2020/pytorch2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>pytorch再接触 | 元哥的日记</title>
  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?567d405f5ec7479a4e2944724d8c336f";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">元哥的日记</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <h1 class="site-subtitle" itemprop="description">终其一生，我们只不过在寻找自己</h1>
      
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/#/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-所有文章">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>所有文章</a>

  </li>
        <li class="menu-item menu-item-标签">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-关于我">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于我</a>

  </li>
        <li class="menu-item menu-item-分类">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        
            
  <li class="menu-item menu-item-更多">

    <a href="/more/" rel="section"><i class="fa fa-fw fa-share"></i>更多</a>

  </li>


      
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://leeee.top/2020/pytorch2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200228120904.jpg">
      <meta itemprop="name" content="Yuan">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="元哥的日记">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          pytorch再接触
        </h2>

        <div class="post-meta">

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2020-04-17 21:51:00 / 修改时间：21:59:31" itemprop="dateCreated datePublished" datetime="2020-04-17T21:51:00+08:00">2020-04-17</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/pytorch/" itemprop="url" rel="index"><span itemprop="name">pytorch</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>11k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>10 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>skorch是基于pytorch的外部工具，集成了很多基础功能，使得训练过程变得异常简单。一个net.fit()就能搞定。<br>本次是MSBD5002的第二次作业，作业要求用MLP实现二分类和多分类的任务。多分类其实是对于图片分类，所以我也照着MNIST的CNNdemo改了个CNN的模型，CNN效果会好一点。但是由于数据集本身的原因，准确率没能上90%。</p><a id="more"></a>
<blockquote>
<p>记录一下过程，仅供参考。以下正文。</p>
</blockquote>
<hr>
<h1 id="Neural-Networks-Models-for-Binary-Classifcation-Data-Sets"><a href="#Neural-Networks-Models-for-Binary-Classifcation-Data-Sets" class="headerlink" title="Neural Networks Models for Binary Classifcation Data Sets"></a>Neural Networks Models for Binary Classifcation Data Sets</h1><h2 id="Define-the-network"><a href="#Define-the-network" class="headerlink" title="Define the network"></a>Define the network</h2><p>For first task we need to set of single hidden layer neural network models, and I choice stochastic gradient descent algorithm by minimizing the cross-entropy loss. By use PyTorch, it’s pretty easy to define my own network jusk as<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net_1hidden</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, n_feature, n_hidden, n_output=<span class="number">2</span>)</span>:</span></span><br><span class="line">        super(Net_1hidden, self).__init__()</span><br><span class="line">        self.hidden = torch.nn.Linear(n_feature, n_hidden)   <span class="comment"># hidden layer</span></span><br><span class="line">        self.out = torch.nn.Linear(n_hidden, n_output)   <span class="comment"># output layer</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = Fun.relu(self.hidden(x))      <span class="comment"># activation function for hidden layer we choose sigmoid</span></span><br><span class="line">        x = F.softmax(self.out(x), dim=<span class="number">-1</span>)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><br>For this net both <code>n_feature</code> and <code>n_hidden</code> are needed to be given a parameter.  <code>n_feature</code> depends on the feature of X, and <code>n_hidden</code> are needed to be be choice by cross validation.<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200415172243.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg#center">  </p>
<h2 id="Build-the-pipeline"><a href="#Build-the-pipeline" class="headerlink" title="Build the pipeline"></a>Build the pipeline</h2><p>To make the train process easier, it’s better to build a hole pipeline include the read data, split the data into different parts and shuffle the data to make the model more stable.<br>So I used scikit-learn compatible neural network library that wraps PyTorch. The goal of skorch is to make it possible to use PyTorch with sklearn. This is achieved by providing a wrapper around PyTorch that has an sklearn interface. In that sense, skorch is the spiritual successor to nolearn, but instead of using Lasagne and Theano, it uses PyTorch.<br>So it’s easy to fit the model by <code>net.fit(train_X,train_Y)</code>.</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> skorch <span class="keyword">import</span> NeuralNetClassifier</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_data</span><span class="params">(filename)</span>:</span></span><br><span class="line">    data = np.load(<span class="string">'./datasets/bi-class/'</span>+filename)</span><br><span class="line">    train_X,test_X = torch.FloatTensor(data[<span class="string">'train_X'</span>]),torch.FloatTensor(data[<span class="string">'test_X'</span>])</span><br><span class="line">    train_Y,test_Y = torch.LongTensor(data[<span class="string">'train_Y'</span>]),torch.LongTensor(data[<span class="string">'test_Y'</span>])</span><br><span class="line">    print(<span class="string">'\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;'</span>+filename,data[<span class="string">'train_X'</span>].shape,data[<span class="string">'test_X'</span>].shape)</span><br><span class="line">    <span class="keyword">return</span> train_X,test_X,train_Y,test_Y</span><br><span class="line"></span><br><span class="line">net = NeuralNetClassifier(</span><br><span class="line">        Net_1hidden(n_feature=n_feature, n_hidden=<span class="number">10</span>, n_output=<span class="number">2</span>),</span><br><span class="line">        max_epochs=<span class="number">20</span>,</span><br><span class="line">        lr=<span class="number">0.1</span>,</span><br><span class="line">        optimizer=torch.optim.SGD,</span><br><span class="line">        criterion=torch.nn.CrossEntropyLoss,</span><br><span class="line">        iterator_train__shuffle=<span class="literal">True</span>,</span><br><span class="line">        )</span><br><span class="line">net.fit(train_X,train_Y)</span><br></pre></td></tr></table></figure>
<p>To make the program more clear, I just choice max_epochs is 20 which by test several times. And I didn’t use early stopping tech because all dataset is small enough and doesn’t need too much time to train.</p>
<h2 id="Cross-validation-to-find-best-parameter"><a href="#Cross-validation-to-find-best-parameter" class="headerlink" title="Cross validation to find best parameter"></a>Cross validation to find best parameter</h2><p>In the assignment description, we needed to find the best hidden units H for each dataset. So I used the <code>GridSearchCV</code> from <code>sklearn</code>. GridSearchCV implements a “fit” and a “score” method. It also implements “predict”, “predict_proba”, “decision_function”, “transform” and “inverse_transform” if they are implemented in the estimator used.Which is very useful for search best parameter. The <code>NeuralNet</code> class allows to directly access parameters of the <code>pytorch module</code> by using the <code>module__</code> prefix.</p>
<p>For each dataset, it is done by randomly sampling 80% of the training instances to train a classifier and then testing it on the remaining 20%. Which means 5-flods.<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">params = &#123;<span class="string">'module__n_hidden'</span>: [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>],&#125;</span><br><span class="line">gs = GridSearchCV(net, params, refit=<span class="literal">False</span>, cv=<span class="number">5</span>, scoring=<span class="string">'accuracy'</span>)</span><br></pre></td></tr></table></figure><br>By this two function we can find best number of hidden between 1 to 10.</p>
<p>After train process and I find the best value is:</p>
<script type="math/tex; mode=display">
\begin{array}{cc}
\text { filename }& \text { best n value }  \\
diabetes.npz& 8\\
breast\_cancer.npz& 10\\
iris.npz& 10\\
wine.npz& 1\\
digit.npz& 8\\
\end{array}</script><p>It’s weird for <code>wine.npz</code>‘s best hidden number is 1. And I will discuss it on next part.</p>
<h2 id="All-result"><a href="#All-result" class="headerlink" title="All result"></a>All result</h2><p>On all five dataset, we can see the model performance as follows .</p>
<p> filename          | N | train_acc | test_acc | test_AUC | train_time |<br>|—————————-|——————-|—————-|—————|—————|——————|<br>| diabetes.npz      | 8           | 0.652     | 0.647    | 0.500    | 0.725      |<br>| breast-cancer.npz | 10          | 0.952     | 0.963    | 0.957    | 0.568      |<br>| iris.npz          | 10          | 1.000     | 1.000    | 1.000    | 0.214      |<br>| wine.npz          | 1           | 0.401     | 0.389    | 0.500    | 0.244      |<br>| digit.npz         | 8           | 0.959     | 0.935    | 0.939    | 0.833      |</p>
<p>As we can see, more hidden unit means more train time, because it need more computing .<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200417005311.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>Model performance well on <code>breast-cancer</code>, <code>iris.npz</code>, <code>digit.npz</code>.But for the <code>diabetes.npz</code> and <code>wine.npz</code> the model seems not work. There are several reasons for this problem. </p>
<ol>
<li>The feature and label of  dataset is meaningless.</li>
<li>The model is underfitting, because the epoch is only 20.</li>
<li>The model is too easy and con’t get the relationship.</li>
</ol>
<p>For find the reason, i try 2 hidden layers and add more epoch.<br>And the train result like follows:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;diabetes.npz (615, 8) (153, 8)</span><br><span class="line">1layer</span><br><span class="line">epoch:   0, loss: 0.716,accuracy: 0.346</span><br><span class="line">epoch: 100, loss: 0.664,accuracy: 0.647</span><br><span class="line">epoch: 200, loss: 0.644,accuracy: 0.647</span><br><span class="line">epoch: 300, loss: 0.635,accuracy: 0.647</span><br><span class="line">epoch: 400, loss: 0.631,accuracy: 0.647</span><br><span class="line">epoch: 500, loss: 0.628,accuracy: 0.647</span><br><span class="line">2layer</span><br><span class="line">epoch:   0, loss: 0.706,accuracy: 0.353</span><br><span class="line">epoch: 100, loss: 0.689,accuracy: 0.647</span><br><span class="line">epoch: 200, loss: 0.676,accuracy: 0.647</span><br><span class="line">epoch: 300, loss: 0.668,accuracy: 0.647</span><br><span class="line">epoch: 400, loss: 0.661,accuracy: 0.647</span><br><span class="line">epoch: 500, loss: 0.657,accuracy: 0.647</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;wine.npz (142, 13) (36, 13)</span><br><span class="line">1layer</span><br><span class="line">epoch:   0, loss: 0.912,accuracy: 0.389</span><br><span class="line">epoch: 100, loss: 0.912,accuracy: 0.389</span><br><span class="line">epoch: 200, loss: 0.912,accuracy: 0.389</span><br><span class="line">epoch: 300, loss: 0.912,accuracy: 0.389</span><br><span class="line">epoch: 400, loss: 0.912,accuracy: 0.389</span><br><span class="line">epoch: 500, loss: 0.912,accuracy: 0.389</span><br><span class="line">2layer</span><br><span class="line">epoch:   0, loss: 0.912,accuracy: 0.389</span><br><span class="line">epoch: 100, loss: 0.912,accuracy: 0.389</span><br><span class="line">epoch: 200, loss: 0.912,accuracy: 0.389</span><br><span class="line">epoch: 300, loss: 0.912,accuracy: 0.389</span><br><span class="line">epoch: 400, loss: 0.912,accuracy: 0.389</span><br><span class="line">epoch: 500, loss: 0.912,accuracy: 0.389</span><br></pre></td></tr></table></figure><br>As we can see, no matter how many epoch and how many layers for this two dataset. The model all don’t work. So I think it is the first reason. The feature and label of  dataset is meaningless.</p>
<h1 id="Neural-Networks-Models-for-Multi-class-Data-Sets"><a href="#Neural-Networks-Models-for-Multi-class-Data-Sets" class="headerlink" title="Neural Networks Models for Multi-class Data Sets"></a>Neural Networks Models for Multi-class Data Sets</h1><h2 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h2><p>For this dataset, we have train with 10000 image, and test with 1000 image. And the label is 0-9,  ten different classes. For each image, it is a 784 dimensions array, which can convert to 28*28 Square picture.<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200416195751.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<p>As we can see, there are some shoes, clothes, skirts, T-Shirts and each one class represent one number between 0-9.</p>
<h2 id="Build-a-2-hidden-layers-net"><a href="#Build-a-2-hidden-layers-net" class="headerlink" title="Build a 2 hidden layers net"></a>Build a 2 hidden layers net</h2><p>By use pytorch, it’s pretty easy to define a network. Again I still use relu as activate function, CrossEntropy as loss function. And I define the input feature is a flatten array with 784, and output layer is 10 which equal to the class number.<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net_2hidden</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, n_hidden1,  n_hidden2, n_output = <span class="number">10</span>, n_feature = <span class="number">784</span>)</span>:</span></span><br><span class="line">        super(Net_2hidden, self).__init__()</span><br><span class="line">        self.hidden1 = torch.nn.Linear(n_feature, n_hidden1)</span><br><span class="line">        self.hidden2 = torch.nn.Linear(n_hidden1, n_hidden2)</span><br><span class="line">        self.out = torch.nn.Linear(n_hidden2, n_output)   <span class="comment"># output layer</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x1 = Fun.relu(self.hidden1(x))</span><br><span class="line">        x2 = Fun.relu(self.hidden2(x1))</span><br><span class="line">        x =  self.out(x2)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><br>And then I use GridSearchCV to try different number of hidden units. And also I used cross validation (randomly sampling 80% of the training instances to train a classifier and then testing it on the remaining 20%). I set the max epochs is 30 for all dataset. And this time I used Adma instead of SGD. Because by experiment,  Adma is faster than SGD to convergence.<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line">net = NeuralNetClassifier(</span><br><span class="line">        Net_2hidden(n_hidden1=<span class="number">500</span>, n_hidden2=<span class="number">100</span>),</span><br><span class="line">        max_epochs=<span class="number">30</span>,</span><br><span class="line">        lr=<span class="number">0.001</span>,</span><br><span class="line">        optimizer=torch.optim.Adam,<span class="comment">#torch.optim.SGD,</span></span><br><span class="line">        criterion=torch.nn.CrossEntropyLoss,</span><br><span class="line">        iterator_train__shuffle=<span class="literal">True</span>,</span><br><span class="line">        )</span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">'module__n_hidden1'</span>: [<span class="number">50</span>,<span class="number">75</span>,<span class="number">100</span>],<span class="comment">#,500],</span></span><br><span class="line">    <span class="string">'module__n_hidden2'</span>: [<span class="number">10</span>,<span class="number">15</span>,<span class="number">20</span>],<span class="comment">#100]</span></span><br><span class="line">&#125;</span><br><span class="line">gs = GridSearchCV(net, params, refit=<span class="literal">False</span>, cv=<span class="number">5</span>, scoring=<span class="string">'accuracy'</span>)</span><br><span class="line">train_X,train_Y = torch.FloatTensor(train_images),torch.LongTensor(train_labels)</span><br><span class="line">gs.fit(train_X,train_Y)</span><br><span class="line">print(gs.best_score_, gs.best_params_)</span><br></pre></td></tr></table></figure><br>After <code>10 minutes</code> train and test, GridSearchCV get the best params with <code>{&#39;module__n_hidden1&#39;: 75, &#39;module__n_hidden2&#39;: 20}</code>.<br>I was surprised to see that the first layer was 75 instead of 100, because in general, the larger the number of cells or the closer to the input layer model, the better the performance. After many experiments, I have come to a conclusion. The first hidden layer is 75 instead of 100, mainly because the largest parameter of the second hidden layer is 20, and the span before 100 to 20 is too large, which may cause too much loss here. Therefore, for the latter layer is 20 units, the first layer chooses 75 units to perform better.</p>
<p>And the final model get the <code>accuracy with 84%</code> on the 1000 test dataset. For each class, the accuracy as follows.<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">       <span class="class"><span class="keyword">class</span>    <span class="title">precision</span>    <span class="title">recall</span>  <span class="title">f1</span>-<span class="title">score</span>   <span class="title">support</span></span></span><br><span class="line"><span class="class">           0       0.78      0.78      0.78       107</span></span><br><span class="line"><span class="class">           1       0.93      0.95      0.94       105</span></span><br><span class="line"><span class="class">           2       0.78      0.82      0.80       111</span></span><br><span class="line"><span class="class">           3       0.78      0.75      0.77        93</span></span><br><span class="line"><span class="class">           4       0.74      0.80      0.77       115</span></span><br><span class="line"><span class="class">           5       0.93      0.90      0.91        87</span></span><br><span class="line"><span class="class">           6       0.63      0.56      0.59        97</span></span><br><span class="line"><span class="class">           7       0.91      0.95      0.93        95</span></span><br><span class="line"><span class="class">           8       0.97      0.93      0.95        95</span></span><br><span class="line"><span class="class">           9       0.94      0.93      0.93        95</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">    <span class="title">accuracy</span>                           0.83      1000</span></span><br><span class="line"><span class="class">   <span class="title">macro</span> <span class="title">avg</span>       0.84      0.84      0.84      1000</span></span><br><span class="line"><span class="class"><span class="title">weighted</span> <span class="title">avg</span>       0.83      0.83      0.83      1000</span></span><br></pre></td></tr></table></figure><br>As we can see, the class 6 get the lowest accuracy.</p>
<h2 id="Improve-build-CNN-net"><a href="#Improve-build-CNN-net" class="headerlink" title="Improve: build CNN net"></a>Improve: build CNN net</h2><p>As we know, CNN make a good performance on image. So I try a 3<em>3 CNN model, try to improve the performance  of model.<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Cnn</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, dropout=<span class="number">0.4</span>)</span>:</span></span><br><span class="line">        super(Cnn, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">32</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>)</span><br><span class="line">        self.conv2_drop = nn.Dropout2d(p=dropout)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">1600</span>, <span class="number">800</span>) <span class="comment"># 1600 = number channels * width * height</span></span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">800</span>, <span class="number">10</span>)</span><br><span class="line">        self.fc1_drop = nn.Dropout(p=dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = torch.relu(F.max_pool2d(self.conv1(x), <span class="number">2</span>))</span><br><span class="line">        x = torch.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), <span class="number">2</span>))</span><br><span class="line">        <span class="comment"># flatten over channel, height and width = 1600</span></span><br><span class="line">        x = x.view(<span class="number">-1</span>, x.size(<span class="number">1</span>) * x.size(<span class="number">2</span>) * x.size(<span class="number">3</span>))</span><br><span class="line">        x = self.fc1_drop(torch.relu(self.fc1(x)))</span><br><span class="line">        x = torch.softmax(self.fc2(x), dim=<span class="number">-1</span>)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><br>After many attempts, I chose <code>max_epics = 200</code>, the <code>learning rate is 0.0005</code>, and the <code>optimizer is Adam.</code> The internal parameters of the model have been fixed after several attempts. In the end, <em>*88.8% of the accuracy</em></em> is obtained in 1000 test sets.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">  epoch    train_loss    valid_acc    valid_loss     dur</span><br><span class="line">-------  ------------  -----------  ------------  ------</span><br><span class="line">      1        5.0852       0.7520        0.9469  0.3805</span><br><span class="line">     50        0.1847       0.8795        0.3360  0.3779</span><br><span class="line">    100        0.0694       0.8860        0.3733  0.3614</span><br><span class="line">    150        0.0336       0.8855        0.4257  0.3691</span><br><span class="line">    200        0.0175       0.8865        0.4704  0.3666</span><br><span class="line">Accuracy on test: 0.888</span><br></pre></td></tr></table></figure><br>Again I compute the accuracy for each class.<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">        <span class="class"><span class="keyword">class</span>  <span class="title">precision</span>    <span class="title">recall</span>  <span class="title">f1</span>-<span class="title">score</span>   <span class="title">support</span></span></span><br><span class="line"><span class="class">           0       0.91      0.80      0.85       107</span></span><br><span class="line"><span class="class">           1       0.99      0.99      0.99       105</span></span><br><span class="line"><span class="class">           2       0.82      0.84      0.83       111</span></span><br><span class="line"><span class="class">           3       0.91      0.85      0.88        93</span></span><br><span class="line"><span class="class">           4       0.85      0.85      0.85       115</span></span><br><span class="line"><span class="class">           5       0.93      0.95      0.94        87</span></span><br><span class="line"><span class="class">           6       0.66      0.75      0.71        97</span></span><br><span class="line"><span class="class">           7       0.92      0.97      0.94        95</span></span><br><span class="line"><span class="class">           8       0.97      0.97      0.97        95</span></span><br><span class="line"><span class="class">           9       0.98      0.93      0.95        95</span></span><br><span class="line"><span class="class">           </span></span><br><span class="line"><span class="class">    <span class="title">accuracy</span>                           0.89      1000</span></span><br><span class="line"><span class="class">   <span class="title">macro</span> <span class="title">avg</span>       0.89      0.89      0.89      1000</span></span><br><span class="line"><span class="class"><span class="title">weighted</span> <span class="title">avg</span>       0.89      0.89      0.89      1000</span></span><br></pre></td></tr></table></figure><br>As we can see, still for the class 6 it’s hard to classify, only 66% accuracy.</p>
<h2 id="Compare-CNN-and-MLP"><a href="#Compare-CNN-and-MLP" class="headerlink" title="Compare CNN and MLP"></a>Compare CNN and MLP</h2><p>By  tensorboard, we can intuitively compare the loss trends of the two models. When I set the maximum number of iterations of both models to 50, the MLP of the two layers decreased significantly faster in terms of training loss, but in the loss of the test set, the MLP of the two layers first decreased and then increased. Fitted. So the optimal number of iterations for two-layer MLP is around 10 words.<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200417202326.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg =500x400"></p>
<p>For the CNN model, because I added the characteristics of the Dropout layer and the CNN model itself, the iteration of the model to 50 layers is still in a decline in loss, and the accuracy of the verification set is increasing.</p>
<h2 id="Error-analysis-and-Optimization-direction"><a href="#Error-analysis-and-Optimization-direction" class="headerlink" title="Error analysis and Optimization direction"></a>Error analysis and Optimization direction</h2><p>In order to further study why it is wrong, I printed out a sample of prediction errors. I chose the most representative group to explain. </p>
<p>In the picture, we can see that these six pictures are all shoes, and their classification also belongs to [5,7,9].<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200417014003.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>The prediction range is also [5,7,9], but the model does not find the difference between shoes. To be honest, it’s hard for the naked eye to see the obvious difference between [5,7,9]. Therefore, it’s understandable that the model is not clear.</p>
<p>For the above question, I think we can use the <strong><em>hierarchical prediction method</em></strong>. For example, train a model to distinguish whether shoes or clothes are needed. Then train a model for shoes to capture the subtle differences between shoes. In this way, I think the accuracy can be further improved.</p>

    </div>

    
    
    
      
  <div class="popular-posts-header">相似文章</div>
  <ul class="popular-posts">
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/2020/Q音算法实习复盘/" rel="bookmark">Q音算法实习复盘</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/2020/pytorch1/" rel="bookmark">pytorch初体验</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/2019/【机器学习】集成学习GDBT-XGBOOST-RF/" rel="bookmark">集成学习GDBT,XGBOOST,RF</a></div>
    </li>
  </ul>


      <div>
      
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------　　　　本文结束　<i class="fa fa-heart"></i>　感谢您的阅读　　　　-------------</div>
      
      </div>

      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"><i class="fa fa-tag"></i> 机器学习</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
                <a href="/2020/pytorch1/" rel="next" title="pytorch初体验">
                  <i class="fa fa-chevron-left"></i> pytorch初体验
                </a>
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
            </div>
          </div>
      </footer>
    
  </article>

  
  
  

  </div>


          </div>
          
    <div class="comments" id="gitalk-container"></div>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Neural-Networks-Models-for-Binary-Classifcation-Data-Sets"><span class="nav-number">1.</span> <span class="nav-text">Neural Networks Models for Binary Classifcation Data Sets</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Define-the-network"><span class="nav-number">1.1.</span> <span class="nav-text">Define the network</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Build-the-pipeline"><span class="nav-number">1.2.</span> <span class="nav-text">Build the pipeline</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Cross-validation-to-find-best-parameter"><span class="nav-number">1.3.</span> <span class="nav-text">Cross validation to find best parameter</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#All-result"><span class="nav-number">1.4.</span> <span class="nav-text">All result</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Neural-Networks-Models-for-Multi-class-Data-Sets"><span class="nav-number">2.</span> <span class="nav-text">Neural Networks Models for Multi-class Data Sets</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Dataset"><span class="nav-number">2.1.</span> <span class="nav-text">Dataset</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Build-a-2-hidden-layers-net"><span class="nav-number">2.2.</span> <span class="nav-text">Build a 2 hidden layers net</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Improve-build-CNN-net"><span class="nav-number">2.3.</span> <span class="nav-text">Improve: build CNN net</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Compare-CNN-and-MLP"><span class="nav-number">2.4.</span> <span class="nav-text">Compare CNN and MLP</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Error-analysis-and-Optimization-direction"><span class="nav-number">2.5.</span> <span class="nav-text">Error analysis and Optimization direction</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="site-author-image" itemprop="image" alt="Yuan"
    src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200228120904.jpg">
  <p class="site-author-name" itemprop="name">Yuan</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">31</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">28</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/liyuan97" title="GitHub &amp;rarr; https:&#x2F;&#x2F;github.com&#x2F;liyuan97" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:lysysu@qq.com" title="E-Mail &amp;rarr; mailto:lysysu@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title">
      <i class="fa fa-fw fa-link"></i>
      Friends Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="http://www.yelbee.top/" title="http:&#x2F;&#x2F;www.yelbee.top&#x2F;" rel="noopener" target="_blank">Yellow Bee</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://blog.dlzhang.com/" title="https:&#x2F;&#x2F;blog.dlzhang.com&#x2F;" rel="noopener" target="_blank">班班碎碎念</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://yiki.tech/" title="https:&#x2F;&#x2F;yiki.tech&#x2F;" rel="noopener" target="_blank">Guan FuQing</a>
        </li>
    </ul>
  </div>

      </div>
      
      <div style="">
  <canvas id="canvas" style="width:60%;">当前浏览器不支持canvas，请更换浏览器后再试</canvas>
</div>
<script>
(function(){

   var digit=
    [
        [
            [0,0,1,1,1,0,0],
            [0,1,1,0,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,0,1,1,0],
            [0,0,1,1,1,0,0]
        ],//0
        [
            [0,0,0,1,1,0,0],
            [0,1,1,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [1,1,1,1,1,1,1]
        ],//1
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,0,0,0],
            [0,1,1,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,0,0,0,1,1],
            [1,1,1,1,1,1,1]
        ],//2
        [
            [1,1,1,1,1,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,1,1,0],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//3
        [
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,1,0],
            [0,0,1,1,1,1,0],
            [0,1,1,0,1,1,0],
            [1,1,0,0,1,1,0],
            [1,1,1,1,1,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,1,1]
        ],//4
        [
            [1,1,1,1,1,1,1],
            [1,1,0,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,1,1,1,1,0],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//5
        [
            [0,0,0,0,1,1,0],
            [0,0,1,1,0,0,0],
            [0,1,1,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,0,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//6
        [
            [1,1,1,1,1,1,1],
            [1,1,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0]
        ],//7
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//8
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,1,1,0,0,0,0]
        ],//9
        [
            [0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0],
            [0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0]
        ]//:
    ];

var canvas = document.getElementById('canvas');

if(canvas.getContext){
    var cxt = canvas.getContext('2d');
    //声明canvas的宽高
    var H = 100,W = 700;
    canvas.height = H;
    canvas.width = W;
    cxt.fillStyle = '#f00';
    cxt.fillRect(10,10,50,50);

    //存储时间数据
    var data = [];
    //存储运动的小球
    var balls = [];
    //设置粒子半径
    var R = canvas.height/20-1;
    (function(){
        var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
        //存储时间数字，由十位小时、个位小时、冒号、十位分钟、个位分钟、冒号、十位秒钟、个位秒钟这7个数字组成
        data.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
    })();

    /*生成点阵数字*/
    function renderDigit(index,num){
        for(var i = 0; i < digit[num].length; i++){
            for(var j = 0; j < digit[num][i].length; j++){
                if(digit[num][i][j] == 1){
                    cxt.beginPath();
                    cxt.arc(14*(R+2)*index + j*2*(R+1)+(R+1),i*2*(R+1)+(R+1),R,0,2*Math.PI);
                    cxt.closePath();
                    cxt.fill();
                }
            }
        }
    }

    /*更新时钟*/
    function updateDigitTime(){
        var changeNumArray = [];
        var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
        var NewData = [];
        NewData.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
        for(var i = data.length-1; i >=0 ; i--){
            //时间发生变化
            if(NewData[i] !== data[i]){
                //将变化的数字值和在data数组中的索引存储在changeNumArray数组中
                changeNumArray.push(i+'_'+(Number(data[i])+1)%10);
            }
        }
        //增加小球
        for(var i = 0; i< changeNumArray.length; i++){
            addBalls.apply(this,changeNumArray[i].split('_'));
        }
        data = NewData.concat();
    }

    /*更新小球状态*/
    function updateBalls(){
        for(var i = 0; i < balls.length; i++){
            balls[i].stepY += balls[i].disY;
            balls[i].x += balls[i].stepX;
            balls[i].y += balls[i].stepY;
            if(balls[i].x > W + R || balls[i].y > H + R){
                balls.splice(i,1);
                i--;
            }
        }
    }

    /*增加要运动的小球*/
    function addBalls(index,num){
        var numArray = [1,2,3];
        var colorArray =  ["#3BE","#09C","#A6C","#93C","#9C0","#690","#FB3","#F80","#F44","#C00"];
        for(var i = 0; i < digit[num].length; i++){
            for(var j = 0; j < digit[num][i].length; j++){
                if(digit[num][i][j] == 1){
                    var ball = {
                        x:14*(R+2)*index + j*2*(R+1)+(R+1),
                        y:i*2*(R+1)+(R+1),
                        stepX:Math.floor(Math.random() * 4 -2),
                        stepY:-2*numArray[Math.floor(Math.random()*numArray.length)],
                        color:colorArray[Math.floor(Math.random()*colorArray.length)],
                        disY:1
                    };
                    balls.push(ball);
                }
            }
        }
    }

    /*渲染*/
    function render(){
        //重置画布宽度，达到清空画布的效果
        canvas.height = 100;
        //渲染时钟
        for(var i = 0; i < data.length; i++){
            renderDigit(i,data[i]);
        }
        //渲染小球
        for(var i = 0; i < balls.length; i++){
            cxt.beginPath();
            cxt.arc(balls[i].x,balls[i].y,R,0,2*Math.PI);
            cxt.fillStyle = balls[i].color;
            cxt.closePath();
            cxt.fill();
        }
    }

    clearInterval(oTimer);
    var oTimer = setInterval(function(){
        //更新时钟
        updateDigitTime();
        //更新小球状态
        updateBalls();
        //渲染
        render();
    },50);
}

})();
</script>

      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        
<div class="copyright">
  
  &copy; 2019 – 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yuan</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">98k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">1:29</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        本站访客数<span id="busuanzi_value_site_uv"></span>人次
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        本站总访问量<span id="busuanzi_value_site_pv"></span>次
      </span>
    </span>
</div>












        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/pisces.js"></script>
<script src="/js/next-boot.js"></script>



  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>






  <script src="/js/local-search.js"></script>














  

<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>



  

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css"/>



<script src="//cdn.jsdelivr.net/npm/js-md5@0.7.3/src/md5.min.js"></script>

<script>
  var gitalk = new Gitalk({
    clientID: '6e0e8cda3de0989d1085',
    clientSecret: '3cb5f9a7db98cf1fb0204f8ef83de99e8be2eb66',
    repo: 'liyuan97.github.io',
    owner: 'liyuan97',
    admin: ['liyuan97'],
    id: md5(location.pathname),
    
      language: 'zh-CN',
    
    distractionFreeMode: 'true'
  });
  gitalk.render('gitalk-container');
</script>

  

  

  

  


  

<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>



  

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css"/>



<script src="//cdn.jsdelivr.net/npm/js-md5@0.7.3/src/md5.min.js"></script>

<script>
  var gitalk = new Gitalk({
    clientID: '6e0e8cda3de0989d1085',
    clientSecret: '3cb5f9a7db98cf1fb0204f8ef83de99e8be2eb66',
    repo: 'liyuan97.github.io',
    owner: 'liyuan97',
    admin: ['liyuan97'],
    id: md5(location.pathname),
    
      language: 'zh-CN',
    
    distractionFreeMode: 'true'
  });
  gitalk.render('gitalk-container');
</script>

</body>
</html>
