<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200228121032.png">
  <link rel="icon" type="image/png" sizes="32x32" href="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200228121032.png">
  <link rel="icon" type="image/png" sizes="16x16" href="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200228121032.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">
  <meta name="google-site-verification" content="true">
  <meta name="msvalidate.01" content="true">
  <meta name="yandex-verification" content="true">
  <meta name="baidu-site-verification" content="true">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css?family=Lato:300,300italic,400,400italic,700,700italic|Long Cang:300,300italic,400,400italic,700,700italic|Noto Serif SC:300,300italic,400,400italic,700,700italic|Source Code Pro:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.4.2',
    exturl: false,
    sidebar: {"position":"left","display":"always","offset":12,"onmobile":false},
    copycode: {"enable":true,"show_result":true,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":true},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: true,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: 'å¤åˆ¶',
      copy_success: 'å¤åˆ¶æˆåŠŸ',
      copy_failure: 'å¤åˆ¶å¤±è´¥'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="æœ¬æ¬¡æ˜¯MSBD5002çš„ç¬¬äºŒæ¬¡ä½œä¸šï¼Œä½œä¸šè¦æ±‚ç”¨MLPå®ç°äºŒåˆ†ç±»å’Œå¤šåˆ†ç±»çš„ä»»åŠ¡ã€‚å¤šåˆ†ç±»å…¶å®æ˜¯å¯¹äºå›¾ç‰‡åˆ†ç±»ï¼Œæ‰€ä»¥æˆ‘ä¹Ÿç…§ç€MNISTçš„CNNdemoæ”¹äº†ä¸ªCNNçš„æ¨¡å‹ï¼ŒCNNæ•ˆæœä¼šå¥½ä¸€ç‚¹ã€‚ä½†æ˜¯ç”±äºæ•°æ®é›†æœ¬èº«çš„åŸå› ï¼Œå‡†ç¡®ç‡æ²¡èƒ½ä¸Š90%ã€‚">
<meta name="keywords" content="æœºå™¨å­¦ä¹ ">
<meta property="og:type" content="article">
<meta property="og:title" content="pytorchå†æ¥è§¦">
<meta property="og:url" content="http:&#x2F;&#x2F;leeee.top&#x2F;2020&#x2F;pytorch2&#x2F;index.html">
<meta property="og:site_name" content="å…ƒå“¥çš„æ—¥è®°">
<meta property="og:description" content="æœ¬æ¬¡æ˜¯MSBD5002çš„ç¬¬äºŒæ¬¡ä½œä¸šï¼Œä½œä¸šè¦æ±‚ç”¨MLPå®ç°äºŒåˆ†ç±»å’Œå¤šåˆ†ç±»çš„ä»»åŠ¡ã€‚å¤šåˆ†ç±»å…¶å®æ˜¯å¯¹äºå›¾ç‰‡åˆ†ç±»ï¼Œæ‰€ä»¥æˆ‘ä¹Ÿç…§ç€MNISTçš„CNNdemoæ”¹äº†ä¸ªCNNçš„æ¨¡å‹ï¼ŒCNNæ•ˆæœä¼šå¥½ä¸€ç‚¹ã€‚ä½†æ˜¯ç”±äºæ•°æ®é›†æœ¬èº«çš„åŸå› ï¼Œå‡†ç¡®ç‡æ²¡èƒ½ä¸Š90%ã€‚">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200415172243.png?x-oss-process=image&#x2F;auto-orient,1&#x2F;quality,q_90&#x2F;format,jpg#center">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200417005311.png?x-oss-process=image&#x2F;auto-orient,1&#x2F;quality,q_90&#x2F;format,jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200416195751.png?x-oss-process=image&#x2F;auto-orient,1&#x2F;quality,q_90&#x2F;format,jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200417202326.png?x-oss-process=image&#x2F;auto-orient,1&#x2F;quality,q_90&#x2F;format,jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200417014003.png?x-oss-process=image&#x2F;auto-orient,1&#x2F;quality,q_90&#x2F;format,jpg">
<meta property="og:updated_time" content="2020-04-22T16:57:03.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https:&#x2F;&#x2F;liyuanimage.oss-cn-beijing.aliyuncs.com&#x2F;img&#x2F;20200415172243.png?x-oss-process=image&#x2F;auto-orient,1&#x2F;quality,q_90&#x2F;format,jpg#center">

<link rel="canonical" href="http://leeee.top/2020/pytorch2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>pytorchå†æ¥è§¦ | å…ƒå“¥çš„æ—¥è®°</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-163973026-1"></script>
    <script>
      var host = window.location.hostname;
      if (host !== "localhost" || !true) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-163973026-1');
      }
    </script>


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?567d405f5ec7479a4e2944724d8c336f";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">å…ƒå“¥çš„æ—¥è®°</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <h1 class="site-subtitle" itemprop="description">ç»ˆå…¶ä¸€ç”Ÿï¼Œæˆ‘ä»¬åªä¸è¿‡åœ¨å¯»æ‰¾è‡ªå·±</h1>
      
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="åˆ‡æ¢å¯¼èˆªæ ">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/#/" rel="section"><i class="fa fa-fw fa-home"></i>é¦–é¡µ</a>

  </li>
        <li class="menu-item menu-item-æ‰€æœ‰æ–‡ç« ">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>æ‰€æœ‰æ–‡ç« </a>

  </li>
        <li class="menu-item menu-item-æ ‡ç­¾">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>æ ‡ç­¾</a>

  </li>
        <li class="menu-item menu-item-å…³äºæˆ‘">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>å…³äºæˆ‘</a>

  </li>
        <li class="menu-item menu-item-åˆ†ç±»">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>åˆ†ç±»</a>

  </li>
        <li class="menu-item menu-item-æ‚è®°">

    <a href="/categories/%E6%9D%82%E4%B9%B1%E6%97%A0%E7%AB%A0" rel="section"><i class="fa fa-fw fa-edit"></i>æ‚è®°</a>

  </li>
        
            
  <li class="menu-item menu-item-æ›´å¤š">

    <a href="/more/" rel="section"><i class="fa fa-fw fa-share"></i>æ›´å¤š</a>

  </li>


      
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>æœç´¢
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="æœç´¢..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://leeee.top/2020/pytorch2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200228120904.jpg">
      <meta itemprop="name" content="Yuan">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="å…ƒå“¥çš„æ—¥è®°">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          pytorchå†æ¥è§¦
        </h2>

        <div class="post-meta">

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">å‘è¡¨äº</span>

              <time title="åˆ›å»ºæ—¶é—´ï¼š2020-04-17 21:51:00" itemprop="dateCreated datePublished" datetime="2020-04-17T21:51:00+08:00">2020-04-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">æ›´æ–°äº</span>
                <time title="ä¿®æ”¹æ—¶é—´ï¼š2020-04-23 00:57:03" itemprop="dateModified" datetime="2020-04-23T00:57:03+08:00">2020-04-23</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">åˆ†ç±»äº</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/pytorch/" itemprop="url" rel="index"><span itemprop="name">pytorch</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="é˜…è¯»æ¬¡æ•°" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">é˜…è¯»æ¬¡æ•°ï¼š</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
            <span class="post-meta-item" title="æœ¬æ–‡å­—æ•°">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">æœ¬æ–‡å­—æ•°ï¼š</span>
              <span>11k</span>
            </span>
            <span class="post-meta-item" title="é˜…è¯»æ—¶é•¿">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">é˜…è¯»æ—¶é•¿ &asymp;</span>
              <span>10 åˆ†é’Ÿ</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>æœ¬æ¬¡æ˜¯MSBD5002çš„ç¬¬äºŒæ¬¡ä½œä¸šï¼Œä½œä¸šè¦æ±‚ç”¨MLPå®ç°äºŒåˆ†ç±»å’Œå¤šåˆ†ç±»çš„ä»»åŠ¡ã€‚å¤šåˆ†ç±»å…¶å®æ˜¯å¯¹äºå›¾ç‰‡åˆ†ç±»ï¼Œæ‰€ä»¥æˆ‘ä¹Ÿç…§ç€MNISTçš„CNNdemoæ”¹äº†ä¸ªCNNçš„æ¨¡å‹ï¼ŒCNNæ•ˆæœä¼šå¥½ä¸€ç‚¹ã€‚ä½†æ˜¯ç”±äºæ•°æ®é›†æœ¬èº«çš„åŸå› ï¼Œå‡†ç¡®ç‡æ²¡èƒ½ä¸Š90%ã€‚</p><a id="more"></a>
<p>é¢å¤–å¼•ç”¨äº†skorchã€‚skorchæ˜¯åŸºäºpytorchçš„å¤–éƒ¨å·¥å…·ï¼Œé›†æˆäº†å¾ˆå¤šåŸºç¡€åŠŸèƒ½ï¼Œä½¿å¾—è®­ç»ƒè¿‡ç¨‹å˜å¾—å¼‚å¸¸ç®€å•ã€‚ä¸€ä¸ªnet.fit()å°±èƒ½æå®šã€‚</p>
<blockquote>
<p>è®°å½•ä¸€ä¸‹è¿‡ç¨‹ï¼Œä»…ä¾›å‚è€ƒã€‚ä»¥ä¸‹æ­£æ–‡ã€‚</p>
</blockquote>
<hr>
<h1 id="Neural-Networks-Models-for-Binary-Classifcation-Data-Sets"><a href="#Neural-Networks-Models-for-Binary-Classifcation-Data-Sets" class="headerlink" title="Neural Networks Models for Binary Classifcation Data Sets"></a>Neural Networks Models for Binary Classifcation Data Sets</h1><h2 id="Define-the-network"><a href="#Define-the-network" class="headerlink" title="Define the network"></a>Define the network</h2><p>For first task we need to set of single hidden layer neural network models, and I choice stochastic gradient descent algorithm by minimizing the cross-entropy loss. By use PyTorch, itâ€™s pretty easy to define my own network jusk as<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net_1hidden</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, n_feature, n_hidden, n_output=<span class="number">2</span>)</span>:</span></span><br><span class="line">        super(Net_1hidden, self).__init__()</span><br><span class="line">        self.hidden = torch.nn.Linear(n_feature, n_hidden)   <span class="comment"># hidden layer</span></span><br><span class="line">        self.out = torch.nn.Linear(n_hidden, n_output)   <span class="comment"># output layer</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = Fun.relu(self.hidden(x))      <span class="comment"># activation function for hidden layer we choose rele</span></span><br><span class="line">        x = F.softmax(self.out(x), dim=<span class="number">-1</span>)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><br>For this net both <code>n_feature</code> and <code>n_hidden</code> are needed to be given a parameter.  <code>n_feature</code> depends on the feature of X, and <code>n_hidden</code> are needed to be be choice by cross validation.<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200415172243.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg#center">  </p>
<h2 id="Build-the-pipeline"><a href="#Build-the-pipeline" class="headerlink" title="Build the pipeline"></a>Build the pipeline</h2><p>To make the train process easier, itâ€™s better to build a hole pipeline include the read data, split the data into different parts and shuffle the data to make the model more stable.<br>So I used scikit-learn compatible neural network library that wraps PyTorch. The goal of skorch is to make it possible to use PyTorch with sklearn. This is achieved by providing a wrapper around PyTorch that has an sklearn interface. In that sense, skorch is the spiritual successor to nolearn, but instead of using Lasagne and Theano, it uses PyTorch.<br>So itâ€™s easy to fit the model by <code>net.fit(train_X,train_Y)</code>.</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> skorch <span class="keyword">import</span> NeuralNetClassifier</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_data</span><span class="params">(filename)</span>:</span></span><br><span class="line">    data = np.load(<span class="string">'./datasets/bi-class/'</span>+filename)</span><br><span class="line">    train_X,test_X = torch.FloatTensor(data[<span class="string">'train_X'</span>]),torch.FloatTensor(data[<span class="string">'test_X'</span>])</span><br><span class="line">    train_Y,test_Y = torch.LongTensor(data[<span class="string">'train_Y'</span>]),torch.LongTensor(data[<span class="string">'test_Y'</span>])</span><br><span class="line">    print(<span class="string">'\n&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;'</span>+filename,data[<span class="string">'train_X'</span>].shape,data[<span class="string">'test_X'</span>].shape)</span><br><span class="line">    <span class="keyword">return</span> train_X,test_X,train_Y,test_Y</span><br><span class="line"></span><br><span class="line">net = NeuralNetClassifier(</span><br><span class="line">        Net_1hidden(n_feature=n_feature, n_hidden=<span class="number">10</span>, n_output=<span class="number">2</span>),</span><br><span class="line">        max_epochs=<span class="number">20</span>,</span><br><span class="line">        lr=<span class="number">0.1</span>,</span><br><span class="line">        optimizer=torch.optim.SGD,</span><br><span class="line">        criterion=torch.nn.CrossEntropyLoss,</span><br><span class="line">        iterator_train__shuffle=<span class="literal">True</span>,</span><br><span class="line">        )</span><br><span class="line">net.fit(train_X,train_Y)</span><br></pre></td></tr></table></figure>
<p>To make the program more clear, I just choice max_epochs is 20 which by test several times. And I didnâ€™t use early stopping tech because all dataset is small enough and doesnâ€™t need too much time to train.</p>
<h2 id="Cross-validation-to-find-best-parameter"><a href="#Cross-validation-to-find-best-parameter" class="headerlink" title="Cross validation to find best parameter"></a>Cross validation to find best parameter</h2><p>In the assignment description, we needed to find the best hidden units H for each dataset. So I used the <code>GridSearchCV</code> from <code>sklearn</code>. GridSearchCV implements a â€œfitâ€ and a â€œscoreâ€ method. It also implements â€œpredictâ€, â€œpredict_probaâ€, â€œdecision_functionâ€, â€œtransformâ€ and â€œinverse_transformâ€ if they are implemented in the estimator used.Which is very useful for search best parameter. The <code>NeuralNet</code> class allows to directly access parameters of the <code>pytorch module</code> by using the <code>module__</code> prefix.</p>
<p>For each dataset, it is done by randomly sampling 80% of the training instances to train a classifier and then testing it on the remaining 20%. Which means 5-flods.<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">params = &#123;<span class="string">'module__n_hidden'</span>: [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span>],&#125;</span><br><span class="line">gs = GridSearchCV(net, params, refit=<span class="literal">False</span>, cv=<span class="number">5</span>, scoring=<span class="string">'accuracy'</span>)</span><br></pre></td></tr></table></figure><br>By this two function we can find best number of hidden between 1 to 10.</p>
<p>After train process and I find the best value is:</p>
<script type="math/tex; mode=display">
\begin{array}{cc}
\text { filename }& \text { best n value }  \\
diabetes.npz& 8\\
breast\_cancer.npz& 10\\
iris.npz& 10\\
wine.npz& 1\\
digit.npz& 8\\
\end{array}</script><p>Itâ€™s weird for <code>wine.npz</code>â€˜s best hidden number is 1. And I will discuss it on next part.</p>
<h2 id="All-result"><a href="#All-result" class="headerlink" title="All result"></a>All result</h2><p>On all five dataset, we can see the model performance as follows .</p>
<p><style type="text/css"><br>.tg  {border-collapse:collapse;border-spacing:0;}<br>.tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}<br>.tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:black;}<br>.tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}
</style></p>
<table class="tg">
  <tr>
    <th class="tg-0pky">filename</th>
    <th class="tg-0pky">best_params</th>
    <th class="tg-0pky">train_acc</th>
    <th class="tg-0pky">test_acc</th>
    <th class="tg-0pky">test_AUC</th>
    <th class="tg-0pky">train_time</th>
  </tr>
  <tr>
    <td class="tg-0pky">diabetes.npz</td>
    <td class="tg-0pky">8</td>
    <td class="tg-0pky">0.652</td>
    <td class="tg-0pky">0.647</td>
    <td class="tg-0pky">0.500</td>
    <td class="tg-0pky">0.725</td>
  </tr>
  <tr>
    <td class="tg-0pky">breast-cancer.npz</td>
    <td class="tg-0pky">10</td>
    <td class="tg-0pky">0.952</td>
    <td class="tg-0pky">0.963</td>
    <td class="tg-0pky">0.957</td>
    <td class="tg-0pky">0.568</td>
  </tr>
  <tr>
    <td class="tg-0pky">iris.npz</td>
    <td class="tg-0pky">10</td>
    <td class="tg-0pky">1.000</td>
    <td class="tg-0pky">1.000</td>
    <td class="tg-0pky">1.000</td>
    <td class="tg-0pky">0.214</td>
  </tr>
  <tr>
    <td class="tg-0pky">wine.npz</td>
    <td class="tg-0pky">1</td>
    <td class="tg-0pky">0.401</td>
    <td class="tg-0pky">0.389</td>
    <td class="tg-0pky">0.500</td>
    <td class="tg-0pky">0.244</td>
  </tr>
  <tr>
    <td class="tg-0pky">digit.npz</td>
    <td class="tg-0pky">8</td>
    <td class="tg-0pky">0.959</td>
    <td class="tg-0pky">0.935</td>
    <td class="tg-0pky">0.939</td>
    <td class="tg-0pky">0.833</td>
  </tr>
</table>

<p>As we can see, more hidden unit means more train time, because it need more computing .<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200417005311.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>Model performance well on <code>breast-cancer</code>, <code>iris.npz</code>, <code>digit.npz</code>.But for the <code>diabetes.npz</code> and <code>wine.npz</code> the model seems not work. There are several reasons for this problem. </p>
<ol>
<li>The feature and label of  dataset is meaningless.</li>
<li>The model is underfitting, because the epoch is only 20.</li>
<li>The model is too easy and conâ€™t get the relationship.</li>
</ol>
<p>For find the reason, i try 2 hidden layers and add more epoch.<br>And the train result like follows:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;diabetes.npz (615, 8) (153, 8)</span><br><span class="line">1layer</span><br><span class="line">epoch:   0, loss: 0.716,accuracy: 0.346</span><br><span class="line">epoch: 100, loss: 0.664,accuracy: 0.647</span><br><span class="line">epoch: 200, loss: 0.644,accuracy: 0.647</span><br><span class="line">epoch: 300, loss: 0.635,accuracy: 0.647</span><br><span class="line">epoch: 400, loss: 0.631,accuracy: 0.647</span><br><span class="line">epoch: 500, loss: 0.628,accuracy: 0.647</span><br><span class="line">2layer</span><br><span class="line">epoch:   0, loss: 0.706,accuracy: 0.353</span><br><span class="line">epoch: 100, loss: 0.689,accuracy: 0.647</span><br><span class="line">epoch: 200, loss: 0.676,accuracy: 0.647</span><br><span class="line">epoch: 300, loss: 0.668,accuracy: 0.647</span><br><span class="line">epoch: 400, loss: 0.661,accuracy: 0.647</span><br><span class="line">epoch: 500, loss: 0.657,accuracy: 0.647</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;wine.npz (142, 13) (36, 13)</span><br><span class="line">1layer</span><br><span class="line">epoch:   0, loss: 0.912,accuracy: 0.389</span><br><span class="line">epoch: 100, loss: 0.912,accuracy: 0.389</span><br><span class="line">epoch: 200, loss: 0.912,accuracy: 0.389</span><br><span class="line">epoch: 300, loss: 0.912,accuracy: 0.389</span><br><span class="line">epoch: 400, loss: 0.912,accuracy: 0.389</span><br><span class="line">epoch: 500, loss: 0.912,accuracy: 0.389</span><br><span class="line">2layer</span><br><span class="line">epoch:   0, loss: 0.912,accuracy: 0.389</span><br><span class="line">epoch: 100, loss: 0.912,accuracy: 0.389</span><br><span class="line">epoch: 200, loss: 0.912,accuracy: 0.389</span><br><span class="line">epoch: 300, loss: 0.912,accuracy: 0.389</span><br><span class="line">epoch: 400, loss: 0.912,accuracy: 0.389</span><br><span class="line">epoch: 500, loss: 0.912,accuracy: 0.389</span><br></pre></td></tr></table></figure><br>As we can see, no matter how many epoch and how many layers for this two dataset. The model all donâ€™t work. So I think it is the first reason. The feature and label of  dataset is meaningless.</p>
<h1 id="Neural-Networks-Models-for-Multi-class-Data-Sets"><a href="#Neural-Networks-Models-for-Multi-class-Data-Sets" class="headerlink" title="Neural Networks Models for Multi-class Data Sets"></a>Neural Networks Models for Multi-class Data Sets</h1><h2 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h2><p>For this dataset, we have train with 10000 image, and test with 1000 image. And the label is 0-9,  ten different classes. For each image, it is a 784 dimensions array, which can convert to 28*28 Square picture.<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200416195751.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<p>As we can see, there are some shoes, clothes, skirts, T-Shirts and each one class represent one number between 0-9.</p>
<h2 id="Build-a-2-hidden-layers-net"><a href="#Build-a-2-hidden-layers-net" class="headerlink" title="Build a 2 hidden layers net"></a>Build a 2 hidden layers net</h2><p>By use pytorch, itâ€™s pretty easy to define a network. Again I still use relu as activate function, CrossEntropy as loss function. And I define the input feature is a flatten array with 784, and output layer is 10 which equal to the class number.<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net_2hidden</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, n_hidden1,  n_hidden2, n_output = <span class="number">10</span>, n_feature = <span class="number">784</span>)</span>:</span></span><br><span class="line">        super(Net_2hidden, self).__init__()</span><br><span class="line">        self.hidden1 = torch.nn.Linear(n_feature, n_hidden1)</span><br><span class="line">        self.hidden2 = torch.nn.Linear(n_hidden1, n_hidden2)</span><br><span class="line">        self.out = torch.nn.Linear(n_hidden2, n_output)   <span class="comment"># output layer</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x1 = Fun.relu(self.hidden1(x))</span><br><span class="line">        x2 = Fun.relu(self.hidden2(x1))</span><br><span class="line">        x =  self.out(x2)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><br>And then I use GridSearchCV to try different number of hidden units. And also I used cross validation (randomly sampling 80% of the training instances to train a classifier and then testing it on the remaining 20%). I set the max epochs is 30 for all dataset. And this time I used Adma instead of SGD. Because by experiment,  Adma is faster than SGD to convergence.<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line">net = NeuralNetClassifier(</span><br><span class="line">        Net_2hidden(n_hidden1=<span class="number">500</span>, n_hidden2=<span class="number">100</span>),</span><br><span class="line">        max_epochs=<span class="number">30</span>,</span><br><span class="line">        lr=<span class="number">0.001</span>,</span><br><span class="line">        optimizer=torch.optim.Adam,<span class="comment">#torch.optim.SGD,</span></span><br><span class="line">        criterion=torch.nn.CrossEntropyLoss,</span><br><span class="line">        iterator_train__shuffle=<span class="literal">True</span>,</span><br><span class="line">        )</span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">'module__n_hidden1'</span>: [<span class="number">50</span>,<span class="number">75</span>,<span class="number">100</span>],<span class="comment">#,500],</span></span><br><span class="line">    <span class="string">'module__n_hidden2'</span>: [<span class="number">10</span>,<span class="number">15</span>,<span class="number">20</span>],<span class="comment">#100]</span></span><br><span class="line">&#125;</span><br><span class="line">gs = GridSearchCV(net, params, refit=<span class="literal">False</span>, cv=<span class="number">5</span>, scoring=<span class="string">'accuracy'</span>)</span><br><span class="line">train_X,train_Y = torch.FloatTensor(train_images),torch.LongTensor(train_labels)</span><br><span class="line">gs.fit(train_X,train_Y)</span><br><span class="line">print(gs.best_score_, gs.best_params_)</span><br></pre></td></tr></table></figure><br>After <code>10 minutes</code> train and test, GridSearchCV get the best params with <code>{&#39;module__n_hidden1&#39;: 75, &#39;module__n_hidden2&#39;: 20}</code>.<br>I was surprised to see that the first layer was 75 instead of 100, because in general, the larger the number of cells or the closer to the input layer model, the better the performance. After many experiments, I have come to a conclusion. The first hidden layer is 75 instead of 100, mainly because the largest parameter of the second hidden layer is 20, and the span before 100 to 20 is too large, which may cause too much loss here. Therefore, for the latter layer is 20 units, the first layer chooses 75 units to perform better.</p>
<p>And the final model get the <code>accuracy with 84%</code> on the 1000 test dataset. For each class, the accuracy as follows.<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">       <span class="class"><span class="keyword">class</span>    <span class="title">precision</span>    <span class="title">recall</span>  <span class="title">f1</span>-<span class="title">score</span>   <span class="title">support</span></span></span><br><span class="line"><span class="class">           0       0.78      0.78      0.78       107</span></span><br><span class="line"><span class="class">           1       0.93      0.95      0.94       105</span></span><br><span class="line"><span class="class">           2       0.78      0.82      0.80       111</span></span><br><span class="line"><span class="class">           3       0.78      0.75      0.77        93</span></span><br><span class="line"><span class="class">           4       0.74      0.80      0.77       115</span></span><br><span class="line"><span class="class">           5       0.93      0.90      0.91        87</span></span><br><span class="line"><span class="class">           6       0.63      0.56      0.59        97</span></span><br><span class="line"><span class="class">           7       0.91      0.95      0.93        95</span></span><br><span class="line"><span class="class">           8       0.97      0.93      0.95        95</span></span><br><span class="line"><span class="class">           9       0.94      0.93      0.93        95</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">    <span class="title">accuracy</span>                           0.83      1000</span></span><br><span class="line"><span class="class">   <span class="title">macro</span> <span class="title">avg</span>       0.84      0.84      0.84      1000</span></span><br><span class="line"><span class="class"><span class="title">weighted</span> <span class="title">avg</span>       0.83      0.83      0.83      1000</span></span><br></pre></td></tr></table></figure><br>As we can see, the class 6 get the lowest accuracy.</p>
<h2 id="Improve-build-CNN-net"><a href="#Improve-build-CNN-net" class="headerlink" title="Improve: build CNN net"></a>Improve: build CNN net</h2><p>As we know, CNN make a good performance on image. So I try a 3<em>3 CNN model, try to improve the performance  of model.<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Cnn</span><span class="params">(torch.nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, dropout=<span class="number">0.4</span>)</span>:</span></span><br><span class="line">        super(Cnn, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">32</span>, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, kernel_size=<span class="number">3</span>)</span><br><span class="line">        self.conv2_drop = nn.Dropout2d(p=dropout)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">1600</span>, <span class="number">800</span>) <span class="comment"># 1600 = number channels * width * height</span></span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">800</span>, <span class="number">10</span>)</span><br><span class="line">        self.fc1_drop = nn.Dropout(p=dropout)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = torch.relu(F.max_pool2d(self.conv1(x), <span class="number">2</span>))</span><br><span class="line">        x = torch.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), <span class="number">2</span>))</span><br><span class="line">        <span class="comment"># flatten over channel, height and width = 1600</span></span><br><span class="line">        x = x.view(<span class="number">-1</span>, x.size(<span class="number">1</span>) * x.size(<span class="number">2</span>) * x.size(<span class="number">3</span>))</span><br><span class="line">        x = self.fc1_drop(torch.relu(self.fc1(x)))</span><br><span class="line">        x = torch.softmax(self.fc2(x), dim=<span class="number">-1</span>)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><br>After many attempts, I chose <code>max_epics = 200</code>, the <code>learning rate is 0.0005</code>, and the <code>optimizer is Adam.</code> The internal parameters of the model have been fixed after several attempts. In the end, <em>*88.8% of the accuracy</em></em> is obtained in 1000 test sets.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">  epoch    train_loss    valid_acc    valid_loss     dur</span><br><span class="line">-------  ------------  -----------  ------------  ------</span><br><span class="line">      1        5.0852       0.7520        0.9469  0.3805</span><br><span class="line">     50        0.1847       0.8795        0.3360  0.3779</span><br><span class="line">    100        0.0694       0.8860        0.3733  0.3614</span><br><span class="line">    150        0.0336       0.8855        0.4257  0.3691</span><br><span class="line">    200        0.0175       0.8865        0.4704  0.3666</span><br><span class="line">Accuracy on test: 0.888</span><br></pre></td></tr></table></figure><br>Again I compute the accuracy for each class.<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">        <span class="class"><span class="keyword">class</span>  <span class="title">precision</span>    <span class="title">recall</span>  <span class="title">f1</span>-<span class="title">score</span>   <span class="title">support</span></span></span><br><span class="line"><span class="class">           0       0.91      0.80      0.85       107</span></span><br><span class="line"><span class="class">           1       0.99      0.99      0.99       105</span></span><br><span class="line"><span class="class">           2       0.82      0.84      0.83       111</span></span><br><span class="line"><span class="class">           3       0.91      0.85      0.88        93</span></span><br><span class="line"><span class="class">           4       0.85      0.85      0.85       115</span></span><br><span class="line"><span class="class">           5       0.93      0.95      0.94        87</span></span><br><span class="line"><span class="class">           6       0.66      0.75      0.71        97</span></span><br><span class="line"><span class="class">           7       0.92      0.97      0.94        95</span></span><br><span class="line"><span class="class">           8       0.97      0.97      0.97        95</span></span><br><span class="line"><span class="class">           9       0.98      0.93      0.95        95</span></span><br><span class="line"><span class="class">           </span></span><br><span class="line"><span class="class">    <span class="title">accuracy</span>                           0.89      1000</span></span><br><span class="line"><span class="class">   <span class="title">macro</span> <span class="title">avg</span>       0.89      0.89      0.89      1000</span></span><br><span class="line"><span class="class"><span class="title">weighted</span> <span class="title">avg</span>       0.89      0.89      0.89      1000</span></span><br></pre></td></tr></table></figure><br>As we can see, still for the class 6 itâ€™s hard to classify, only 66% accuracy.</p>
<h2 id="Compare-CNN-and-MLP"><a href="#Compare-CNN-and-MLP" class="headerlink" title="Compare CNN and MLP"></a>Compare CNN and MLP</h2><p>By  tensorboard, we can intuitively compare the loss trends of the two models. When I set the maximum number of iterations of both models to 50, the MLP of the two layers decreased significantly faster in terms of training loss, but in the loss of the test set, the MLP of the two layers first decreased and then increased. Fitted. So the optimal number of iterations for two-layer MLP is around 10 words.</p>
<p><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200417202326.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"></p>
<p>For the CNN model, because I added the characteristics of the Dropout layer and the CNN model itself, the iteration of the model to 50 layers is still in a decline in loss, and the accuracy of the verification set is increasing.</p>
<h2 id="Error-analysis-and-Optimization-direction"><a href="#Error-analysis-and-Optimization-direction" class="headerlink" title="Error analysis and Optimization direction"></a>Error analysis and Optimization direction</h2><p>In order to further study why it is wrong, I printed out a sample of prediction errors. I chose the most representative group to explain. </p>
<p>In the picture, we can see that these six pictures are all shoes, and their classification also belongs to [5,7,9].<br><img alt data-src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200417014003.png?x-oss-process=image/auto-orient,1/quality,q_90/format,jpg"><br>The prediction range is also [5,7,9], but the model does not find the difference between shoes. To be honest, itâ€™s hard for the naked eye to see the obvious difference between [5,7,9]. Therefore, itâ€™s understandable that the model is not clear.</p>
<p>For the above question, I think we can use the <strong><em>hierarchical prediction method</em></strong>. For example, train a model to distinguish whether shoes or clothes are needed. Then train a model for shoes to capture the subtle differences between shoes. In this way, I think the accuracy can be further improved.</p>

    </div>

    
    
    
      
  <div class="popular-posts-header">ç›¸ä¼¼æ–‡ç« </div>
  <ul class="popular-posts">
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/2020/AutoML/" rel="bookmark">AutoML-è°ƒå‚è¿ˆå…¥è’¸æ±½æ—¶ä»£</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/2020/pytorch1/" rel="bookmark">pytorchåˆä½“éªŒ</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/2020/QéŸ³ç®—æ³•å®ä¹ å¤ç›˜/" rel="bookmark">QéŸ³ç®—æ³•å®ä¹ å¤ç›˜</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/2019/ã€æœºå™¨å­¦ä¹ ã€‘é›†æˆå­¦ä¹ GDBT-XGBOOST-RF/" rel="bookmark">é›†æˆå­¦ä¹ GDBT,XGBOOST,RF</a></div>
    </li>
  </ul>


      <div>
      
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------ã€€ã€€ã€€ã€€ä½ çš„ç•™è¨€ã€€<i class="fa fa-heart"></i>ã€€æ˜¯æˆ‘æ›´æ–°çš„åŠ¨åŠ›ğŸ˜Šã€€ã€€ã€€ã€€-------------</div>
      
      </div>

      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"><i class="fa fa-tag"></i> æœºå™¨å­¦ä¹ </a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
                <a href="/2020/pytorch1/" rel="next" title="pytorchåˆä½“éªŒ">
                  <i class="fa fa-chevron-left"></i> pytorchåˆä½“éªŒ
                </a>
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
                <a href="/2020/AutoML/" rel="prev" title="AutoML-è°ƒå‚è¿ˆå…¥è’¸æ±½æ—¶ä»£">
                  AutoML-è°ƒå‚è¿ˆå…¥è’¸æ±½æ—¶ä»£ <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
      </footer>
    
  </article>

  
  
  

  </div>


          </div>
          
    <div class="comments" id="gitalk-container"></div>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          æ–‡ç« ç›®å½•
        </li>
        <li class="sidebar-nav-overview">
          ç«™ç‚¹æ¦‚è§ˆ
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Neural-Networks-Models-for-Binary-Classifcation-Data-Sets"><span class="nav-number">1.</span> <span class="nav-text">Neural Networks Models for Binary Classifcation Data Sets</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Define-the-network"><span class="nav-number">1.1.</span> <span class="nav-text">Define the network</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Build-the-pipeline"><span class="nav-number">1.2.</span> <span class="nav-text">Build the pipeline</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Cross-validation-to-find-best-parameter"><span class="nav-number">1.3.</span> <span class="nav-text">Cross validation to find best parameter</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#All-result"><span class="nav-number">1.4.</span> <span class="nav-text">All result</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Neural-Networks-Models-for-Multi-class-Data-Sets"><span class="nav-number">2.</span> <span class="nav-text">Neural Networks Models for Multi-class Data Sets</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Dataset"><span class="nav-number">2.1.</span> <span class="nav-text">Dataset</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Build-a-2-hidden-layers-net"><span class="nav-number">2.2.</span> <span class="nav-text">Build a 2 hidden layers net</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Improve-build-CNN-net"><span class="nav-number">2.3.</span> <span class="nav-text">Improve: build CNN net</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Compare-CNN-and-MLP"><span class="nav-number">2.4.</span> <span class="nav-text">Compare CNN and MLP</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Error-analysis-and-Optimization-direction"><span class="nav-number">2.5.</span> <span class="nav-text">Error analysis and Optimization direction</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->



      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="site-author-image" itemprop="image" alt="Yuan"
    src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20200228120904.jpg">
  <p class="site-author-name" itemprop="name">Yuan</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">42</span>
          <span class="site-state-item-name">æ—¥å¿—</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">åˆ†ç±»</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
        <span class="site-state-item-count">31</span>
        <span class="site-state-item-name">æ ‡ç­¾</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/liyuan97" title="GitHub &amp;rarr; https:&#x2F;&#x2F;github.com&#x2F;liyuan97" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:lysysu@qq.com" title="E-Mail &amp;rarr; mailto:lysysu@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title">
      <i class="fa fa-fw fa-link"></i>
      Friends Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="http://www.yelbee.top/" title="http:&#x2F;&#x2F;www.yelbee.top&#x2F;" rel="noopener" target="_blank">Yellow Bee</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://blog.dlzhang.com/" title="https:&#x2F;&#x2F;blog.dlzhang.com&#x2F;" rel="noopener" target="_blank">ç­ç­ç¢ç¢å¿µ</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://yiki.tech/" title="https:&#x2F;&#x2F;yiki.tech&#x2F;" rel="noopener" target="_blank">Guan FuQing</a>
        </li>
    </ul>
  </div>

      </div>

      <div style="">
  <canvas id="canvas" style="width:60%;">å½“å‰æµè§ˆå™¨ä¸æ”¯æŒcanvasï¼Œè¯·æ›´æ¢æµè§ˆå™¨åå†è¯•</canvas>
</div>
<script>
(function(){

   var digit=
    [
        [
            [0,0,1,1,1,0,0],
            [0,1,1,0,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,0,1,1,0],
            [0,0,1,1,1,0,0]
        ],//0
        [
            [0,0,0,1,1,0,0],
            [0,1,1,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [1,1,1,1,1,1,1]
        ],//1
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,0,0,0],
            [0,1,1,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,0,0,0,1,1],
            [1,1,1,1,1,1,1]
        ],//2
        [
            [1,1,1,1,1,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,1,1,0],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//3
        [
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,1,0],
            [0,0,1,1,1,1,0],
            [0,1,1,0,1,1,0],
            [1,1,0,0,1,1,0],
            [1,1,1,1,1,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,1,1]
        ],//4
        [
            [1,1,1,1,1,1,1],
            [1,1,0,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,1,1,1,1,0],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//5
        [
            [0,0,0,0,1,1,0],
            [0,0,1,1,0,0,0],
            [0,1,1,0,0,0,0],
            [1,1,0,0,0,0,0],
            [1,1,0,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//6
        [
            [1,1,1,1,1,1,1],
            [1,1,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,0,0,1,1,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0],
            [0,0,1,1,0,0,0]
        ],//7
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,1,1,0]
        ],//8
        [
            [0,1,1,1,1,1,0],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [1,1,0,0,0,1,1],
            [0,1,1,1,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,0,1,1],
            [0,0,0,0,1,1,0],
            [0,0,0,1,1,0,0],
            [0,1,1,0,0,0,0]
        ],//9
        [
            [0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0],
            [0,0,0,0,0,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,1,1,1,0,0],
            [0,0,0,0,0,0,0]
        ]//:
    ];

var canvas = document.getElementById('canvas');

if(canvas.getContext){
    var cxt = canvas.getContext('2d');
    //å£°æ˜canvasçš„å®½é«˜
    var H = 100,W = 700;
    canvas.height = H;
    canvas.width = W;
    cxt.fillStyle = '#f00';
    cxt.fillRect(10,10,50,50);

    //å­˜å‚¨æ—¶é—´æ•°æ®
    var data = [];
    //å­˜å‚¨è¿åŠ¨çš„å°çƒ
    var balls = [];
    //è®¾ç½®ç²’å­åŠå¾„
    var R = canvas.height/20-1;
    (function(){
        var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
        //å­˜å‚¨æ—¶é—´æ•°å­—ï¼Œç”±åä½å°æ—¶ã€ä¸ªä½å°æ—¶ã€å†’å·ã€åä½åˆ†é’Ÿã€ä¸ªä½åˆ†é’Ÿã€å†’å·ã€åä½ç§’é’Ÿã€ä¸ªä½ç§’é’Ÿè¿™7ä¸ªæ•°å­—ç»„æˆ
        data.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
    })();

    /*ç”Ÿæˆç‚¹é˜µæ•°å­—*/
    function renderDigit(index,num){
        for(var i = 0; i < digit[num].length; i++){
            for(var j = 0; j < digit[num][i].length; j++){
                if(digit[num][i][j] == 1){
                    cxt.beginPath();
                    cxt.arc(14*(R+2)*index + j*2*(R+1)+(R+1),i*2*(R+1)+(R+1),R,0,2*Math.PI);
                    cxt.closePath();
                    cxt.fill();
                }
            }
        }
    }

    /*æ›´æ–°æ—¶é’Ÿ*/
    function updateDigitTime(){
        var changeNumArray = [];
        var temp = /(\d)(\d):(\d)(\d):(\d)(\d)/.exec(new Date());
        var NewData = [];
        NewData.push(temp[1],temp[2],10,temp[3],temp[4],10,temp[5],temp[6]);
        for(var i = data.length-1; i >=0 ; i--){
            //æ—¶é—´å‘ç”Ÿå˜åŒ–
            if(NewData[i] !== data[i]){
                //å°†å˜åŒ–çš„æ•°å­—å€¼å’Œåœ¨dataæ•°ç»„ä¸­çš„ç´¢å¼•å­˜å‚¨åœ¨changeNumArrayæ•°ç»„ä¸­
                changeNumArray.push(i+'_'+(Number(data[i])+1)%10);
            }
        }
        //å¢åŠ å°çƒ
        for(var i = 0; i< changeNumArray.length; i++){
            addBalls.apply(this,changeNumArray[i].split('_'));
        }
        data = NewData.concat();
    }

    /*æ›´æ–°å°çƒçŠ¶æ€*/
    function updateBalls(){
        for(var i = 0; i < balls.length; i++){
            balls[i].stepY += balls[i].disY;
            balls[i].x += balls[i].stepX;
            balls[i].y += balls[i].stepY;
            if(balls[i].x > W + R || balls[i].y > H + R){
                balls.splice(i,1);
                i--;
            }
        }
    }

    /*å¢åŠ è¦è¿åŠ¨çš„å°çƒ*/
    function addBalls(index,num){
        var numArray = [1,2,3];
        var colorArray =  ["#3BE","#09C","#A6C","#93C","#9C0","#690","#FB3","#F80","#F44","#C00"];
        for(var i = 0; i < digit[num].length; i++){
            for(var j = 0; j < digit[num][i].length; j++){
                if(digit[num][i][j] == 1){
                    var ball = {
                        x:14*(R+2)*index + j*2*(R+1)+(R+1),
                        y:i*2*(R+1)+(R+1),
                        stepX:Math.floor(Math.random() * 4 -2),
                        stepY:-2*numArray[Math.floor(Math.random()*numArray.length)],
                        color:colorArray[Math.floor(Math.random()*colorArray.length)],
                        disY:1
                    };
                    balls.push(ball);
                }
            }
        }
    }

    /*æ¸²æŸ“*/
    function render(){
        //é‡ç½®ç”»å¸ƒå®½åº¦ï¼Œè¾¾åˆ°æ¸…ç©ºç”»å¸ƒçš„æ•ˆæœ
        canvas.height = 100;
        //æ¸²æŸ“æ—¶é’Ÿ
        for(var i = 0; i < data.length; i++){
            renderDigit(i,data[i]);
        }
        //æ¸²æŸ“å°çƒ
        for(var i = 0; i < balls.length; i++){
            cxt.beginPath();
            cxt.arc(balls[i].x,balls[i].y,R,0,2*Math.PI);
            cxt.fillStyle = balls[i].color;
            cxt.closePath();
            cxt.fill();
        }
    }

    clearInterval(oTimer);
    var oTimer = setInterval(function(){
        //æ›´æ–°æ—¶é’Ÿ
        updateDigitTime();
        //æ›´æ–°å°çƒçŠ¶æ€
        updateBalls();
        //æ¸²æŸ“
        render();
    },50);
}

})();
</script>

      <a href='https://clustrmaps.com/site/1b73v' target="_blank" rel="noopener"  title='Visit tracker'><img src='//clustrmaps.com/map_v2.png?cl=e6c2f3&w=a&t=m&d=7LzHpKGh5CvpAVMdhxQU8ILYaJmvVC9lpP0tATg6mtQ&co=6384c9&ct=f5f2f2'/></a>

      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        
<div class="copyright">
  
  &copy; 2019 â€“ 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yuan</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
      <span class="post-meta-item-text">ç«™ç‚¹æ€»å­—æ•°ï¼š</span>
    <span title="ç«™ç‚¹æ€»å­—æ•°">127k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">ç«™ç‚¹é˜…è¯»æ—¶é•¿ &asymp;</span>
    <span title="ç«™ç‚¹é˜…è¯»æ—¶é•¿">1:55</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="æ€»è®¿å®¢é‡">
        æœ¬ç«™è®¿å®¢æ•°<span id="busuanzi_value_site_uv"></span>äººæ¬¡
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="æ€»è®¿é—®é‡">
        æœ¬ç«™æ€»è®¿é—®é‡<span id="busuanzi_value_site_pv"></span>æ¬¡
      </span>
    </span>
</div>












        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/pisces.js"></script>
<script src="/js/next-boot.js"></script>



  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>






  <script src="/js/local-search.js"></script>














  

<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>



  

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css"/>



<script src="//cdn.jsdelivr.net/npm/js-md5@0.7.3/src/md5.min.js"></script>

<script>
  var gitalk = new Gitalk({
    clientID: '6e0e8cda3de0989d1085',
    clientSecret: '3cb5f9a7db98cf1fb0204f8ef83de99e8be2eb66',
    repo: 'liyuan97.github.io',
    owner: 'liyuan97',
    admin: ['liyuan97'],
    id: md5(location.pathname),
    
      language: 'zh-CN',
    
    distractionFreeMode: 'true'
  });
  gitalk.render('gitalk-container');
</script>

  

  

  

  


  

<script src="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>



  

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css"/>



<script src="//cdn.jsdelivr.net/npm/js-md5@0.7.3/src/md5.min.js"></script>

<script>
  var gitalk = new Gitalk({
    clientID: '6e0e8cda3de0989d1085',
    clientSecret: '3cb5f9a7db98cf1fb0204f8ef83de99e8be2eb66',
    repo: 'liyuan97.github.io',
    owner: 'liyuan97',
    admin: ['liyuan97'],
    id: md5(location.pathname),
    
      language: 'zh-CN',
    
    distractionFreeMode: 'true'
  });
  gitalk.render('gitalk-container');
</script>

</body>
</html>
