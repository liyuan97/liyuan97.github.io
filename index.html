<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.4.2',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: 'Copy',
      copy_success: 'Copied',
      copy_failure: 'Copy failed'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="keywords" content="技术,学习">
<meta property="og:type" content="website">
<meta property="og:title" content="元哥的后花园">
<meta property="og:url" content="http:&#x2F;&#x2F;yoursite.com&#x2F;index.html">
<meta property="og:site_name" content="元哥的后花园">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yoursite.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: true,
    isPost: false,
    isPage: false,
    isArchive: false
  };
</script>

  <title>元哥的后花园</title>
  








  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">元哥的后花园</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">学习笔记&采坑日记</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/11/30/What-is-GAN-basicly/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/pic03.jpg">
      <meta itemprop="name" content="Yuan">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="元哥的后花园">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/11/30/What-is-GAN-basicly/" class="post-title-link" itemprop="url">What is GAN basicly?</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2019-11-30 15:13:04 / Modified: 15:13:31" itemprop="dateCreated datePublished" datetime="2019-11-30T15:13:04+08:00">2019-11-30</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><strong>MSBD5012 Term Paper</strong></p>
<p>Due Date: 7 December 2019</p>
<p>Via Canvas</p>
<p>As announced by the university administration, there won’t be any proctored examinations this semester and alternative assessment arrangements are to be made by the course instructors. For CSIT6000G/MSBD5012, you are asked to write a term paper in lieu of the final exam.</p>
<p>You need to choose one topic from the following list, and explain it informally:</p>
<p>· Adversarial attack</p>
<p>· Variational autoencoders</p>
<p>· Generative adversarial networks</p>
<p>· Deep reinforcement learning</p>
<p>The targeted readers of the paper are computer science students who are about to take the course. In other words,  <strong>you are asked to explain the chosen topic to the past you</strong> at 1 September 2019.  Obviously, there isn’t enough space for you to include all the details. However, you need to cover the<br>key concepts and key ideas.<br> You can follow the outlines of the relevant lectures, and might need to include contents before those lectures as background.</p>
<p>You can include diagrams and mathematical formulae. However, avoid mathematical formulae as much as possible because  <strong>the purpose is to give informal explanations, not formal proofs.</strong></p>
<p>The term paper should be no more than 4 pages in length, and the font size of the main text should be 12pt. You are encouraged to use latex  <a href="https://github.com/ICLR/Master-Template/blob/master/archive/iclr2020.zip" target="_blank" rel="noopener">latex template</a> of <a href="https://iclr.cc/Conferences/2020/CallForPapers" target="_blank" rel="noopener">ICLR 2020</a>. Generate a pdf file for submission via Canvas and name your file  “ [Last Name]_ [First Name]_[Student ID].pdf”. Discussions among students are encouraged. However, you need to write up your paper independently.  A plagiarism checker will be run on all submitted reports.</p>
<p>The term paper will be graded using the following scheme:</p>
<p>· Overall understanding of the topic:  50%</p>
<p>· Clarity of explanations:  30%</p>
<p>· Effort (how polished the report is):  20%</p>
<p>The term paper is  <strong>due by 23:59 on 7 December</strong>, the scheduled final exam date.  <strong>No late submissions will be accepted</strong>.</p>
<hr>
<h1 id="Generative-Adversarial-Networks-is-so-Easy"><a href="#Generative-Adversarial-Networks-is-so-Easy" class="headerlink" title="Generative Adversarial Networks is so Easy"></a>Generative Adversarial Networks is so Easy</h1><p>In machine learning course, we learn how to teach our program to learn the information among the data. There are a lot’s kinds of work can be down, just like classification, regression and generate new data as same as nature. Generating new data is pretty interesting job. Thinking about what if you can teach your program to learn the plot by Picasso’s. The plots by Picasso’s  is very famous and expensive. The most painting by Picasso is _Les femmes d’Alger_  which worth  $179 million.  If we can teach our program to plot a image similar with his style easily. That’s will be a amazing job. But now we can made it by the algorithm GANs.</p>
<h2 id="Basic-idea"><a href="#Basic-idea" class="headerlink" title="Basic idea"></a>Basic idea</h2><p><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191130001221.png" alt=""></p>
<p>GANs are the algorithms represented for Generative Adversarial Networks.  It is the process of two complex algorithms (neural networks) competing against each other. One algorithms is called <strong>Generator,</strong> the other algorithm is called <strong>Discriminator</strong>.</p>
<p>The generative model and the discriminant model play a game with each other and learn to produce quite good output. Taking pictures as an example, the main task of the generator is to learn the real picture set, so that the pictures generated by yourself are closer to the real pictures, and the “disguise” discriminator. The main task of the discriminator is to find out the picture generated by the generator, distinguish it from the real picture, and perform true and false discrimination. Throughout the iteration process, the generator continuously strives to make the generated image more and more real, and the discriminator continuously strives to identify the authenticity of the picture. This is similar to the game between the generator and the discriminator. After repeated iterations, the two finally reached a balance: the picture generated by the generator is very close to the real picture, and it is difficult for the discriminator to distinguish the difference between the real and fake pictures. Its performance is that for true and false pictures, the probability output of the discriminator is close to 0.5.</p>
<p>Let’s still assume an I wants to replicate the style of Picasso. After I have watch all the detail of Picasso’s paintings, I think I have learned a lot. So I find a a collector to help me improve my level. The collector has rich experience and sharp eyes, and the paintings on the market that imitate Picasso cannot escape his eyes. The collector told me a word: when will your painting deceive me, you will be successful.</p>
<p>Then I give hime this one:<br><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191130110753.png" alt=""><br>The collector glanced lightly and was very angry. “0 points! This is also called painting? Too much difference!” After listening to the collector’s words, I began to reflect on myself and did not hesitate to draw, even it is a black image. So I drew another picture:<br><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191130110852.png" alt=""></p>
<p>The collector saw : 1 point ! Repaint! As soon as I thought it was still impossible, the painting was too bad, so I went back to study Picasso’s painting style, and continued to improve and re-create, until one day I showed the new painting to the collector:<br><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191130001221.png" alt=""><br>This time, the collector was wearing glasses and carefully analyzing. After a long time, the collector patted my shoulder and said that the painting was very good. Haha, I was so happy to be praised and affirmed by the collector.</p>
<p>This example is actually a GAN training process. I am a generator, the purpose is to output a picture that can fool collectors, making it difficult for collectors to distinguish between true and false! The collector is the discriminator, the purpose is to identify my painting and judge it to be false! The whole process is a game of “generation-confrontation”. In the end, I (the generator) outputs a picture of “truths and false truths”, and even collectors (the discriminator) can hardly distinguish.</p>
<h2 id="What’s-GAN-model"><a href="#What’s-GAN-model" class="headerlink" title="What’s GAN model?"></a>What’s GAN model?</h2><p>After we talk about the basic ideal, then let’s see what is the Generative Adversarial Networks(GANs) mathematically.  Generally, GANs are a model architecture for training a generative model, and it is most common to use deep learning models in this architecture.</p>
<p>The GAN architecture was first described in the 2014 paper by  Ian Goodfellow, et al. titled “Generative Adversarial Networks.” After this paper appeared, there are plenty related paper followed. A standardized approach called Deep Convolutional Generative Adversarial Networks, or DCGAN, that led to more stable models was later formalized by  Alec Radford, et al. in the 2015 paper titled Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks.</p>
<p>The GAN model architecture involves two sub-models: a  _generator model_  for generating new examples and a  _discriminator model_  for classifying whether generated examples are real, from the domain, or fake, generated by the generator model.</p>
<ul>
<li><strong>Generator</strong>. Model that is used to generate new plausible examples from the problem domain.</li>
<li><strong>Discriminator</strong>. Model that is used to classify examples as real (_from the domain_) or fake (_generated_).</li>
</ul>
<blockquote>
<p>Generative adversarial networks are based on a game theoretic scenario in which the generator network must compete against an adversary. The generator network directly produces samples. Its adversary, the discriminator network, attempts to distinguish between samples drawn from the training data and samples drawn from the generator.</p>
</blockquote>
<h3 id="Generator-Model"><a href="#Generator-Model" class="headerlink" title="Generator Model"></a>Generator Model</h3><p>The generator model takes a fixed-length random vector as input and generates a sample in the domain. The vector is drawn from randomly from a Gaussian distribution, and the vector is used to seed the generative process. After training, points in this multidimensional vector space will correspond to points in the problem domain, forming a compressed representation of the data distribution.</p>
<p>This vector space is referred to as a latent space, or a vector space comprised of  <a href="https://en.wikipedia.org/wiki/Latent_variable" target="_blank" rel="noopener">latent variables</a>. Latent variables, or hidden variables, are those variables that are important for a domain but are not directly observable.</p>
<p>We often refer to latent variables, or a latent space, as a projection or compression of a data distribution. That is, a latent space provides a compression or high-level concepts of the observed raw data such as the input data distribution. In the case of GANs, the generator model applies meaning to points in a chosen latent space, such that new points drawn from the latent space can be provided to the generator model as input and used to generate new and different output examples.</p>
<p>After training, the generator model is kept and used to generate new samples.</p>
<p><img src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/04/Example-of-the-GAN-Generator-Model.png" alt="Example of the GAN Generator Model"></p>
<p>Example of the GAN Generator Model</p>
<h3 id="The-Discriminator-Model"><a href="#The-Discriminator-Model" class="headerlink" title="The Discriminator Model"></a>The Discriminator Model</h3><p>The discriminator model takes an example from the domain as input (real or generated) and predicts a binary class label of real or fake (generated).</p>
<p>The real example comes from the training dataset. The generated examples are output by the generator model.</p>
<p>The discriminator is a normal (and well understood) classification model.</p>
<p>After the training process, the discriminator model is discarded as we are interested in the generator.</p>
<p>Sometimes, the generator can be repurposed as it has learned to effectively extract features from examples in the problem domain. Some or all of the feature extraction layers can be used in transfer learning applications using the same or similar input data.</p>
<p><img src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/04/Example-of-the-GAN-Discriminator-Model.png" alt="Example of the GAN Discriminator Model"></p>
<h1 id="Combine-two-parts"><a href="#Combine-two-parts" class="headerlink" title="Combine two parts"></a>Combine two parts</h1><p>Generative modeling is an unsupervised learning problem, as we discussed in the previous section, although a clever property of the GAN architecture is that the training of the generative model is framed as a supervised learning problem. The two models, the generator and discriminator, are trained together. The generator generates a batch of samples, and these, along with real examples from the domain, are provided to the discriminator and classified as real or fake. The discriminator is then updated to get better at discriminating real and fake samples in the next round, and importantly, the generator is updated based on how well, or not, the generated samples fooled the discriminator.</p>
<p>In this way, the two models are competing against each other, they are adversarial in the game theory sense, and are playing a  zero-sum game. In this case, zero-sum means that when the discriminator successfully identifies real and fake samples, it is rewarded or no change is needed to the model parameters, whereas the generator is penalized with large updates to model parameters. Alternately, when the generator fools the discriminator, it is rewarded, or no change is needed to the model parameters, but the discriminator is penalized and its model parameters are updated.</p>
<p>At a limit, the generator generates perfect replicas from the input domain every time, and the discriminator cannot tell the difference and predicts “unsure” (e.g. 50% for real and fake) in every case. This is just an example of an idealized case; we do not need to get to this point to arrive at a useful generator model.</p>
<p><img src="https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/04/Example-of-the-Generative-Adversarial-Network-Model-Architecture.png" alt="Example of the Generative Adversarial Network Model Architecture"></p>
<p>Example of the Generative Adversarial Network Model Architecture</p>

      
    </div>
    <div>
      
    </div>
    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/11/16/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%91%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0GDBT-XGBOOST-RF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/pic03.jpg">
      <meta itemprop="name" content="Yuan">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="元哥的后花园">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/11/16/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%91%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0GDBT-XGBOOST-RF/" class="post-title-link" itemprop="url">集成学习GDBT,XGBOOST,RF</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2019-11-16 14:58:20 / Modified: 15:42:33" itemprop="dateCreated datePublished" datetime="2019-11-16T14:58:20+08:00">2019-11-16</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>集成学习（Ensemble Learning），集成学习的目的是通过结合多个基学习器的预测结果来改善单个学习器的泛化能力和鲁棒性。</p>
<p>集成学习致分为两大类：</p>
<ul>
<li>Boosting:即个体学习器之间存在强依赖关系、必须串行生成的序列化方法，Adaboost, GDBT, Xgboost.</li>
<li>Bagging以及个体学习器间不存在强依赖关系、可同时生成的并行化方法，“随机森林”（Random Forest）。</li>
</ul>
<h1 id="1-Bagging"><a href="#1-Bagging" class="headerlink" title="1. Bagging"></a>1. Bagging</h1><p>Bagging：简单放回抽样，多数表决（分类）或简单平均（回归）,同时Bagging的基学习器之间属于并列生成，无依赖关系。</p>
<h2 id="1-1-随机森林"><a href="#1-1-随机森林" class="headerlink" title="1.1 随机森林"></a>1.1 随机森林</h2><p>Random Forest（随机森林）：Bagging的扩展变体，它在以决策树为基学习器构建Bagging集成的基础上，进一步在决策树的训练过程中引入了随机特征选择，因此可以概括RF包括四个部分：<br>1、随机选择 样本（放回抽样）；<br>2、随机选择 特征；<br>3、构建分类器；如：ID3、C4.5、CART、SVM、Logistic regression等<br>4、投票（平均）</p>
<p>随机性偏差会有微增（相比于单棵不随机树），‘平均’会使得方差减小更多</p>
<ul>
<li>随机森林的优点<br>1、速度快，精度不会很差<br>2、能够处理高维数据，不用特征选择，训练完后，可给出特征重要性；<br>3、可并行化  </li>
<li>随机森林的缺点：在噪声较大的分类或者回归问题上回过拟合。</li>
</ul>
<h1 id="2-Boosting"><a href="#2-Boosting" class="headerlink" title="2. Boosting"></a>2. Boosting</h1><h2 id="2-1-基于调整权重-Adaboost"><a href="#2-1-基于调整权重-Adaboost" class="headerlink" title="2.1 基于调整权重 Adaboost"></a>2.1 基于调整权重 Adaboost</h2><p>每生成一棵树之后，计算两个权重</p>
<blockquote>
<p>1 计算这个树的误差率，误差率越高，权重越低<br>2 计算每个样本的错分率，错分的样本，权重越高，之后更容易分对</p>
</blockquote>
<p><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191116091802.png" alt=""><br><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191116091915.png" alt=""></p>
<h2 id="2-2-基于残差：GB-GBTD-Xgboost"><a href="#2-2-基于残差：GB-GBTD-Xgboost" class="headerlink" title="2.2 基于残差：GB(GBTD,Xgboost)"></a>2.2 基于残差：GB(GBTD,Xgboost)</h2><h3 id="2-2-1-GBTD"><a href="#2-2-1-GBTD" class="headerlink" title="2.2.1 GBTD"></a>2.2.1 GBTD</h3><p>GBDT只能由回归树组成.</p>
<ul>
<li>基本思想：<br>在GradientBoost中，每个新的模型的建立是为了使得之前的模型的残差往梯度下降的方法。</li>
</ul>
<p><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191116110339.png" alt=""></p>
<ul>
<li>如果是分类树，损失函数是指数损失函数：<br>𝐿(𝑦,𝑓(𝑥))=𝑒𝑥𝑝(−𝑦𝑓(𝑥))</li>
<li>如果是回归树，损失函数是均方损失（CART）：<br>𝐿(𝑦,𝑓(𝑥))=(𝑦−𝑓(𝑥))^2</li>
<li>如何防止过拟合？<blockquote>
<ol>
<li>步长v(0-1)，权重衰减 𝑓𝑘(𝑥)=𝑓𝑘−1(𝑥)+𝑣 ℎ𝑘(𝑥)，降低新来的分类器的影响力</li>
<li>子采样比例</li>
<li>用弱学习器</li>
</ol>
</blockquote>
</li>
</ul>
<h3 id="2-2-2-xgboost"><a href="#2-2-2-xgboost" class="headerlink" title="2.2.2 xgboost"></a>2.2.2 xgboost</h3><p>当已经生成了一棵树的时候，如何去选择新子树：</p>
<ul>
<li><p>1 目标函数：</p>
<script type="math/tex; mode=display">Obj=\sum_{i=1}^{n} l\left(y_{i}, \hat{y}_{i}\right)+\sum_{k} \Omega\left(f_{k}\right), f_{k} \in \mathcal{F}</script></li>
<li><p>1.1 第t轮的时候：</p>
<script type="math/tex; mode=display">\begin{aligned} O b j^{(t)} 
&=\sum_{i=1}^{n} l\left(y_{i}, \hat{y}_{i}^{(t)}\right)+\sum_{i=1}^{t} \Omega\left(f_{i}\right) 
\\ & \equiv \sum_{i=1}^{n} l\left(y_{i}, \hat{y}_{i}^{(t-1)}+f_{t}\left(x_{i}\right)\right)+\Omega\left(f_{t}\right)+c\end{aligned}</script></li>
<li>这时候需要寻找f_t来让目标函数最小</li>
</ul>
<blockquote>
<p>a. 式子左边，对目标函数在$f_t(x)$上泰勒展开，去二阶，求得近似解：<br><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191116120113.png" alt=""></p>
<p>b. 式子右边，定义复杂度 $\Omega\left(f_{t}\right)$<br>每颗树，都是由枝干(分类节点)和叶子(树的末端)组成的。<br>定义复杂度为：叶子个个数T, 加上每个叶子的值w平方和（各有系数）。<br>树越复杂，T ↑，w平方和 ↑，复杂度 ↑，惩罚 ↑。<br><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191116121238.png" alt=""></p>
</blockquote>
<ul>
<li>更新目标函数：<script type="math/tex; mode=display">
\begin{aligned} O b j^{(t)} & \simeq \sum_{i=1}^{n}\left[g_{i} f_{t}\left(x_{i}\right)+\frac{1}{2} h_{i} f_{t}^{2}\left(x_{i}\right)\right]+\Omega\left(f_{t}\right) +c\\ &=\sum_{i=1}^{n}\left[g_{i} w_{q\left(x_{i}\right)}+\frac{1}{2} h_{i} w_{q\left(x_{i}\right)}^{2}\right]+\left(\gamma T+\lambda \frac{1}{2} \sum_{j=1}^{T} w_{j}^{2}\right)+c
\\ &=\sum_{j=1}^{T}\left[\left(\sum_{i \in I_{j}} g_{i}\right) w_{j}+\frac{1}{2}\left(\sum_{i \in I_{j}} h_{i}+\lambda\right) w_{j}^{2}\right]+\gamma T +c \end{aligned}</script></li>
</ul>
<blockquote>
<ul>
<li>其中$f_{t}(x)=w_{q(x)}, w \in \mathbf{R}^{T}, q: \mathbf{R}^{d} \rightarrow\{1,2, \cdots, T\}$，表示x→叶节点→对应的值w。目的是统一用$w_{j}$表示树$f_t$。</li>
<li>第三行的理解，对于示性函数$I_{j}=\left\{i | q\left(x_{i}\right)=j\right\}$，$I_j$表示一个集合在j的叶子节点中。用示性函数求和代替1-n的求和，然后交换求和顺序。</li>
</ul>
</blockquote>
<ul>
<li>这里发现目标函数是关于$w_{j}$的二次函数，二次函数在对称轴上取极值。<br>简化表达：$G_{j}=\sum_{i \in I_{j}} g_{i} \quad H_{j}=\sum_{i \in I_{j}} h_{i}$得到：<script type="math/tex; mode=display">
\begin{aligned} O b j^{(t)} =\sum_{j=1}^{T}\left[G_{j} w_{j}+\frac{1}{2}\left(H_{j}+\lambda\right) w_{j}^{2}\right]+\gamma T \end{aligned}</script>二次函数求极值得到：<script type="math/tex; mode=display">
\begin{array}{c}{w_{j}^{*}=-\frac{G_{j}}{H_{j}+\lambda}} \\ {} \\ {O b j=-\frac{1}{2} \sum_{j=1}^{T} \frac{G_{j}^{2}}{H_{j}+\lambda}+\gamma T}\end{array}</script>w是每一个叶节点值，Obj是这个树的分数，分数越低越好。<br>这样，就可以直接计算出树的分数，可以对于候选进行评比。</li>
</ul>
<hr>
<p>如何生成候选树？</p>
<ul>
<li>Enumerate 枚举可能的结构</li>
<li>通过刚才的式子计算最优分数</li>
<li>但是问题是有无限的可能性。</li>
</ul>
<hr>
<ul>
<li>所以通过贪婪学习：（不详细讲）<br>每一次尝试对已有的叶子结点加入一个分割，选择具有最佳增益的分割对结点进行分裂。对于一个具体的分割方案，我们可以获得的增益可以由如下公式计算：<br><img src="https://liyuanimage.oss-cn-beijing.aliyuncs.com/img/20191116142330.png" alt=""></li>
</ul>
<blockquote>
<p>也就是通过信息增益去寻找最优分割点。<br>这里有个好处就是如果惩罚大于增益，gain就会为负数，自动停止。</p>
</blockquote>
<h1 id="3-模型对比"><a href="#3-模型对比" class="headerlink" title="3 模型对比"></a>3 模型对比</h1><h2 id="3-1-随机森林vsGDBT"><a href="#3-1-随机森林vsGDBT" class="headerlink" title="3.1 随机森林vsGDBT"></a>3.1 随机森林vsGDBT</h2><ul>
<li>决策树类型：组成随机森林的树可以是分类树，也可以是回归树；而GBDT只能由回归树组成；  </li>
<li>结果预测：对于最终的输出结果而言，随机森林采用多数投票、简单平均等；而GBDT则是将所有结果累加起来，或者加权累加起来；  </li>
<li>并行/串行：组成随机森林的树可以并行生成；而GBDT只能是串行生成；  </li>
<li>异常值：随机森林对异常值不敏感；GBDT对异常值非常敏感；</li>
<li>方差/偏差：随机森林减少方差；GBDT是通过减少偏差。</li>
</ul>
<h2 id="3-2-GDBT-vs-XGboost"><a href="#3-2-GDBT-vs-XGboost" class="headerlink" title="3.2 GDBT vs XGboost"></a>3.2 GDBT vs XGboost</h2><ul>
<li>GDBT只支持CATR树，xgboost还支持线性分类器</li>
<li>GDBT只用了一阶，xgboost泰勒展开，用了二阶</li>
<li>xgboost有正则项，而且会自动停止生成(依赖参数gamma)。</li>
<li>xgboost可以列抽样，借鉴了随机森林的做法</li>
<li>XGBOOST可以自动学习出缺失值的分裂方向</li>
<li>XGBOOST实现了并行化：每个特征并行计算，每个特征划分也并行计算</li>
</ul>
<p>后期实现中，xgboost还有优化，所以很快：</p>
<ul>
<li>在寻找分割点，枚举贪心法效率低，xgboost实现近似的算法。大致的思想是根据百分位法列举几个成为分割点的候选者，然后再进一步计算。</li>
<li>xgboost考虑了训练数据为稀疏值的情况（我也不懂T^T）</li>
<li>特征列排序后以块的形式存储在内存中，在迭代中可以重复使用；虽然boosting算法迭代必须串行，但是在处理每个特征列时可以做到并行。</li>
<li>Shrinkage（缩减），相当于学习速率（xgboost中的eta）。xgboost在进行完一次迭代后，会将叶子节点的权重乘上该系数，主要是为了削弱每棵树的影响，让后面有更大的学习空间。实际应用中，一般把eta设置得小一点，然后迭代次数设置得大一点。（补充：传统GBDT的实现也有学习速率）</li>
</ul>
<p>总结，一个简单的idel不断优化，借鉴别的想法，优化到了极致，导致xgboost能这么强。</p>
<p>参考资料：xgboost原文<br><a href="https://blog.csdn.net/weixin_42158523/article/details/81737370" target="_blank" rel="noopener">https://blog.csdn.net/weixin_42158523/article/details/81737370</a><br><a href="https://www.cnblogs.com/aixiao07/p/11375168.html" target="_blank" rel="noopener">https://www.cnblogs.com/aixiao07/p/11375168.html</a></p>

      
    </div>
    <div>
      
    </div>
    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/26/Blog2-%E6%B8%AF%E6%A0%A1msc-%E4%BA%92%E8%81%94%E7%BD%91%E6%89%BE%E5%B7%A5%E4%BD%9C%E6%97%B6%E9%97%B4%E8%BD%B4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/pic03.jpg">
      <meta itemprop="name" content="Yuan">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="元哥的后花园">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/10/26/Blog2-%E6%B8%AF%E6%A0%A1msc-%E4%BA%92%E8%81%94%E7%BD%91%E6%89%BE%E5%B7%A5%E4%BD%9C%E6%97%B6%E9%97%B4%E8%BD%B4/" class="post-title-link" itemprop="url">Blog-2 港校msc 互联网找工作时间轴</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-10-26 08:52:24" itemprop="dateCreated datePublished" datetime="2019-10-26T08:52:24+08:00">2019-10-26</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-10-27 14:29:47" itemprop="dateModified" datetime="2019-10-27T14:29:47+08:00">2019-10-27</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="港校msc-互联网找工作时间轴"><a href="#港校msc-互联网找工作时间轴" class="headerlink" title="港校msc 互联网找工作时间轴"></a>港校msc 互联网找工作时间轴</h1><p><strong>入学前的（大四） 暑期实习</strong> 建议参加<br>3-5月 实习岗位网申开启<br>5-7月 进行网申、面试，发放Offer<br>7-9月 进入公司实习</p>
<p><strong>入学前的 秋季校招</strong> 建议参加<br>7-8月 互联网大厂的提前批、正式校招开放；<br>9月意向书，10月底谈薪</p>
<hr>
<h2 id="入学"><a href="#入学" class="headerlink" title="入学"></a>入学</h2><p><strong>入学后的</strong> 春季校招 招人较少<br>2-4月 进行网申<br>3-5月 开始笔试、面试<br>5-6月 发Offer入职</p>
<p><strong>暑假实习</strong> 必参加<br>3-5月 各大行业实习岗位网申开启<br>5-7月 进行网申、面试，发放Offer<br>7-9月 进入公司实习</p>
<p><strong>秋季校招</strong> 即使拿到实习return也建议参加，有利于argue涨价<br>7-8月 互联网大厂的提前批、正式校招开放；<br>9月意向书，10月底谈薪</p>
<p>11月毕业-&gt;入职</p>
<hr>
<h2 id="成为社畜"><a href="#成为社畜" class="headerlink" title="成为社畜"></a>成为社畜</h2><p>我的个人准备笔试面试时间轴：<br><!-- Table --><br>| 月份| 校内|找工作准备|<br>|—|—|—|<br>| 11月| 各种ddl | 算法基础+数据结构<br>|12月|考试+寒假|剑指offer<br>|1月|寒假| 剑指offer+NLP+整理机器学习+特征工程<br>|2月|开学不忙|leetcode mid+NLP实战+整理深度学习<br>|3月|开始准备期中| leetcode hard+笔试概率题、智商题</p>

      
    </div>
    <div>
      
    </div>
    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/24/Blog1-Build%20by%20Hexo/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/pic03.jpg">
      <meta itemprop="name" content="Yuan">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="元哥的后花园">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/10/24/Blog1-Build%20by%20Hexo/" class="post-title-link" itemprop="url">Blog1-Build by Hexo</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2019-10-24 16:00:23" itemprop="dateCreated datePublished" datetime="2019-10-24T16:00:23+08:00">2019-10-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-11-16 14:59:48" itemprop="dateModified" datetime="2019-11-16T14:59:48+08:00">2019-11-16</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>本次搭建blog，完全学习于：<a href="https://www.bilibili.com/video/av44544186?from=search&amp;seid=6748505739751413370" target="_blank" rel="noopener">b站up主codesheep视频</a></p>
<p>下面进入流程：</p>
<ol>
<li>sudo su 进入管理员</li>
<li>安装Node.js，搜索，下载，安装<br>安装之后会有两个工具： node和npm<br>也可以用国内的cnpm</li>
<li>通过npm安装hexo 博客静态框架<blockquote>
<p>npm install -g hexo-cli </p>
</blockquote>
</li>
<li>建立一个专有的文件夹，方便管理</li>
<li>文件夹下运行hexo<blockquote>
<p>sudo hexo init</p>
</blockquote>
</li>
</ol>
<p>初始化文件，主要的有_config.yml 配置文件，source内容的文件夹，themes主题文件夹。</p>
<blockquote>
<p>hexo s #start 开始<br>hexo n “文章名” #生成文章<br>hexo clean #清理之前的</p>
<ol>
<li>部署到github</li>
</ol>
</blockquote>
<p>生成 xxx.github.io（ xxx必须为github的用户名）的项目</p>
<blockquote>
<p>npm install —save hexo-deployer-git</p>
</blockquote>
<p>下载插件，连接到git</p>
<p>设置_config.yml最下面</p>
<blockquote>
<p>type: git<br>repo: <a href="https://github.com/xxxx/xxxx.github.io" target="_blank" rel="noopener">https://github.com/xxxx/xxxx.github.io</a></p>
</blockquote>
<p>推送到远端</p>
<blockquote>
<p>hexo clean &amp;&amp; hexo g &amp;&amp; hexo d</p>
</blockquote>
<p>访问 xxxx.github.io，就可以看到自己的博客啦。</p>
<hr>
<p><a href="https://hexo.io/zh-cn/docs/commands.html" target="_blank" rel="noopener">hexo官网</a></p>

      
    </div>
    <div>
      
    </div>
    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

        
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block home" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/24/Blog0-Hello-Blog/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/pic03.jpg">
      <meta itemprop="name" content="Yuan">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="元哥的后花园">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            <a href="/2019/10/24/Blog0-Hello-Blog/" class="post-title-link" itemprop="url">Blog-0 Hello Blog</a>
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2019-10-24 15:04:38 / Modified: 15:08:00" itemprop="dateCreated datePublished" datetime="2019-10-24T15:04:38+08:00">2019-10-24</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Hello-Blog"><a href="#Hello-Blog" class="headerlink" title="Hello Blog."></a>Hello Blog.</h1><p>之前经常会发现大佬有自己的技术博客，之前也尝试着去做一个，但是由于自己的技术水平有限，也没有决定好走技术路线，所以就一直没有开始写技术博客。</p>
<p>最近比较了算法和产品的待遇，真的差别好大。暂且不说之后的发展会怎样，程序员/技术岗本身是智力和努力的比拼，是硬功夫。有更清晰的发展方向。再加上种种原因，我决定做技术了。</p>
<ul>
<li>所以为什么要写博客呢？<br>（鉴于自己的理解和b站up主<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fwww.bilibili.com%2Fvideo%2Fav56930990%2F%3Fspm_id_from%3D333.788.videocard.2" target="_blank" rel="noopener">codesheep</a> 的介绍，总结如下） <ol>
<li>博客=输出=实践<br>写博客也是一个技术输出的过程，而当你想输出的时候，你就已经需要整合自己的学习成果，不断的理解技术细节，比如说：神经网络的梯度传到过程，虽然接触很多遍，不动手就很难掌握。</li>
<li>博客=输出=表达<br>理科出身的我经常给自己找借口，原理我懂就行，表达不清楚就慢慢表达，但实际上，表达不清楚会导致别人不愿意和你交流，从而丧失很多机会。<br>有了输出的过程，就需要去磨炼自己表达的精炼程度，以及练习如何让别人明白，就更容易理解。</li>
<li>博客=简历=社交<br>有了个人主页，别人就知道你的技术水平，你会什么，你学过什么，一应俱全。是找工作，或者是技术交流的好平台。</li>
</ol>
</li>
<li>担心自己的博客没有技术含量？<br>你觉得没有技术含量的可能会对别人有用，只要可复现，都是有价值的。</li>
<li>现在写的会晚吗？<br>我知道很多cs的同学大一就开始搭建自己的知识体系，构建专栏，值得敬佩和羡慕。不过人生漫长，任何时候开始干一件事都不晚。</li>
<li>写什么内容？<ol>
<li>学习笔记、心得</li>
<li>生活感悟</li>
<li>工程排坑</li>
</ol>
</li>
</ul>
<p>为了混口饭吃，写博客的flag没有任何理由推倒了吧。<br>希望最少保持一个月一篇的频率，正常频率一周一篇。</p>

      
    </div>
    <div>
      
    </div>
    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

  </div>

  



          </div>
          

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="site-author-image" itemprop="image" alt="Yuan"
    src="/images/pic03.jpg">
  <p class="site-author-name" itemprop="name">Yuan</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">5</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yuan</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> v4.0.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.4.2
  </div>

        












        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/pisces.js"></script>
<script src="/js/next-boot.js"></script>



  


















  

  
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  

  

</body>
</html>
